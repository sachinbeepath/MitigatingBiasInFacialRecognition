{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import models,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import collections\n",
    "from  PIL import Image\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data \n",
    "# create df to contain all identities, their image file names, their ethnicities\n",
    "path = \"data/RFW/images/test/txts/\"\n",
    "img_path = 'data/RFW/images/test/data/'\n",
    "\n",
    "# African images\n",
    "african_images = pd.read_csv(path + 'African/African_images.txt', sep=\"\\t\", header=None)\n",
    "african_images.columns = ['File', 'Label']\n",
    "african_images['identityID'] = african_images['File'].str[:-9]\n",
    "african_images['faceID'] = african_images['File'].str[-8:-4]\n",
    "african_images['Ethnicity'] = 'African'\n",
    "# Asian images\n",
    "asian_images = pd.read_csv(path + 'Asian/Asian_images.txt', sep=\"\\t\", header=None)\n",
    "asian_images.columns = ['File', 'Label']\n",
    "asian_images['identityID'] = asian_images['File'].str[:-9]\n",
    "asian_images['faceID'] = asian_images['File'].str[-8:-4]\n",
    "asian_images['Ethnicity'] = 'Asian'\n",
    "# Caucasian images\n",
    "caucasian_images = pd.read_csv(path + 'Caucasian/Caucasian_images.txt', sep=\"\\t\", header=None)\n",
    "caucasian_images.columns = ['File', 'Label']\n",
    "caucasian_images['identityID'] = caucasian_images['File'].str[:-9]\n",
    "caucasian_images['faceID'] = caucasian_images['File'].str[-8:-4]\n",
    "caucasian_images['Ethnicity'] = 'Caucasian'\n",
    "# Indian images\n",
    "indian_images = pd.read_csv(path + 'Indian/Indian_images.txt', sep=\"\\t\", header=None)\n",
    "indian_images.columns = ['File', 'Label']\n",
    "indian_images['identityID'] = indian_images['File'].str[:-9]\n",
    "indian_images['faceID'] = indian_images['File'].str[-8:-4]\n",
    "indian_images['Ethnicity'] = 'Indian'\n",
    "all_images = pd.concat([african_images,asian_images,caucasian_images,indian_images])\n",
    "\n",
    "# remove any duplicate identities\n",
    "v = all_images.reset_index().groupby('identityID').Ethnicity.nunique()\n",
    "dup = v[v>1].index.tolist()\n",
    "all_images = all_images[~all_images['identityID'].isin(dup)]\n",
    "\n",
    "# get first image from each identity and use it as reference\n",
    "identities = np.array(all_images.identityID.unique().tolist()).astype(object)\n",
    "file_end =  np.array('_0001.jpg'.split()*len(identities)).astype(object)\n",
    "first_images = identities + file_end\n",
    "\n",
    "references = all_images[all_images['File'].isin(first_images)]\n",
    "candidates = all_images[~all_images['File'].isin(first_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ResNet50 model architecture\n",
    "__all__ = ['ResNet', 'resnet50']\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=8631, include_top=True):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        if not self.include_top:\n",
    "            return x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load model, assign weights, send to device\n",
    "model_ft = resnet50()\n",
    "fname = 'weights/resnet50_ft_weight.pkl'\n",
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    weights = pickle.load(f, encoding='latin1')\n",
    "\n",
    "own_state = model_ft.state_dict()\n",
    "for name, param in weights.items():\n",
    "    if name in own_state:\n",
    "        try:\n",
    "            own_state[name].copy_(torch.from_numpy(param))\n",
    "        except Exception:\n",
    "            raise RuntimeError('While copying the parameter named {}, whose dimensions in the model are {} and whose '\\\n",
    "                                'dimensions in the checkpoint are {}.'.format(name, own_state[name].size(), param.shape))\n",
    "    else:\n",
    "        raise KeyError('unexpected key \"{}\" in state_dict'.format(name))\n",
    "model_ft = torch.nn.Sequential(*(list(model_ft.children())[:-1]))\n",
    "model_ft.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 10000 images\n",
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 10000 images\n",
      "processing: 15000 images\n",
      "processing: 20000 images\n",
      "processing: 25000 images\n"
     ]
    }
   ],
   "source": [
    "# create dataset class for RFW\n",
    "class resnetRFW(data.Dataset):\n",
    "    \n",
    "    '''\n",
    "    This will be a class to load data from RFW for resnet50 model\n",
    "    '''\n",
    "     \n",
    "    mean_bgr = np.array([91.4953, 103.8827, 131.0912])  # from resnet50_ft.prototxt\n",
    "\n",
    "    def __init__(self,img_path,img_df):\n",
    "        \"\"\"\n",
    "        :param img_path: dataset directory\n",
    "        :param img_df: contains image file names and other information\n",
    "        \"\"\"\n",
    "        assert os.path.exists(img_path), \"root: {} not found.\".format(img_path)\n",
    "        self.img_path = img_path\n",
    "        self.img_df = img_df\n",
    "        self.img_info = []\n",
    "\n",
    "        for i, row in self.img_df.iterrows():\n",
    "            self.img_info.append({\n",
    "                'img_file': row.Ethnicity + '/' + row.identityID + '/' + row.File,\n",
    "                'identityID': row.identityID,\n",
    "                'Ethnicity': row.Ethnicity,\n",
    "                'faceID': row.faceID,\n",
    "            })\n",
    "            if i % 5000 == 0:\n",
    "                print(\"processing: {} images\".format(i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_info)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        info = self.img_info[index]\n",
    "        img_file = info['img_file']\n",
    "        img = Image.open(os.path.join(self.img_path, img_file))\n",
    "        img = transforms.Resize(256)(img)\n",
    "        img = transforms.CenterCrop(224)(img)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        assert len(img.shape) == 3  # assumes color images and no alpha channel\n",
    "\n",
    "        Ethnicity = info['Ethnicity']\n",
    "        identityID = info['identityID']\n",
    "        faceID = info['faceID']\n",
    "        return self.transform(img), identityID, Ethnicity, faceID\n",
    "  \n",
    "\n",
    "    def transform(self, img):\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float32)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose(2, 0, 1)  # C x H x W\n",
    "        img = torch.from_numpy(img).float()\n",
    "        return img\n",
    "\n",
    "    def untransform(self, img, lbl):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        #img += self.mean_bgr\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        return img, lbl\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "# load reference images\n",
    "reference_dataset = resnetRFW(img_path,references.reset_index(drop=True))\n",
    "reference_loader = torch.utils.data.DataLoader(reference_dataset, batch_size=4, shuffle=False, **kwargs)\n",
    "# load candidate images\n",
    "candidate_dataset = resnetRFW(img_path,candidates.reset_index(drop=True))\n",
    "candidate_loader = torch.utils.data.DataLoader(candidate_dataset, batch_size=4, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model,dataloader,file_prefix,device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    identities = []\n",
    "    ethnicities = []\n",
    "    faceIDs = []\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(dataloader),total=len(dataloader)):\n",
    "            imgs = imgs.to(device)\n",
    "            x = model(imgs)\n",
    "            out = x.view(x.size(0),-1)\n",
    "            outputs.append(out)\n",
    "            identities.append(np.array(identityID))\n",
    "            ethnicities.append(np.array(Ethnicity))\n",
    "            faceIDs.append(np.array(faceID))\n",
    "\n",
    "    outputs=torch.cat(outputs)\n",
    "    identities= np.concatenate(np.array(identities)).ravel()\n",
    "    ethnicities= np.concatenate(np.array(ethnicities)).ravel()\n",
    "    faceIDs= np.concatenate(np.array(faceIDs)).ravel()\n",
    "\n",
    "    torch.save(outputs, file_prefix + '_outputs.pt')\n",
    "    np.save(file_prefix + '_identities.npy', identities)\n",
    "    np.save(file_prefix + '_ethnicities.npy', ethnicities)\n",
    "    np.save(file_prefix + '_faceIDs.npy', faceIDs)\n",
    "    return outputs, identities, ethnicities, faceIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfca54e77fa349e7b43a34c9d0e74a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2851 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reference_outputs, reference_identities, reference_ethnicities, reference_faceIDs = apply_model(model_ft,reference_loader,'outputs/RFW/ft/reference2',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97055abdf9d0411aa8b2ff3ead5967ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidate_outputs, candidate_identities, candidate_ethnicities, candidate_faceIDs = apply_model(model_ft,candidate_loader,'outputs/RFW/ft/candidate2',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2_coeff(A, B):\n",
    "    # Rowwise mean of input arrays & subtract from input arrays themeselves\n",
    "    A_mA = A - A.mean(1)[:, None]\n",
    "    B_mB = B - B.mean(1)[:, None]\n",
    "\n",
    "    # Sum of squares across rows\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "\n",
    "    # Finally get corr coeff\n",
    "    return torch.matmul(A_mA, B_mB.T) / torch.sqrt(torch.matmul(ssA[:, None],ssB[None]))\n",
    "def cos_sim(a, b, eps=1e-8):\n",
    "    \"\"\"\n",
    "    added eps for numerical stability\n",
    "    \"\"\"\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt\n",
    "\n",
    "cor = corr2_coeff(reference_outputs,candidate_outputs).cpu().detach().numpy()\n",
    "cos = cos_sim(reference_outputs,candidate_outputs).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ca943156c84e259e96fbd7a884bbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5add148aa1349afb105c3dc6442041d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ethnicity  accuracy\n",
      "0    African  0.496348\n",
      "1      Asian  0.530124\n",
      "2  Caucasian  0.633877\n",
      "3     Indian  0.625377\n",
      "   ethnicity  accuracy\n",
      "0    African  0.494455\n",
      "1      Asian  0.529428\n",
      "2  Caucasian  0.632771\n",
      "3     Indian  0.623184\n"
     ]
    }
   ],
   "source": [
    "# Face Identification\n",
    "\n",
    "'''\n",
    "here i want to do face identification\n",
    "basically take the outputs from the candidates and check against all references\n",
    "take the reference image that has highest correlation/similarity\n",
    "if the identities match then correct otherwise wrong\n",
    "'''\n",
    "\n",
    "cor_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor.T),total=len(cor.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cor_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cor_identification = cor_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos.T),total=len(cos.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cos_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cos_identification = cos_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cos_identification.candidate_ethnicity.unique():\n",
    "    eth_cos = cos_identification.loc[cos_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cos.match)/len(eth_cos)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cos_id_acc = cos_id_acc.append(row,ignore_index=True)\n",
    "print(cos_id_acc)\n",
    "\n",
    "cor_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cor_identification.candidate_ethnicity.unique():\n",
    "    eth_cor = cor_identification.loc[cor_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cor.match)/len(eth_cor)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cor_id_acc = cor_id_acc.append(row,ignore_index=True)\n",
    "print(cor_id_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608b29c4eb664707a05520022b5a4813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      reference_identity reference_ethnicity TP     TN FP FN  \\\n",
      "4              m.0p8s_gx             African  2  29115  0  0   \n",
      "17             m.047d6rm             African  2  29115  0  0   \n",
      "32              m.041x_3             African  3  29114  0  0   \n",
      "38              m.03dwmn             African  1  29116  0  0   \n",
      "57             m.02qvq8h             African  1  29116  0  0   \n",
      "...                  ...                 ... ..    ... .. ..   \n",
      "11374          m.03h654p              Indian  4  29113  0  0   \n",
      "11379           m.07pkcf              Indian  3  29114  0  0   \n",
      "11383          m.047t0lb              Indian  3  29114  0  0   \n",
      "11384           m.0cp4n7              Indian  6  29111  0  0   \n",
      "11391           m.0gxtsj              Indian  2  29115  0  0   \n",
      "\n",
      "                                                 matches  \\\n",
      "4                                 [m.0p8s_gx, m.0p8s_gx]   \n",
      "17                                [m.047d6rm, m.047d6rm]   \n",
      "32                        [m.041x_3, m.041x_3, m.041x_3]   \n",
      "38                                            [m.03dwmn]   \n",
      "57                                           [m.02qvq8h]   \n",
      "...                                                  ...   \n",
      "11374       [m.03h654p, m.03h654p, m.03h654p, m.03h654p]   \n",
      "11379                     [m.07pkcf, m.07pkcf, m.07pkcf]   \n",
      "11383                  [m.047t0lb, m.047t0lb, m.047t0lb]   \n",
      "11384  [m.0cp4n7, m.0cp4n7, m.0cp4n7, m.0cp4n7, m.0cp...   \n",
      "11391                               [m.0gxtsj, m.0gxtsj]   \n",
      "\n",
      "                                             not_matches  \n",
      "4      [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "17     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "32     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "38     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "57     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "...                                                  ...  \n",
      "11374  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11379  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11383  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11384  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11391  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "\n",
      "[1502 rows x 8 columns]\n",
      "reference_identity     m.0c7mh2m.026tq86m.02wz3ncm.0c012t4m.0p8s_gxm....\n",
      "reference_ethnicity    AfricanAfricanAfricanAfricanAfricanAfricanAfri...\n",
      "TP                                                                  2687\n",
      "TN                                                              86817900\n",
      "FP                                                                  1600\n",
      "FN                                                                  4707\n",
      "dtype: object\n",
      "reference_identity     m.0281bfhm.0421bfhm.02r80dqm.06w18lbm.02tcmtm....\n",
      "reference_ethnicity    AsianAsianAsianAsianAsianAsianAsianAsianAsianA...\n",
      "TP                                                                  2951\n",
      "TN                                                              72462768\n",
      "FP                                                                  2258\n",
      "FN                                                                  4236\n",
      "dtype: object\n",
      "reference_identity     m.05zdk2m.04064_hm.06414fsm.0dtsglm.02ww2f6m.0...\n",
      "reference_ethnicity    IndianIndianIndianIndianIndianIndianIndianIndi...\n",
      "TP                                                                  3381\n",
      "TN                                                              86585420\n",
      "FP                                                                  1240\n",
      "FN                                                                  3917\n",
      "dtype: object\n",
      "reference_identity     m.0cqh0qm.02r6ydbm.0415yw4m.049pq8m.03cdg6lm.0...\n",
      "reference_ethnicity    CaucasianCaucasianCaucasianCaucasianCaucasianC...\n",
      "TP                                                                  2450\n",
      "TN                                                              86120708\n",
      "FP                                                                   140\n",
      "FN                                                                  4788\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### face verification\n",
    "thresh = 0.65\n",
    "cos_verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity','TP','TN','FP','FN','matches','not_matches'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos),total=len(cos)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  matches = candidate_identities[cos_row>thresh]  \n",
    "  not_matches = candidate_identities[cos_row<=thresh]\n",
    "  TP = sum(matches == identity)\n",
    "  FP = sum(matches != identity)\n",
    "  TN = sum(not_matches != identity)\n",
    "  FN = sum(not_matches == identity)\n",
    "  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'TP': TP,\n",
    "           'TN': TN,\n",
    "           'FP': FP,\n",
    "           'FN': FN,\n",
    "           'matches': matches, \n",
    "           'not_matches': not_matches}\n",
    "  cos_verification = cos_verification.append(row,ignore_index=True)\n",
    "\n",
    "print(cos_verification[cos_verification.FN == 0][cos_verification.FP == 0])\n",
    "African_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'African']\n",
    "print(African_cos.sum(axis=0))\n",
    "Asian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Asian']\n",
    "print(Asian_cos.sum(axis=0))\n",
    "Indian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Indian']\n",
    "print(Indian_cos.sum(axis=0))\n",
    "Caucasian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Caucasian']\n",
    "print(Caucasian_cos.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76b4c272fe544e9965fa9ae80273be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      reference_identity reference_ethnicity TP     TN FP FN  \\\n",
      "9               m.0b49ph             African  2  29115  0  0   \n",
      "38              m.03dwmn             African  1  29116  0  0   \n",
      "56             m.064qbj5             African  3  29114  0  0   \n",
      "74              m.04_zbx             African  2  29115  0  0   \n",
      "76              m.0g5576             African  2  29115  0  0   \n",
      "...                  ...                 ... ..    ... .. ..   \n",
      "11299           m.08lj5b              Indian  1  29116  0  0   \n",
      "11341          m.026n0ps              Indian  1  29116  0  0   \n",
      "11349           m.0bfm55              Indian  3  29114  0  0   \n",
      "11353           m.0h19lp              Indian  2  29115  0  0   \n",
      "11379           m.07pkcf              Indian  3  29114  0  0   \n",
      "\n",
      "                                 matches  \\\n",
      "9                   [m.0b49ph, m.0b49ph]   \n",
      "38                            [m.03dwmn]   \n",
      "56     [m.064qbj5, m.064qbj5, m.064qbj5]   \n",
      "74                  [m.04_zbx, m.04_zbx]   \n",
      "76                  [m.0g5576, m.0g5576]   \n",
      "...                                  ...   \n",
      "11299                         [m.08lj5b]   \n",
      "11341                        [m.026n0ps]   \n",
      "11349     [m.0bfm55, m.0bfm55, m.0bfm55]   \n",
      "11353               [m.0h19lp, m.0h19lp]   \n",
      "11379     [m.07pkcf, m.07pkcf, m.07pkcf]   \n",
      "\n",
      "                                             not_matches  \n",
      "9      [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "38     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "56     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "74     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "76     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "...                                                  ...  \n",
      "11299  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11341  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11349  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11353  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "11379  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
      "\n",
      "[576 rows x 8 columns]\n",
      "reference_identity     m.0c7mh2m.026tq86m.02wz3ncm.0c012t4m.0p8s_gxm....\n",
      "reference_ethnicity    AfricanAfricanAfricanAfricanAfricanAfricanAfri...\n",
      "TP                                                                  2687\n",
      "TN                                                              86817900\n",
      "FP                                                                  1600\n",
      "FN                                                                  4707\n",
      "dtype: object\n",
      "reference_identity     m.0281bfhm.0421bfhm.02r80dqm.06w18lbm.02tcmtm....\n",
      "reference_ethnicity    AsianAsianAsianAsianAsianAsianAsianAsianAsianA...\n",
      "TP                                                                  2951\n",
      "TN                                                              72462768\n",
      "FP                                                                  2258\n",
      "FN                                                                  4236\n",
      "dtype: object\n",
      "reference_identity     m.05zdk2m.04064_hm.06414fsm.0dtsglm.02ww2f6m.0...\n",
      "reference_ethnicity    IndianIndianIndianIndianIndianIndianIndianIndi...\n",
      "TP                                                                  3381\n",
      "TN                                                              86585420\n",
      "FP                                                                  1240\n",
      "FN                                                                  3917\n",
      "dtype: object\n",
      "reference_identity     m.0cqh0qm.02r6ydbm.0415yw4m.049pq8m.03cdg6lm.0...\n",
      "reference_ethnicity    CaucasianCaucasianCaucasianCaucasianCaucasianC...\n",
      "TP                                                                  2450\n",
      "TN                                                              86120708\n",
      "FP                                                                   140\n",
      "FN                                                                  4788\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.65\n",
    "cor_verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity','TP','TN','FP','FN','matches','not_matches'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor),total=len(cor)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  matches = candidate_identities[cor_row>thresh]  \n",
    "  not_matches = candidate_identities[cor_row<=thresh]\n",
    "  TP = sum(matches == identity)\n",
    "  FP = sum(matches != identity)\n",
    "  TN = sum(not_matches != identity)\n",
    "  FN = sum(not_matches == identity)\n",
    "  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'TP': TP,\n",
    "           'TN': TN,\n",
    "           'FP': FP,\n",
    "           'FN': FN,\n",
    "           'matches': matches, \n",
    "           'not_matches': not_matches}\n",
    "  cor_verification = cor_verification.append(row,ignore_index=True)\n",
    "\n",
    "print(cor_verification[cor_verification.FN == 0][cor_verification.FP == 0])\n",
    "\n",
    "African_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'African']\n",
    "print(African_cos.sum(axis=0))\n",
    "Asian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Asian']\n",
    "print(Asian_cos.sum(axis=0))\n",
    "Indian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Indian']\n",
    "print(Indian_cos.sum(axis=0))\n",
    "Caucasian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Caucasian']\n",
    "print(Caucasian_cos.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2492"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asian_images.identityID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
