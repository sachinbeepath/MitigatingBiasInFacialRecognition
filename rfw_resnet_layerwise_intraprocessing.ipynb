{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import copy\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import math\n",
    "from skopt import gbrt_minimize\n",
    "from skopt.space import Real\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "print(device)\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29311</th>\n",
       "      <td>m.0402tg</td>\n",
       "      <td>m.01npnk3</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29312</th>\n",
       "      <td>m.05pbbnj</td>\n",
       "      <td>m.02rrb2n</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>m.09j6df</td>\n",
       "      <td>m.07kcsqd</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29314</th>\n",
       "      <td>m.0fhrbz</td>\n",
       "      <td>m.025zgjt</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29315</th>\n",
       "      <td>m.02q15tj</td>\n",
       "      <td>m.01w6m_0</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29316 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity candidate_identity reference_ethnicity  \\\n",
       "0               m.0c7mh2           m.0c7mh2             african   \n",
       "1               m.0c7mh2           m.0c7mh2             african   \n",
       "2              m.026tq86          m.026tq86             african   \n",
       "3              m.026tq86          m.026tq86             african   \n",
       "4              m.02wz3nc          m.02wz3nc             african   \n",
       "...                  ...                ...                 ...   \n",
       "29311           m.0402tg          m.01npnk3           caucasian   \n",
       "29312          m.05pbbnj          m.02rrb2n           caucasian   \n",
       "29313           m.09j6df          m.07kcsqd             african   \n",
       "29314           m.0fhrbz          m.025zgjt             african   \n",
       "29315          m.02q15tj          m.01w6m_0             african   \n",
       "\n",
       "      candidate_ethnicity  labels  \n",
       "0                 African     1.0  \n",
       "1                 African     1.0  \n",
       "2                 African     1.0  \n",
       "3                 African     1.0  \n",
       "4                 African     1.0  \n",
       "...                   ...     ...  \n",
       "29311           Caucasian     0.0  \n",
       "29312           Caucasian     0.0  \n",
       "29313             African     0.0  \n",
       "29314             African     0.0  \n",
       "29315             African     0.0  \n",
       "\n",
       "[29316 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data and split\n",
    "X = torch.load('inputs/rfw_resnet50_face_embeddings.pt').cpu()\n",
    "y = torch.load('inputs/rfw_resnet50_labels.pt').cpu()\n",
    "df = pd.read_csv('inputs/rfw_resnet50_df.csv')\n",
    "df['reference_ethnicity'] = df['reference_ethnicity'].str.lower()\n",
    "ethnicity = df['reference_ethnicity']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, test_split = train_test_split(np.arange(len(X)),test_size=0.2, random_state=random_state)\n",
    "train_split, val_split = train_test_split(train_split,test_size=0.25, random_state=random_state)\n",
    "X_train = X[train_split]\n",
    "X_val = X[val_split]\n",
    "X_test = X[test_split]\n",
    "y_train = y[train_split]\n",
    "y_val = y[val_split]\n",
    "y_test = y[test_split]\n",
    "\n",
    "ethnicity_train = ethnicity[train_split].values\n",
    "ethnicity_train[ethnicity_train=='caucasian'] = 0\n",
    "ethnicity_train[ethnicity_train=='african'] = 1\n",
    "ethnicity_train = ethnicity_train.astype(int)\n",
    "\n",
    "ethnicity_val = ethnicity[val_split].values\n",
    "ethnicity_val[ethnicity_val=='caucasian'] = 0\n",
    "ethnicity_val[ethnicity_val=='african'] = 1\n",
    "ethnicity_val = ethnicity_val.astype(int)\n",
    "\n",
    "ethnicity_test = ethnicity[test_split].values\n",
    "ethnicity_test[ethnicity_test=='caucasian'] = 0\n",
    "ethnicity_test[ethnicity_test=='african'] = 1\n",
    "ethnicity_test = ethnicity_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18904</th>\n",
       "      <td>m.0cx09_</td>\n",
       "      <td>m.02q_nsj</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28620</th>\n",
       "      <td>m.080gs5b</td>\n",
       "      <td>m.027w0nt</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11687</th>\n",
       "      <td>m.027q3qg</td>\n",
       "      <td>m.027q3qg</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>m.034s_j</td>\n",
       "      <td>m.03h3058</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12283</th>\n",
       "      <td>m.05p7_tb</td>\n",
       "      <td>m.05p7_tb</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18134</th>\n",
       "      <td>m.0hzpkcs</td>\n",
       "      <td>m.067fmb</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>m.05lnvt</td>\n",
       "      <td>m.05lnvt</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>m.01ndxh</td>\n",
       "      <td>m.01ndxh</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>m.0c2g8y</td>\n",
       "      <td>m.0c2g8y</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21112</th>\n",
       "      <td>m.05mgqb</td>\n",
       "      <td>m.04xb3k</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5864 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity candidate_identity reference_ethnicity  \\\n",
       "18904           m.0cx09_          m.02q_nsj           caucasian   \n",
       "28620          m.080gs5b          m.027w0nt             african   \n",
       "11687          m.027q3qg          m.027q3qg           caucasian   \n",
       "27477           m.034s_j          m.03h3058             african   \n",
       "12283          m.05p7_tb          m.05p7_tb           caucasian   \n",
       "...                  ...                ...                 ...   \n",
       "18134          m.0hzpkcs           m.067fmb           caucasian   \n",
       "3639            m.05lnvt           m.05lnvt             african   \n",
       "11091           m.01ndxh           m.01ndxh           caucasian   \n",
       "9369            m.0c2g8y           m.0c2g8y           caucasian   \n",
       "21112           m.05mgqb           m.04xb3k           caucasian   \n",
       "\n",
       "      candidate_ethnicity  labels  \n",
       "18904           Caucasian     0.0  \n",
       "28620             African     0.0  \n",
       "11687           Caucasian     1.0  \n",
       "27477             African     0.0  \n",
       "12283           Caucasian     1.0  \n",
       "...                   ...     ...  \n",
       "18134           Caucasian     0.0  \n",
       "3639              African     1.0  \n",
       "11091           Caucasian     1.0  \n",
       "9369            Caucasian     1.0  \n",
       "21112           Caucasian     0.0  \n",
       "\n",
       "[5864 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.iloc[train_split]\n",
    "val_df = df.iloc[val_split]\n",
    "test_df = df.iloc[test_split]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class TrainData(data.Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data,ethnicity):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.ethnicity = ethnicity    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index], self.ethnicity[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train),\n",
    "                       ethnicity_train)\n",
    "test_data = TrainData(torch.FloatTensor(X_test),torch.FloatTensor(y_test),ethnicity_test)\n",
    "val_data = TrainData(torch.FloatTensor(X_val), \n",
    "                       torch.FloatTensor(y_val),\n",
    "                       ethnicity_val)\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 4096\n",
    "        self.layer_1 = nn.Linear(4096, 1024) \n",
    "        self.layer_2 = nn.Linear(1024, 512)\n",
    "        self.layer_out = nn.Linear(512, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(1024)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def confusion_mat(y_pred, y_test):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    acc = (tn + tp)/(tn+tp+fn+fp)\n",
    "    return tn, fp, fn, tp, acc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "eps = 1e-5\n",
    "\n",
    "model = torch.load('weights/rfw_resnet50_logistic_regression_face_matching_0.0_betaTEST.pt')\n",
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE)\n",
    "val_loader = data.DataLoader(dataset=val_data, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_model(model, loader, criterion):\n",
    "    \"\"\"Validate model on loader with criterion function\"\"\"\n",
    "    y_true, y_pred, y_prot = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels,protected in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            y_true.append(labels)\n",
    "            y_prot.append(protected)\n",
    "            y_pred.append(torch.sigmoid(model(inputs)).cpu())\n",
    "    y_true, y_pred, y_prot = torch.cat(y_true), torch.cat(y_pred), torch.cat(y_prot)\n",
    "    return criterion(y_true, y_pred, y_prot)\n",
    "def compute_bias(y_pred, y_true, prot, metric):\n",
    "    \"\"\"Compute bias on the dataset\"\"\"\n",
    "    def zero_if_nan(data):\n",
    "        \"\"\"Zero if there is a nan\"\"\"\n",
    "        return 0. if torch.isnan(data) else data\n",
    "\n",
    "    gtpr_prot = zero_if_nan(y_pred[prot * y_true == 1].mean())\n",
    "    gfpr_prot = zero_if_nan(y_pred[prot * (1-y_true) == 1].mean())\n",
    "    mean_prot = zero_if_nan(y_pred[prot == 1].mean())\n",
    "\n",
    "    gtpr_unprot = zero_if_nan(y_pred[(1-prot) * y_true == 1].mean())\n",
    "    gfpr_unprot = zero_if_nan(y_pred[(1-prot) * (1-y_true) == 1].mean())\n",
    "    mean_unprot = zero_if_nan(y_pred[(1-prot) == 1].mean())\n",
    "\n",
    "    if metric == \"spd\":\n",
    "        return mean_prot - mean_unprot\n",
    "    elif metric == \"aod\":\n",
    "        return 0.5 * ((gfpr_prot - gfpr_unprot) + (gtpr_prot - gtpr_unprot))\n",
    "    elif metric == \"eod\":\n",
    "        return gtpr_prot - gtpr_unprot\n",
    "    elif 'false_diff':\n",
    "        return (np.abs(gfpr_prot - gfpr_unprot) + np.abs(gtpr_unprot - gtpr_prot))\n",
    "\n",
    "def compute_objective(performance, bias, epsilon=0.001, margin=0.0005):\n",
    "    if abs(bias) <= (epsilon-margin):\n",
    "        return performance\n",
    "    else:\n",
    "        return 0.0\n",
    "def get_best_objective(y_true, y_pred, y_prot):\n",
    "    \"\"\"Find the threshold for the best objective\"\"\"\n",
    "    num_samples = 5\n",
    "    threshs = torch.linspace(0, 1, 501)\n",
    "    best_obj, best_thresh = -math.inf, 0.\n",
    "    for thresh in threshs:\n",
    "        indices = np.random.choice(np.arange(y_pred.size()[0]), num_samples*y_pred.size()[0], replace=True).reshape(num_samples, y_pred.size()[0])\n",
    "        objs = []\n",
    "        for index in indices:\n",
    "            y_pred_tmp = y_pred[index]\n",
    "            y_true_tmp = y_true[index]\n",
    "            y_prot_tmp = y_prot[index]\n",
    "            perf = (torch.mean((y_pred_tmp > thresh)[y_true_tmp.type(torch.bool)].type(torch.float32)) + torch.mean((y_pred_tmp <= thresh)[~y_true_tmp.type(torch.bool)].type(torch.float32))) / 2\n",
    "            bias = compute_bias((y_pred_tmp > thresh).float().cpu(), y_true_tmp.float().cpu(), y_prot_tmp.float().cpu(), 'false_diff')\n",
    "            objs.append(compute_objective(perf, bias))\n",
    "        obj = float(torch.tensor(objs).mean())\n",
    "        if obj > best_obj:\n",
    "            best_obj, best_thresh = obj, thresh\n",
    "\n",
    "    return best_obj, best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0185)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bias before applying random processing\n",
    "y_true, y_pred, y_prot = [], [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels,protected in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        y_true.append(labels)\n",
    "        y_prot.append(protected)\n",
    "        y_pred.append(torch.sigmoid(model(inputs)).cpu())\n",
    "y_true, y_pred, y_prot = torch.cat(y_true), torch.cat(y_pred), torch.cat(y_prot)\n",
    "\n",
    "compute_bias((y_pred>0.5).float().cpu(), y_true, y_prot, 'false_diff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3766f90b7a44a269ae0ba147e1e9d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating param number 1 of 10\n",
      "Number of sparse indices: 5016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m space \u001b[39m=\u001b[39m [Real(\u001b[39mfloat\u001b[39m(x\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()) \u001b[39m-\u001b[39m \u001b[39m2.2\u001b[39m\u001b[39m*\u001b[39mstd\u001b[39m-\u001b[39meps, \u001b[39mfloat\u001b[39m(x\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()) \u001b[39m+\u001b[39m \u001b[39m2.2\u001b[39m\u001b[39m*\u001b[39mstd) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m param\u001b[39m.\u001b[39mcpu()[indices]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of sparse indices: \u001b[39m\u001b[39m{\u001b[39;00mindices\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m res_gbrt \u001b[39m=\u001b[39m gbrt_minimize(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     objective,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     space,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     n_calls\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mif\u001b[39;00m res_gbrt\u001b[39m.\u001b[39mfun \u001b[39m<\u001b[39m best_obj:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     param\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdata[indices] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(res_gbrt\u001b[39m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/skopt/optimizer/gbrt.py:179\u001b[0m, in \u001b[0;36mgbrt_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m base_estimator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     base_estimator \u001b[39m=\u001b[39m cook_estimator(\u001b[39m\"\u001b[39m\u001b[39mGBRT\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39mrng,\n\u001b[1;32m    178\u001b[0m                                     n_jobs\u001b[39m=\u001b[39mn_jobs)\n\u001b[0;32m--> 179\u001b[0m \u001b[39mreturn\u001b[39;00m base_minimize(func, dimensions, base_estimator,\n\u001b[1;32m    180\u001b[0m                      n_calls\u001b[39m=\u001b[39;49mn_calls, n_points\u001b[39m=\u001b[39;49mn_points,\n\u001b[1;32m    181\u001b[0m                      n_random_starts\u001b[39m=\u001b[39;49mn_random_starts,\n\u001b[1;32m    182\u001b[0m                      n_initial_points\u001b[39m=\u001b[39;49mn_initial_points,\n\u001b[1;32m    183\u001b[0m                      initial_point_generator\u001b[39m=\u001b[39;49minitial_point_generator,\n\u001b[1;32m    184\u001b[0m                      x0\u001b[39m=\u001b[39;49mx0, y0\u001b[39m=\u001b[39;49my0, random_state\u001b[39m=\u001b[39;49mrandom_state, xi\u001b[39m=\u001b[39;49mxi,\n\u001b[1;32m    185\u001b[0m                      kappa\u001b[39m=\u001b[39;49mkappa, acq_func\u001b[39m=\u001b[39;49macq_func, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    186\u001b[0m                      callback\u001b[39m=\u001b[39;49mcallback, acq_optimizer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msampling\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    187\u001b[0m                      model_queue_size\u001b[39m=\u001b[39;49mmodel_queue_size)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/skopt/optimizer/base.py:299\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_calls):\n\u001b[1;32m    298\u001b[0m     next_x \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mask()\n\u001b[0;32m--> 299\u001b[0m     next_y \u001b[39m=\u001b[39m func(next_x)\n\u001b[1;32m    300\u001b[0m     result \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    301\u001b[0m     result\u001b[39m.\u001b[39mspecs \u001b[39m=\u001b[39m specs\n",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb Cell 9\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(new_param)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m param\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdata[indices] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(new_param)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m base_model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m best_obj, thresh \u001b[39m=\u001b[39m val_model(base_model, val_loader, get_best_objective)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# print(f'Evaluating param number {index} of {total_params}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mfloat\u001b[39m(best_obj)\n",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb Cell 9\u001b[0m in \u001b[0;36mval_model\u001b[0;34m(model, loader, criterion)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, labels,protected \u001b[39min\u001b[39;00m loader:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         y_true\u001b[39m.\u001b[39mappend(labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_resnet_layerwise_intraprocessing.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         y_prot\u001b[39m.\u001b[39mappend(protected)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model = copy.deepcopy(model)\n",
    "best_state_dict, best_thresh, best_obj = None, None, np.inf\n",
    "num_layers = 10\n",
    "max_sparsity = 5000\n",
    "total_params = len(list(base_model.parameters()))\n",
    "for index, param in tqdm_notebook(enumerate(base_model.parameters()),total=total_params):\n",
    "    # if index < num_layers:\n",
    "    #     continue\n",
    "    print(f'Evaluating param number {index+1} of {total_params}')\n",
    "    param_copy = copy.deepcopy(param)\n",
    "\n",
    "    def objective(new_param):\n",
    "        param.cpu().data[indices] = torch.tensor(new_param)\n",
    "        base_model.eval()\n",
    "        best_obj, thresh = val_model(base_model, val_loader, get_best_objective)\n",
    "        # print(f'Evaluating param number {index} of {total_params}')\n",
    "        return -float(best_obj)\n",
    "\n",
    "    std = param.flatten().cpu().detach().numpy().std()\n",
    "    num_elems = param.size().numel()\n",
    "    ratio = min(1., max_sparsity/ num_elems)\n",
    "    indices = torch.rand(param.size()) < ratio\n",
    "    space = [Real(float(x.cpu().detach()) - 2.2*std-eps, float(x.cpu().detach()) + 2.2*std) for x in param.cpu()[indices]]\n",
    "    print(f'Number of sparse indices: {indices.sum().item()}')\n",
    "    res_gbrt = gbrt_minimize(\n",
    "        objective,\n",
    "        space,\n",
    "        n_calls=20,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if res_gbrt.fun < best_obj:\n",
    "        param.cpu().data[indices] = torch.tensor(res_gbrt.x)\n",
    "        best_state_dict = copy.deepcopy(base_model.state_dict())\n",
    "        best_obj, best_thresh = val_model(base_model, val_loader, get_best_objective)\n",
    "    param.data = param_copy.data\n",
    "\n",
    "best_model = copy.deepcopy(model)\n",
    "best_model.load_state_dict(best_state_dict)\n",
    "best_model.to(device)\n",
    "\n",
    "y_true, y_pred, y_prot = [], [], []\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels,protected in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        y_true.append(labels)\n",
    "        y_prot.append(protected)\n",
    "        y_pred.append(torch.sigmoid(best_model(inputs)).cpu())\n",
    "y_true, y_pred, y_prot = torch.cat(y_true), torch.cat(y_pred), torch.cat(y_prot)\n",
    "compute_bias((y_pred>best_thresh).float().cpu(), y_true, y_prot, 'false_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
