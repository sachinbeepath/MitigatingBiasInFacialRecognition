{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from aif360.algorithms.postprocessing import (CalibratedEqOddsPostprocessing, EqOddsPostprocessing,RejectOptionClassification)\n",
    "from aif360.datasets import StandardDataset\n",
    "from torchvision import models,transforms\n",
    "import pickle\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "AvgPool2d(kernel_size=7, stride=1, padding=0)\n"
     ]
    }
   ],
   "source": [
    "# load resnet50 model and modify it to match the one from the github to load the weights from the pkl\n",
    "# resnet50 trained on VGGFace2\n",
    "resnet50 = models.resnet50(pretrained=False)\n",
    "print(resnet50.maxpool)\n",
    "resnet50.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
    "print(resnet50.maxpool)\n",
    "print(resnet50.layer2[0].conv1)\n",
    "resnet50.layer2[0].conv1 = nn.Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "print(resnet50.layer2[0].conv1)\n",
    "print(resnet50.layer2[0].conv2)\n",
    "resnet50.layer2[0].conv2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "print(resnet50.layer2[0].conv2)\n",
    "print(resnet50.layer3[0].conv1)\n",
    "resnet50.layer3[0].conv1 = nn.Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "print(resnet50.layer3[0].conv1)\n",
    "print(resnet50.layer3[0].conv2)\n",
    "resnet50.layer3[0].conv2 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "print(resnet50.layer3[0].conv2)\n",
    "print(resnet50.layer4[0].conv1)\n",
    "resnet50.layer4[0].conv1 = nn.Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "print(resnet50.layer4[0].conv1)\n",
    "print(resnet50.layer4[0].conv2)\n",
    "resnet50.layer4[0].conv2 = nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "print(resnet50.layer4[0].conv2)\n",
    "print(resnet50.avgpool)\n",
    "resnet50.avgpool = nn.AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
    "print(resnet50.avgpool)\n",
    "resnet50.fc = nn.Linear(in_features=2048,out_features=8631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights from pickle and load state dict into model\n",
    "with open(\"weights/resnet50_scratch_weight.pkl\", 'rb') as f:\n",
    "        weights = pickle.load(f, encoding='latin1')\n",
    "def f(x):\n",
    "    return torch.from_numpy(x)\n",
    "weights = dict(map(lambda x: (x[0], f(x[1])), weights.items()))\n",
    "weights = OrderedDict(weights)\n",
    "resnet50.load_state_dict(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dissEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ab01ac27ec76bffb5c2aa0a183c02b22b22d6a3289db72f56ae87ad680cea4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
