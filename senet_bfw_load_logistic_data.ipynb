{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import models,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import collections\n",
    "from  PIL import Image\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "from itertools import product\n",
    "import senet50\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = senet50.make_model()\n",
    "fname = 'weights/senet50_ft_weight.pkl'\n",
    "with open(fname, 'rb') as f:\n",
    "    weights = pickle.load(f, encoding='latin1')\n",
    "\n",
    "own_state = model_scratch.state_dict()\n",
    "for name, param in weights.items():\n",
    "    if name in own_state:\n",
    "        try:\n",
    "            own_state[name].copy_(torch.from_numpy(param))\n",
    "        except Exception:\n",
    "            raise RuntimeError('While copying the parameter named {}, whose dimensions in the model are {} and whose '\\\n",
    "                                'dimensions in the checkpoint are {}.'.format(name, own_state[name].size(), param.shape))\n",
    "    else:\n",
    "        raise KeyError('unexpected key \"{}\" in state_dict'.format(name))\n",
    "model_scratch = model_scratch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data \n",
    "# create df to contain all identities, their image file names, their ethnicities\n",
    "n = 24\n",
    "img_path = 'data/BFW/CROPPED_ALIGNED'\n",
    "# asian female\n",
    "asian_female_identities = np.array(next(os.walk(img_path+'/asian_females'))[1])\n",
    "asian_female_files = np.array([])\n",
    "asian_female_references = []\n",
    "for identity in asian_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/asian_females/'+identity))[2])\n",
    "    x = img_path+'/asian_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    asian_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    asian_female_files = np.concatenate((asian_female_files,files))\n",
    "asian_female_candidates = pd.DataFrame(asian_female_files,columns =['file'])\n",
    "asian_female_candidates['ethnicity'] = 'asian'\n",
    "asian_female_candidates['gender'] = 'female'\n",
    "asian_female_candidates['identity'] = np.repeat(asian_female_identities,n)\n",
    "\n",
    "asian_female_references = pd.DataFrame(asian_female_references,columns =['file'])\n",
    "asian_female_references['ethnicity'] = 'asian'\n",
    "asian_female_references['gender'] = 'female'\n",
    "asian_female_references['identity'] = asian_female_identities\n",
    "\n",
    "# black females\n",
    "black_female_identities = np.array(next(os.walk(img_path+'/black_females'))[1])\n",
    "black_female_files = np.array([])\n",
    "black_female_references = []\n",
    "for identity in black_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/black_females/'+identity))[2])\n",
    "    x = img_path+'/black_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    black_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    black_female_files = np.concatenate((black_female_files,files))\n",
    "black_female_candidates = pd.DataFrame(black_female_files,columns =['file'])\n",
    "black_female_candidates['ethnicity'] = 'black'\n",
    "black_female_candidates['gender'] = 'female'\n",
    "black_female_candidates['identity'] = np.repeat(black_female_identities,n)\n",
    "\n",
    "\n",
    "black_female_references = pd.DataFrame(black_female_references,columns =['file'])\n",
    "black_female_references['ethnicity'] = 'black'\n",
    "black_female_references['gender'] = 'female'\n",
    "black_female_references['identity'] = black_female_identities\n",
    "\n",
    "# indian females\n",
    "indian_female_identities = np.array(next(os.walk(img_path+'/indian_females'))[1])\n",
    "indian_female_files = np.array([])\n",
    "indian_female_references = []\n",
    "for identity in indian_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/indian_females/'+identity))[2])\n",
    "    x = img_path+'/indian_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    indian_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    indian_female_files = np.concatenate((indian_female_files,files))\n",
    "indian_female_candidates = pd.DataFrame(indian_female_files,columns =['file'])\n",
    "indian_female_candidates['ethnicity'] = 'indian'\n",
    "indian_female_candidates['gender'] = 'female'\n",
    "indian_female_candidates['identity'] = np.repeat(indian_female_identities,n)\n",
    "\n",
    "\n",
    "indian_female_references = pd.DataFrame(indian_female_references,columns =['file'])\n",
    "indian_female_references['ethnicity'] = 'indian'\n",
    "indian_female_references['gender'] = 'female'\n",
    "indian_female_references['identity'] = indian_female_identities\n",
    "\n",
    "# white females\n",
    "white_female_identities = np.array(next(os.walk(img_path+'/white_females'))[1])\n",
    "white_female_files = np.array([])\n",
    "white_female_references = []\n",
    "for identity in white_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/white_females/'+identity))[2])\n",
    "    x = img_path+'/white_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    white_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    white_female_files = np.concatenate((white_female_files,files))\n",
    "white_female_candidates = pd.DataFrame(white_female_files,columns =['file'])\n",
    "white_female_candidates['ethnicity'] = 'white'\n",
    "white_female_candidates['gender'] = 'female'\n",
    "white_female_candidates['identity'] = np.repeat(white_female_identities,n)\n",
    "\n",
    "\n",
    "white_female_references = pd.DataFrame(white_female_references,columns =['file'])\n",
    "white_female_references['ethnicity'] = 'white'\n",
    "white_female_references['gender'] = 'female'\n",
    "white_female_references['identity'] = white_female_identities\n",
    "\n",
    "\n",
    "# asian males\n",
    "asian_male_identities = np.array(next(os.walk(img_path+'/asian_males'))[1])\n",
    "asian_male_files = np.array([])\n",
    "asian_male_references = []\n",
    "for identity in asian_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/asian_males/'+identity))[2])\n",
    "    x = img_path+'/asian_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    asian_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    asian_male_files = np.concatenate((asian_male_files,files))\n",
    "asian_male_candidates = pd.DataFrame(asian_male_files,columns =['file'])\n",
    "asian_male_candidates['ethnicity'] = 'asian'\n",
    "asian_male_candidates['gender'] = 'male'\n",
    "asian_male_candidates['identity'] = np.repeat(asian_male_identities,n)\n",
    "\n",
    "asian_male_references = pd.DataFrame(asian_male_references,columns =['file'])\n",
    "asian_male_references['ethnicity'] = 'asian'\n",
    "asian_male_references['gender'] = 'male'\n",
    "asian_male_references['identity'] = asian_male_identities\n",
    "\n",
    "# black males\n",
    "black_male_identities = np.array(next(os.walk(img_path+'/black_males'))[1])\n",
    "black_male_files = np.array([])\n",
    "black_male_references = []\n",
    "for identity in black_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/black_males/'+identity))[2])\n",
    "    x = img_path+'/black_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    black_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    black_male_files = np.concatenate((black_male_files,files))\n",
    "black_male_candidates = pd.DataFrame(black_male_files,columns =['file'])\n",
    "black_male_candidates['ethnicity'] = 'black'\n",
    "black_male_candidates['gender'] = 'male'\n",
    "black_male_candidates['identity'] = np.repeat(black_male_identities,n)\n",
    "\n",
    "\n",
    "black_male_references = pd.DataFrame(black_male_references,columns =['file'])\n",
    "black_male_references['ethnicity'] = 'black'\n",
    "black_male_references['gender'] = 'male'\n",
    "black_male_references['identity'] = black_male_identities\n",
    "\n",
    "# indian males\n",
    "indian_male_identities = np.array(next(os.walk(img_path+'/indian_males'))[1])\n",
    "indian_male_files = np.array([])\n",
    "indian_male_references = []\n",
    "for identity in indian_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/indian_males/'+identity))[2])\n",
    "    x = img_path+'/indian_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    indian_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    indian_male_files = np.concatenate((indian_male_files,files))\n",
    "indian_male_candidates = pd.DataFrame(indian_male_files,columns =['file'])\n",
    "indian_male_candidates['ethnicity'] = 'indian'\n",
    "indian_male_candidates['gender'] = 'male'\n",
    "indian_male_candidates['identity'] = np.repeat(indian_male_identities,n)\n",
    "\n",
    "\n",
    "indian_male_references = pd.DataFrame(indian_male_references,columns =['file'])\n",
    "indian_male_references['ethnicity'] = 'indian'\n",
    "indian_male_references['gender'] = 'male'\n",
    "indian_male_references['identity'] = indian_male_identities\n",
    "\n",
    "# white males\n",
    "white_male_identities = np.array(next(os.walk(img_path+'/white_males'))[1])\n",
    "white_male_files = np.array([])\n",
    "white_male_references = []\n",
    "for identity in white_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/white_males/'+identity))[2])\n",
    "    x = img_path+'/white_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    white_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    white_male_files = np.concatenate((white_male_files,files))\n",
    "white_male_candidates = pd.DataFrame(white_male_files,columns =['file'])\n",
    "white_male_candidates['ethnicity'] = 'white'\n",
    "white_male_candidates['gender'] = 'male'\n",
    "white_male_candidates['identity'] = np.repeat(white_male_identities,n)\n",
    "\n",
    "\n",
    "white_male_references = pd.DataFrame(white_male_references,columns =['file'])\n",
    "white_male_references['ethnicity'] = 'white'\n",
    "white_male_references['gender'] = 'male'\n",
    "white_male_references['identity'] = white_male_identities\n",
    "\n",
    "# all ethnicity\n",
    "asian_references = pd.concat([asian_male_references,asian_female_references],ignore_index=True)\n",
    "black_references = pd.concat([black_male_references,black_female_references],ignore_index=True)\n",
    "indian_references = pd.concat([indian_male_references,indian_female_references],ignore_index=True)\n",
    "white_references = pd.concat([white_male_references,white_female_references],ignore_index=True)\n",
    "female_references = pd.concat([asian_female_references,black_female_references,indian_female_references,white_female_references],ignore_index=True)\n",
    "male_references = pd.concat([asian_male_references,black_male_references,indian_male_references,white_male_references],ignore_index=True)\n",
    "references = pd.concat([male_references,female_references],ignore_index=True)\n",
    "\n",
    "asian_candidates = pd.concat([asian_male_candidates,asian_female_candidates],ignore_index=True)\n",
    "black_candidates = pd.concat([black_male_candidates,black_female_candidates],ignore_index=True)\n",
    "indian_candidates = pd.concat([indian_male_candidates,indian_female_candidates],ignore_index=True)\n",
    "white_candidates = pd.concat([white_male_candidates,white_female_candidates],ignore_index=True)\n",
    "female_candidates = pd.concat([asian_female_candidates,black_female_candidates,indian_female_candidates,white_female_candidates],ignore_index=True)\n",
    "male_candidates = pd.concat([asian_male_candidates,black_male_candidates,indian_male_candidates,white_male_candidates],ignore_index=True)\n",
    "candidates = pd.concat([male_candidates,female_candidates],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFW_dataset(data.Dataset):\n",
    "    '''\n",
    "    This class loads data from dataframes containing images from BFW\n",
    "    '''\n",
    "    # mean_bgr = np.array([91.4953, 103.8827, 131.0912])  # from senet50_ft.prototxt\n",
    "    mean_bgr = np.array([93.5940, 104.7624, 129.1863])  # from senet50_scratch.prototxt\n",
    "\n",
    "    def __init__(self,img_df):\n",
    "        \"\"\"\n",
    "        :param img_path: dataset directory\n",
    "        :param img_df: contains image file names and other information\n",
    "        \"\"\"\n",
    "        assert os.path.exists(img_path), \"root: {} not found.\".format(img_path)\n",
    "        self.img_df = img_df\n",
    "        self.img_info = []\n",
    "\n",
    "        for i, row in self.img_df.iterrows():\n",
    "            self.img_info.append({\n",
    "                'img_file': row.file,\n",
    "                'identity': row.identity,\n",
    "                'ethnicity': row.ethnicity,\n",
    "                'gender': row.gender,\n",
    "            })\n",
    "            if i % 1000 == 0:\n",
    "                print(\"processing: {} images\".format(i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_info)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        info = self.img_info[index]\n",
    "        img_file = info['img_file']\n",
    "        img = Image.open(img_file)\n",
    "        img = transforms.Resize(256)(img)\n",
    "        img = transforms.CenterCrop(224)(img)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        assert len(img.shape) == 3  # assumes color images and no alpha channel\n",
    "\n",
    "        ethnicity = info['ethnicity']\n",
    "        identity = info['identity']\n",
    "        gender = info['gender']\n",
    "        return self.transform(img), identity, ethnicity, gender\n",
    "  \n",
    "    def transform(self, img):\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float32)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose(2, 0, 1)  # C x H x W\n",
    "        img = torch.from_numpy(img).float()\n",
    "        return img\n",
    "\n",
    "    def untransform(self, img, lbl):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        #img += self.mean_bgr\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        return img, lbl\n",
    "        \n",
    "def apply_model(model,dataloader,device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    identities = []\n",
    "    ethnicities = []\n",
    "    genders = []\n",
    "    with torch.no_grad():\n",
    "        for _, (imgs, identityID, ethnicity, gender) in tqdm_notebook(enumerate(dataloader),total=len(dataloader)):\n",
    "            imgs = imgs.to(device)\n",
    "            x = model(imgs)\n",
    "            out = x.view(x.size(0),-1)\n",
    "            outputs.append(out)\n",
    "            identities.append(np.array(identityID))\n",
    "            ethnicities.append(np.array(ethnicity))\n",
    "            genders.append(np.array(gender))\n",
    "\n",
    "    outputs=torch.cat(outputs)\n",
    "    identities= np.concatenate(np.array(identities)).ravel()\n",
    "    ethnicities= np.concatenate(np.array(ethnicities)).ravel()\n",
    "    genders= np.concatenate(np.array(genders)).ravel()\n",
    "\n",
    "    # torch.save(outputs, file_prefix + '_outputs.pt')\n",
    "    # np.save(file_prefix + '_identities.npy', identities)\n",
    "    # np.save(file_prefix + '_ethnicities.npy', ethnicities)\n",
    "    # np.save(file_prefix + '_faceIDs.npy', genders)\n",
    "    return outputs, identities, ethnicities, genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 0 images\n",
      "processing: 0 images\n",
      "processing: 1000 images\n",
      "processing: 2000 images\n",
      "processing: 3000 images\n",
      "processing: 4000 images\n",
      "processing: 5000 images\n",
      "processing: 6000 images\n",
      "processing: 7000 images\n",
      "processing: 8000 images\n",
      "processing: 9000 images\n",
      "processing: 10000 images\n",
      "processing: 11000 images\n",
      "processing: 12000 images\n",
      "processing: 13000 images\n",
      "processing: 14000 images\n",
      "processing: 15000 images\n",
      "processing: 16000 images\n",
      "processing: 17000 images\n",
      "processing: 18000 images\n",
      "processing: 19000 images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de4b26106ee4985b615973887bd0c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6058e347e449908a535670380712a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load reference images\n",
    "reference_dataset = BFW_dataset(references.reset_index(drop=True))\n",
    "reference_loader = torch.utils.data.DataLoader(reference_dataset, batch_size=4, shuffle=False)#, **kwargs)\n",
    "\n",
    "candidate_dataset = BFW_dataset(candidates.reset_index(drop=True))\n",
    "candidate_loader = torch.utils.data.DataLoader(candidate_dataset, batch_size=4, shuffle=False)#, **kwargs)\n",
    "\n",
    "\n",
    "reference_outputs, reference_identities, reference_ethnicities, reference_genders = apply_model(model_scratch,reference_loader,device)\n",
    "candidate_outputs, candidate_identities, candidate_ethnicities, candidate_genders = apply_model(model_scratch,candidate_loader,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs</th>\n",
       "      <th>identity</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.389668, 0.0034971081, 0.001645086, 6.863606...</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.008046066, 6.0874624, 0.18496192, 4.87325, ...</td>\n",
       "      <td>n003355</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7.8066754, 0.3295099, 0.030479558, 2.3926117,...</td>\n",
       "      <td>n003167</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.8476263, 0.0034392818, 0.0050945044, 0.0025...</td>\n",
       "      <td>n009037</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3.0760949, 0.006605825, 0.118142106, 0.513239...</td>\n",
       "      <td>n003156</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>[0.03098317, 0.5413279, 0.07278461, 0.58929145...</td>\n",
       "      <td>n005887</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>[1.1820213, 0.5093816, 0.00026345663, 3.235255...</td>\n",
       "      <td>n008333</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>[0.00084624346, 2.2345731, 0.8576557, 0.480147...</td>\n",
       "      <td>n009241</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>[4.747732, 0.09120478, 0.0019000388, 1.2522712...</td>\n",
       "      <td>n004901</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>[1.3949747, 0.003622235, 7.03336, 0.055739466,...</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               outputs identity ethnicity  \\\n",
       "0    [2.389668, 0.0034971081, 0.001645086, 6.863606...  n004721     asian   \n",
       "1    [0.008046066, 6.0874624, 0.18496192, 4.87325, ...  n003355     asian   \n",
       "2    [7.8066754, 0.3295099, 0.030479558, 2.3926117,...  n003167     asian   \n",
       "3    [1.8476263, 0.0034392818, 0.0050945044, 0.0025...  n009037     asian   \n",
       "4    [3.0760949, 0.006605825, 0.118142106, 0.513239...  n003156     asian   \n",
       "..                                                 ...      ...       ...   \n",
       "795  [0.03098317, 0.5413279, 0.07278461, 0.58929145...  n005887     white   \n",
       "796  [1.1820213, 0.5093816, 0.00026345663, 3.235255...  n008333     white   \n",
       "797  [0.00084624346, 2.2345731, 0.8576557, 0.480147...  n009241     white   \n",
       "798  [4.747732, 0.09120478, 0.0019000388, 1.2522712...  n004901     white   \n",
       "799  [1.3949747, 0.003622235, 7.03336, 0.055739466,...  n005218     white   \n",
       "\n",
       "     gender  \n",
       "0      male  \n",
       "1      male  \n",
       "2      male  \n",
       "3      male  \n",
       "4      male  \n",
       "..      ...  \n",
       "795  female  \n",
       "796  female  \n",
       "797  female  \n",
       "798  female  \n",
       "799  female  \n",
       "\n",
       "[800 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_outputs_list = []\n",
    "for output in reference_outputs.cpu().numpy():\n",
    "    reference_outputs_list.append(output)\n",
    "candidate_outputs_list = []\n",
    "for output in candidate_outputs.cpu().numpy():\n",
    "    candidate_outputs_list.append(output)\n",
    "output_references = {'outputs': reference_outputs_list, 'identity': reference_identities,'ethnicity': reference_ethnicities, 'gender': reference_genders}\n",
    "output_references = pd.DataFrame(output_references)\n",
    "\n",
    "output_candidates = {'outputs': candidate_outputs_list, 'identity': candidate_identities,'ethnicity': candidate_ethnicities, 'gender': candidate_genders}\n",
    "output_candidates = pd.DataFrame(output_candidates)\n",
    "output_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>reference_gender</th>\n",
       "      <th>candidate_gender</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359995</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359996</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359997</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359998</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359999</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15360000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reference_identity candidate_identity reference_ethnicity  \\\n",
       "0                   n004721            n004721               asian   \n",
       "1                   n004721            n004721               asian   \n",
       "2                   n004721            n004721               asian   \n",
       "3                   n004721            n004721               asian   \n",
       "4                   n004721            n004721               asian   \n",
       "...                     ...                ...                 ...   \n",
       "15359995            n005218            n005218               white   \n",
       "15359996            n005218            n005218               white   \n",
       "15359997            n005218            n005218               white   \n",
       "15359998            n005218            n005218               white   \n",
       "15359999            n005218            n005218               white   \n",
       "\n",
       "         candidate_ethnicity reference_gender candidate_gender  labels  \n",
       "0                      asian             male             male       1  \n",
       "1                      asian             male             male       1  \n",
       "2                      asian             male             male       1  \n",
       "3                      asian             male             male       1  \n",
       "4                      asian             male             male       1  \n",
       "...                      ...              ...              ...     ...  \n",
       "15359995               white           female           female       1  \n",
       "15359996               white           female           female       1  \n",
       "15359997               white           female           female       1  \n",
       "15359998               white           female           female       1  \n",
       "15359999               white           female           female       1  \n",
       "\n",
       "[15360000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.array(list(product(output_references['identity'], output_candidates['identity'])))\n",
    "# labels = (ids[:,0] == ids[:,1])*1\n",
    "ethnicities = np.array(list(product(output_references['ethnicity'], output_candidates['ethnicity'])))\n",
    "genders = np.array(list(product(output_references['gender'], output_candidates['gender'])))\n",
    "\n",
    "logistic_df = { \n",
    "                'reference_identity': ids[:,0],'candidate_identity': ids[:,1],\n",
    "                'reference_ethnicity': ethnicities[:,0],'candidate_ethnicity': ethnicities[:,1], \n",
    "                'reference_gender': genders[:,0],'candidate_gender': genders[:,1]}\n",
    "\n",
    "\n",
    "logistic_df = pd.DataFrame(logistic_df)\n",
    "logistic_df['labels']=(logistic_df.reference_identity == logistic_df.candidate_identity )*1\n",
    "\n",
    "\n",
    "logistic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>reference_gender</th>\n",
       "      <th>candidate_gender</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359995</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359996</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359997</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359998</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15359999</th>\n",
       "      <td>n005218</td>\n",
       "      <td>n005218</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7680000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reference_identity candidate_identity reference_ethnicity  \\\n",
       "0                   n004721            n004721               asian   \n",
       "1                   n004721            n004721               asian   \n",
       "2                   n004721            n004721               asian   \n",
       "3                   n004721            n004721               asian   \n",
       "4                   n004721            n004721               asian   \n",
       "...                     ...                ...                 ...   \n",
       "15359995            n005218            n005218               white   \n",
       "15359996            n005218            n005218               white   \n",
       "15359997            n005218            n005218               white   \n",
       "15359998            n005218            n005218               white   \n",
       "15359999            n005218            n005218               white   \n",
       "\n",
       "         candidate_ethnicity reference_gender candidate_gender  labels  \n",
       "0                      asian             male             male       1  \n",
       "1                      asian             male             male       1  \n",
       "2                      asian             male             male       1  \n",
       "3                      asian             male             male       1  \n",
       "4                      asian             male             male       1  \n",
       "...                      ...              ...              ...     ...  \n",
       "15359995               white           female           female       1  \n",
       "15359996               white           female           female       1  \n",
       "15359997               white           female           female       1  \n",
       "15359998               white           female           female       1  \n",
       "15359999               white           female           female       1  \n",
       "\n",
       "[7680000 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic_df2 = logistic_df[(logistic_df['reference_ethnicity']==logistic_df['candidate_ethnicity'] )]\n",
    "logistic_df2 = logistic_df[(logistic_df['reference_gender']==logistic_df['candidate_gender'] )]\n",
    "logistic_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7660800\n",
       "1      19200\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels= logistic_df2.labels\n",
    "logistic_df2.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5526834 3665458 7491418 ... 3813658 4321071 7662193]\n"
     ]
    }
   ],
   "source": [
    "match_idx = np.where(labels==1)[0]\n",
    "not_match_idx = np.where(labels==0)[0]\n",
    "np.random.seed(random_state)\n",
    "not_match_idx_sub  = not_match_idx[np.random.choice(len(not_match_idx), size=len(match_idx), replace=False)]\n",
    "print((not_match_idx_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_1 = np.arange(reference_outputs.shape[0])\n",
    "array_2 = np.arange(candidate_outputs.shape[0])\n",
    "mesh = np.array(np.meshgrid(array_1, array_2))\n",
    "combinations = mesh.T.reshape(-1, 2)\n",
    "combinations = combinations[logistic_df2.index.values]\n",
    "combinations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6090f8335dbe40d2b75bd78da139917a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26f136d3c054a479ab89d24b94787ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9ee8a450d14900b2b56cc34502bd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf2b5eec0734a4db38ed602a2e900a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "match_pairs = combinations[match_idx]\n",
    "not_match_pairs = combinations[not_match_idx_sub]\n",
    "\n",
    "match_list = []\n",
    "for _,pairs in tqdm_notebook(enumerate(match_pairs),total=len(match_pairs)):\n",
    "    match_list.append(torch.concat((reference_outputs[pairs[0]],candidate_outputs[pairs[1]])))\n",
    "\n",
    "not_match_list = []\n",
    "for _,pairs in tqdm_notebook(enumerate(not_match_pairs),total=len(not_match_pairs)):\n",
    "    not_match_list.append(torch.concat((reference_outputs[pairs[0]],candidate_outputs[pairs[1]])))\n",
    "\n",
    "match_tensor=torch.stack(match_list)\n",
    "not_match_tensor=torch.stack(not_match_list)\n",
    "\n",
    "match_ref_ids =[]\n",
    "match_ref_eth =[]\n",
    "match_ref_gend =[]\n",
    "\n",
    "for _,pairs in tqdm_notebook(enumerate(match_pairs),total=len(match_pairs)):\n",
    "    match_ref_ids.append(reference_identities[pairs[0]])\n",
    "    match_ref_eth.append(reference_ethnicities[pairs[0]])\n",
    "    match_ref_gend.append(reference_genders[pairs[0]])\n",
    "    \n",
    "not_match_ref_ids =[]\n",
    "not_match_ref_eth =[]\n",
    "not_match_ref_gend =[]\n",
    "not_match_cand_ids =[]\n",
    "not_match_cand_eth =[]\n",
    "not_match_cand_gend =[]\n",
    "\n",
    "for _,pairs in tqdm_notebook(enumerate(not_match_pairs),total=len(not_match_pairs)):\n",
    "    not_match_ref_ids.append(reference_identities[pairs[0]])\n",
    "    not_match_ref_eth.append(reference_ethnicities[pairs[0]])\n",
    "    not_match_ref_gend.append(reference_genders[pairs[0]])\n",
    "    not_match_cand_ids.append(candidate_identities[pairs[1]])\n",
    "    not_match_cand_eth.append(candidate_ethnicities[pairs[1]])\n",
    "    not_match_cand_gend.append(candidate_genders[pairs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = torch.cat([match_tensor,not_match_tensor])\n",
    "torch.save(all_inputs,'inputs/bfw_senet50_face_embeddings2.pt')\n",
    "match_labels = torch.ones(len(match_pairs))\n",
    "not_match_labels = torch.zeros(len(match_pairs))\n",
    "all_labels = torch.cat([match_labels,not_match_labels])\n",
    "torch.save(all_labels,'inputs/bfw_senet50_labels2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>reference_gender</th>\n",
       "      <th>candidate_gender</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n004721</td>\n",
       "      <td>n004721</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38395</th>\n",
       "      <td>n004686</td>\n",
       "      <td>n000313</td>\n",
       "      <td>asian</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38396</th>\n",
       "      <td>n009005</td>\n",
       "      <td>n007882</td>\n",
       "      <td>white</td>\n",
       "      <td>asian</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38397</th>\n",
       "      <td>n007917</td>\n",
       "      <td>n002012</td>\n",
       "      <td>white</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38398</th>\n",
       "      <td>n005063</td>\n",
       "      <td>n006222</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38399</th>\n",
       "      <td>n004901</td>\n",
       "      <td>n000856</td>\n",
       "      <td>white</td>\n",
       "      <td>asian</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity candidate_identity reference_ethnicity  \\\n",
       "0                n004721            n004721               asian   \n",
       "1                n004721            n004721               asian   \n",
       "2                n004721            n004721               asian   \n",
       "3                n004721            n004721               asian   \n",
       "4                n004721            n004721               asian   \n",
       "...                  ...                ...                 ...   \n",
       "38395            n004686            n000313               asian   \n",
       "38396            n009005            n007882               white   \n",
       "38397            n007917            n002012               white   \n",
       "38398            n005063            n006222               asian   \n",
       "38399            n004901            n000856               white   \n",
       "\n",
       "      candidate_ethnicity reference_gender candidate_gender  labels  \n",
       "0                   asian             male             male     1.0  \n",
       "1                   asian             male             male     1.0  \n",
       "2                   asian             male             male     1.0  \n",
       "3                   asian             male             male     1.0  \n",
       "4                   asian             male             male     1.0  \n",
       "...                   ...              ...              ...     ...  \n",
       "38395               white             male             male     0.0  \n",
       "38396               asian             male             male     0.0  \n",
       "38397               black             male             male     0.0  \n",
       "38398               asian           female           female     0.0  \n",
       "38399               asian           female           female     0.0  \n",
       "\n",
       "[38400 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ref_ids = match_ref_ids + not_match_ref_ids\n",
    "all_ref_eth = match_ref_eth + not_match_ref_eth\n",
    "all_ref_gend = match_ref_gend + not_match_ref_gend\n",
    "all_cand_ids = match_ref_ids + not_match_cand_ids\n",
    "all_cand_eth = match_ref_eth + not_match_cand_eth\n",
    "all_cand_gend = match_ref_gend + not_match_cand_gend\n",
    "\n",
    "all_df = { 'reference_identity': all_ref_ids,'candidate_identity': all_cand_ids,\n",
    "            'reference_ethnicity': all_ref_eth,'candidate_ethnicity': all_cand_eth, \n",
    "            'reference_gender': all_ref_gend,'candidate_gender':all_cand_gend,\n",
    "            'labels': all_labels.cpu().numpy()}\n",
    "\n",
    "\n",
    "all_df = pd.DataFrame(all_df)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('inputs/bfw_senet50_df2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
