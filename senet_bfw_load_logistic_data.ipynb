{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import models,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import collections\n",
    "from  PIL import Image\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "from itertools import product\n",
    "import senet50\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = senet50.make_model()\n",
    "fname = 'weights/senet50_ft_weight.pkl'\n",
    "with open(fname, 'rb') as f:\n",
    "    weights = pickle.load(f, encoding='latin1')\n",
    "\n",
    "own_state = model_scratch.state_dict()\n",
    "for name, param in weights.items():\n",
    "    if name in own_state:\n",
    "        try:\n",
    "            own_state[name].copy_(torch.from_numpy(param))\n",
    "        except Exception:\n",
    "            raise RuntimeError('While copying the parameter named {}, whose dimensions in the model are {} and whose '\\\n",
    "                                'dimensions in the checkpoint are {}.'.format(name, own_state[name].size(), param.shape))\n",
    "    else:\n",
    "        raise KeyError('unexpected key \"{}\" in state_dict'.format(name))\n",
    "model_scratch = model_scratch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data \n",
    "# create df to contain all identities, their image file names, their ethnicities\n",
    "n = 24\n",
    "img_path = 'data/BFW/CROPPED_ALIGNED'\n",
    "# asian female\n",
    "asian_female_identities = np.array(next(os.walk(img_path+'/asian_females'))[1])\n",
    "asian_female_files = np.array([])\n",
    "asian_female_references = []\n",
    "for identity in asian_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/asian_females/'+identity))[2])\n",
    "    x = img_path+'/asian_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    asian_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    asian_female_files = np.concatenate((asian_female_files,files))\n",
    "asian_female_candidates = pd.DataFrame(asian_female_files,columns =['file'])\n",
    "asian_female_candidates['ethnicity'] = 'asian'\n",
    "asian_female_candidates['gender'] = 'female'\n",
    "asian_female_candidates['identity'] = np.repeat(asian_female_identities,n)\n",
    "\n",
    "asian_female_references = pd.DataFrame(asian_female_references,columns =['file'])\n",
    "asian_female_references['ethnicity'] = 'asian'\n",
    "asian_female_references['gender'] = 'female'\n",
    "asian_female_references['identity'] = asian_female_identities\n",
    "\n",
    "# black females\n",
    "black_female_identities = np.array(next(os.walk(img_path+'/black_females'))[1])\n",
    "black_female_files = np.array([])\n",
    "black_female_references = []\n",
    "for identity in black_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/black_females/'+identity))[2])\n",
    "    x = img_path+'/black_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    black_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    black_female_files = np.concatenate((black_female_files,files))\n",
    "black_female_candidates = pd.DataFrame(black_female_files,columns =['file'])\n",
    "black_female_candidates['ethnicity'] = 'black'\n",
    "black_female_candidates['gender'] = 'female'\n",
    "black_female_candidates['identity'] = np.repeat(black_female_identities,n)\n",
    "\n",
    "\n",
    "black_female_references = pd.DataFrame(black_female_references,columns =['file'])\n",
    "black_female_references['ethnicity'] = 'black'\n",
    "black_female_references['gender'] = 'female'\n",
    "black_female_references['identity'] = black_female_identities\n",
    "\n",
    "# indian females\n",
    "indian_female_identities = np.array(next(os.walk(img_path+'/indian_females'))[1])\n",
    "indian_female_files = np.array([])\n",
    "indian_female_references = []\n",
    "for identity in indian_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/indian_females/'+identity))[2])\n",
    "    x = img_path+'/indian_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    indian_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    indian_female_files = np.concatenate((indian_female_files,files))\n",
    "indian_female_candidates = pd.DataFrame(indian_female_files,columns =['file'])\n",
    "indian_female_candidates['ethnicity'] = 'indian'\n",
    "indian_female_candidates['gender'] = 'female'\n",
    "indian_female_candidates['identity'] = np.repeat(indian_female_identities,n)\n",
    "\n",
    "\n",
    "indian_female_references = pd.DataFrame(indian_female_references,columns =['file'])\n",
    "indian_female_references['ethnicity'] = 'indian'\n",
    "indian_female_references['gender'] = 'female'\n",
    "indian_female_references['identity'] = indian_female_identities\n",
    "\n",
    "# white females\n",
    "white_female_identities = np.array(next(os.walk(img_path+'/white_females'))[1])\n",
    "white_female_files = np.array([])\n",
    "white_female_references = []\n",
    "for identity in white_female_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/white_females/'+identity))[2])\n",
    "    x = img_path+'/white_females/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    white_female_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    white_female_files = np.concatenate((white_female_files,files))\n",
    "white_female_candidates = pd.DataFrame(white_female_files,columns =['file'])\n",
    "white_female_candidates['ethnicity'] = 'white'\n",
    "white_female_candidates['gender'] = 'female'\n",
    "white_female_candidates['identity'] = np.repeat(white_female_identities,n)\n",
    "\n",
    "\n",
    "white_female_references = pd.DataFrame(white_female_references,columns =['file'])\n",
    "white_female_references['ethnicity'] = 'white'\n",
    "white_female_references['gender'] = 'female'\n",
    "white_female_references['identity'] = white_female_identities\n",
    "\n",
    "\n",
    "# asian males\n",
    "asian_male_identities = np.array(next(os.walk(img_path+'/asian_males'))[1])\n",
    "asian_male_files = np.array([])\n",
    "asian_male_references = []\n",
    "for identity in asian_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/asian_males/'+identity))[2])\n",
    "    x = img_path+'/asian_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    asian_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    asian_male_files = np.concatenate((asian_male_files,files))\n",
    "asian_male_candidates = pd.DataFrame(asian_male_files,columns =['file'])\n",
    "asian_male_candidates['ethnicity'] = 'asian'\n",
    "asian_male_candidates['gender'] = 'male'\n",
    "asian_male_candidates['identity'] = np.repeat(asian_male_identities,n)\n",
    "\n",
    "asian_male_references = pd.DataFrame(asian_male_references,columns =['file'])\n",
    "asian_male_references['ethnicity'] = 'asian'\n",
    "asian_male_references['gender'] = 'male'\n",
    "asian_male_references['identity'] = asian_male_identities\n",
    "\n",
    "# black males\n",
    "black_male_identities = np.array(next(os.walk(img_path+'/black_males'))[1])\n",
    "black_male_files = np.array([])\n",
    "black_male_references = []\n",
    "for identity in black_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/black_males/'+identity))[2])\n",
    "    x = img_path+'/black_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    black_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    black_male_files = np.concatenate((black_male_files,files))\n",
    "black_male_candidates = pd.DataFrame(black_male_files,columns =['file'])\n",
    "black_male_candidates['ethnicity'] = 'black'\n",
    "black_male_candidates['gender'] = 'male'\n",
    "black_male_candidates['identity'] = np.repeat(black_male_identities,n)\n",
    "\n",
    "\n",
    "black_male_references = pd.DataFrame(black_male_references,columns =['file'])\n",
    "black_male_references['ethnicity'] = 'black'\n",
    "black_male_references['gender'] = 'male'\n",
    "black_male_references['identity'] = black_male_identities\n",
    "\n",
    "# indian males\n",
    "indian_male_identities = np.array(next(os.walk(img_path+'/indian_males'))[1])\n",
    "indian_male_files = np.array([])\n",
    "indian_male_references = []\n",
    "for identity in indian_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/indian_males/'+identity))[2])\n",
    "    x = img_path+'/indian_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    indian_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    indian_male_files = np.concatenate((indian_male_files,files))\n",
    "indian_male_candidates = pd.DataFrame(indian_male_files,columns =['file'])\n",
    "indian_male_candidates['ethnicity'] = 'indian'\n",
    "indian_male_candidates['gender'] = 'male'\n",
    "indian_male_candidates['identity'] = np.repeat(indian_male_identities,n)\n",
    "\n",
    "\n",
    "indian_male_references = pd.DataFrame(indian_male_references,columns =['file'])\n",
    "indian_male_references['ethnicity'] = 'indian'\n",
    "indian_male_references['gender'] = 'male'\n",
    "indian_male_references['identity'] = indian_male_identities\n",
    "\n",
    "# white males\n",
    "white_male_identities = np.array(next(os.walk(img_path+'/white_males'))[1])\n",
    "white_male_files = np.array([])\n",
    "white_male_references = []\n",
    "for identity in white_male_identities:\n",
    "    files = np.sort(next(os.walk(img_path+'/white_males/'+identity))[2])\n",
    "    x = img_path+'/white_males/'+identity +'/'\n",
    "    files = np.char.add(x,files)\n",
    "    white_male_references.append(files[0])\n",
    "    files = files[1:n+1]\n",
    "    white_male_files = np.concatenate((white_male_files,files))\n",
    "white_male_candidates = pd.DataFrame(white_male_files,columns =['file'])\n",
    "white_male_candidates['ethnicity'] = 'white'\n",
    "white_male_candidates['gender'] = 'male'\n",
    "white_male_candidates['identity'] = np.repeat(white_male_identities,n)\n",
    "\n",
    "\n",
    "white_male_references = pd.DataFrame(white_male_references,columns =['file'])\n",
    "white_male_references['ethnicity'] = 'white'\n",
    "white_male_references['gender'] = 'male'\n",
    "white_male_references['identity'] = white_male_identities\n",
    "\n",
    "# all ethnicity\n",
    "asian_references = pd.concat([asian_male_references,asian_female_references],ignore_index=True)\n",
    "black_references = pd.concat([black_male_references,black_female_references],ignore_index=True)\n",
    "indian_references = pd.concat([indian_male_references,indian_female_references],ignore_index=True)\n",
    "white_references = pd.concat([white_male_references,white_female_references],ignore_index=True)\n",
    "female_references = pd.concat([asian_female_references,black_female_references,indian_female_references,white_female_references],ignore_index=True)\n",
    "male_references = pd.concat([asian_male_references,black_male_references,indian_male_references,white_male_references],ignore_index=True)\n",
    "references = pd.concat([male_references,female_references],ignore_index=True)\n",
    "\n",
    "asian_candidates = pd.concat([asian_male_candidates,asian_female_candidates],ignore_index=True)\n",
    "black_candidates = pd.concat([black_male_candidates,black_female_candidates],ignore_index=True)\n",
    "indian_candidates = pd.concat([indian_male_candidates,indian_female_candidates],ignore_index=True)\n",
    "white_candidates = pd.concat([white_male_candidates,white_female_candidates],ignore_index=True)\n",
    "female_candidates = pd.concat([asian_female_candidates,black_female_candidates,indian_female_candidates,white_female_candidates],ignore_index=True)\n",
    "male_candidates = pd.concat([asian_male_candidates,black_male_candidates,indian_male_candidates,white_male_candidates],ignore_index=True)\n",
    "candidates = pd.concat([male_candidates,female_candidates],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFW_dataset(data.Dataset):\n",
    "    '''\n",
    "    This class loads data from dataframes containing images from BFW\n",
    "    '''\n",
    "    # mean_bgr = np.array([91.4953, 103.8827, 131.0912])  # from senet50_ft.prototxt\n",
    "    mean_bgr = np.array([93.5940, 104.7624, 129.1863])  # from senet50_scratch.prototxt\n",
    "\n",
    "    def __init__(self,img_df):\n",
    "        \"\"\"\n",
    "        :param img_path: dataset directory\n",
    "        :param img_df: contains image file names and other information\n",
    "        \"\"\"\n",
    "        assert os.path.exists(img_path), \"root: {} not found.\".format(img_path)\n",
    "        self.img_df = img_df\n",
    "        self.img_info = []\n",
    "\n",
    "        for i, row in self.img_df.iterrows():\n",
    "            self.img_info.append({\n",
    "                'img_file': row.file,\n",
    "                'identity': row.identity,\n",
    "                'ethnicity': row.ethnicity,\n",
    "                'gender': row.gender,\n",
    "            })\n",
    "            if i % 1000 == 0:\n",
    "                print(\"processing: {} images\".format(i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_info)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        info = self.img_info[index]\n",
    "        img_file = info['img_file']\n",
    "        img = Image.open(img_file)\n",
    "        img = transforms.Resize(256)(img)\n",
    "        img = transforms.CenterCrop(224)(img)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        assert len(img.shape) == 3  # assumes color images and no alpha channel\n",
    "\n",
    "        ethnicity = info['ethnicity']\n",
    "        identity = info['identity']\n",
    "        gender = info['gender']\n",
    "        return self.transform(img), identity, ethnicity, gender\n",
    "  \n",
    "    def transform(self, img):\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float32)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose(2, 0, 1)  # C x H x W\n",
    "        img = torch.from_numpy(img).float()\n",
    "        return img\n",
    "\n",
    "    def untransform(self, img, lbl):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        #img += self.mean_bgr\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        return img, lbl\n",
    "        \n",
    "def apply_model(model,dataloader,device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    identities = []\n",
    "    ethnicities = []\n",
    "    genders = []\n",
    "    with torch.no_grad():\n",
    "        for _, (imgs, identityID, ethnicity, gender) in tqdm_notebook(enumerate(dataloader),total=len(dataloader)):\n",
    "            imgs = imgs.to(device)\n",
    "            x = model(imgs)\n",
    "            out = x.view(x.size(0),-1)\n",
    "            outputs.append(out)\n",
    "            identities.append(np.array(identityID))\n",
    "            ethnicities.append(np.array(ethnicity))\n",
    "            genders.append(np.array(gender))\n",
    "\n",
    "    outputs=torch.cat(outputs)\n",
    "    identities= np.concatenate(np.array(identities)).ravel()\n",
    "    ethnicities= np.concatenate(np.array(ethnicities)).ravel()\n",
    "    genders= np.concatenate(np.array(genders)).ravel()\n",
    "\n",
    "    # torch.save(outputs, file_prefix + '_outputs.pt')\n",
    "    # np.save(file_prefix + '_identities.npy', identities)\n",
    "    # np.save(file_prefix + '_ethnicities.npy', ethnicities)\n",
    "    # np.save(file_prefix + '_faceIDs.npy', genders)\n",
    "    return outputs, identities, ethnicities, genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference images\n",
    "reference_dataset = BFW_dataset(references.reset_index(drop=True))\n",
    "reference_loader = torch.utils.data.DataLoader(reference_dataset, batch_size=4, shuffle=False)#, **kwargs)\n",
    "\n",
    "candidate_dataset = BFW_dataset(candidates.reset_index(drop=True))\n",
    "candidate_loader = torch.utils.data.DataLoader(candidate_dataset, batch_size=4, shuffle=False)#, **kwargs)\n",
    "\n",
    "\n",
    "reference_outputs, reference_identities, reference_ethnicities, reference_genders = apply_model(model_scratch,reference_loader,device)\n",
    "candidate_outputs, candidate_identities, candidate_ethnicities, candidate_genders = apply_model(model_scratch,candidate_loader,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_outputs_list = []\n",
    "for output in reference_outputs.cpu().numpy():\n",
    "    reference_outputs_list.append(output)\n",
    "candidate_outputs_list = []\n",
    "for output in candidate_outputs.cpu().numpy():\n",
    "    candidate_outputs_list.append(output)\n",
    "output_references = {'outputs': reference_outputs_list, 'identity': reference_identities,'ethnicity': reference_ethnicities, 'gender': reference_genders}\n",
    "output_references = pd.DataFrame(output_references)\n",
    "\n",
    "output_candidates = {'outputs': candidate_outputs_list, 'identity': candidate_identities,'ethnicity': candidate_ethnicities, 'gender': candidate_genders}\n",
    "output_candidates = pd.DataFrame(output_candidates)\n",
    "output_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(list(product(output_references['identity'], output_candidates['identity'])))\n",
    "# labels = (ids[:,0] == ids[:,1])*1\n",
    "ethnicities = np.array(list(product(output_references['ethnicity'], output_candidates['ethnicity'])))\n",
    "genders = np.array(list(product(output_references['gender'], output_candidates['gender'])))\n",
    "\n",
    "logistic_df = { \n",
    "                'reference_identity': ids[:,0],'candidate_identity': ids[:,1],\n",
    "                'reference_ethnicity': ethnicities[:,0],'candidate_ethnicity': ethnicities[:,1], \n",
    "                'reference_gender': genders[:,0],'candidate_gender': genders[:,1]}\n",
    "\n",
    "\n",
    "logistic_df = pd.DataFrame(logistic_df)\n",
    "logistic_df['labels']=(logistic_df.reference_identity == logistic_df.candidate_identity )*1\n",
    "\n",
    "\n",
    "logistic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_df2 = logistic_df[(logistic_df['reference_ethnicity']==logistic_df['candidate_ethnicity'] )]\n",
    "logistic_df2 = logistic_df2[(logistic_df2['reference_gender']==logistic_df2['candidate_gender'] )]\n",
    "logistic_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= logistic_df2.labels\n",
    "logistic_df2.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_idx = np.where(labels==1)[0]\n",
    "not_match_idx = np.where(labels==0)[0]\n",
    "np.random.seed(random_state)\n",
    "not_match_idx_sub  = not_match_idx[np.random.choice(len(not_match_idx), size=len(match_idx), replace=False)]\n",
    "print((not_match_idx_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1 = np.arange(reference_outputs.shape[0])\n",
    "array_2 = np.arange(candidate_outputs.shape[0])\n",
    "mesh = np.array(np.meshgrid(array_1, array_2))\n",
    "combinations = mesh.T.reshape(-1, 2)\n",
    "combinations = combinations[logistic_df2.index.values]\n",
    "combinations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_pairs = combinations[match_idx]\n",
    "not_match_pairs = combinations[not_match_idx_sub]\n",
    "\n",
    "match_list = []\n",
    "for _,pairs in tqdm_notebook(enumerate(match_pairs),total=len(match_pairs)):\n",
    "    match_list.append(torch.concat((reference_outputs[pairs[0]],candidate_outputs[pairs[1]])))\n",
    "\n",
    "not_match_list = []\n",
    "for _,pairs in tqdm_notebook(enumerate(not_match_pairs),total=len(not_match_pairs)):\n",
    "    not_match_list.append(torch.concat((reference_outputs[pairs[0]],candidate_outputs[pairs[1]])))\n",
    "\n",
    "match_tensor=torch.stack(match_list)\n",
    "not_match_tensor=torch.stack(not_match_list)\n",
    "\n",
    "match_ref_ids =[]\n",
    "match_ref_eth =[]\n",
    "match_ref_gend =[]\n",
    "\n",
    "for _,pairs in tqdm_notebook(enumerate(match_pairs),total=len(match_pairs)):\n",
    "    match_ref_ids.append(reference_identities[pairs[0]])\n",
    "    match_ref_eth.append(reference_ethnicities[pairs[0]])\n",
    "    match_ref_gend.append(reference_genders[pairs[0]])\n",
    "    \n",
    "not_match_ref_ids =[]\n",
    "not_match_ref_eth =[]\n",
    "not_match_ref_gend =[]\n",
    "not_match_cand_ids =[]\n",
    "not_match_cand_eth =[]\n",
    "not_match_cand_gend =[]\n",
    "\n",
    "for _,pairs in tqdm_notebook(enumerate(not_match_pairs),total=len(not_match_pairs)):\n",
    "    not_match_ref_ids.append(reference_identities[pairs[0]])\n",
    "    not_match_ref_eth.append(reference_ethnicities[pairs[0]])\n",
    "    not_match_ref_gend.append(reference_genders[pairs[0]])\n",
    "    not_match_cand_ids.append(candidate_identities[pairs[1]])\n",
    "    not_match_cand_eth.append(candidate_ethnicities[pairs[1]])\n",
    "    not_match_cand_gend.append(candidate_genders[pairs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = torch.cat([match_tensor,not_match_tensor])\n",
    "torch.save(all_inputs,'inputs/bfw_senet50_face_embeddings.pt')\n",
    "match_labels = torch.ones(len(match_pairs))\n",
    "not_match_labels = torch.zeros(len(match_pairs))\n",
    "all_labels = torch.cat([match_labels,not_match_labels])\n",
    "torch.save(all_labels,'inputs/bfw_senet50_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ref_ids = match_ref_ids + not_match_ref_ids\n",
    "all_ref_eth = match_ref_eth + not_match_ref_eth\n",
    "all_ref_gend = match_ref_gend + not_match_ref_gend\n",
    "all_cand_ids = match_ref_ids + not_match_cand_ids\n",
    "all_cand_eth = match_ref_eth + not_match_cand_eth\n",
    "all_cand_gend = match_ref_gend + not_match_cand_gend\n",
    "\n",
    "all_df = { 'reference_identity': all_ref_ids,'candidate_identity': all_cand_ids,\n",
    "            'reference_ethnicity': all_ref_eth,'candidate_ethnicity': all_cand_eth, \n",
    "            'reference_gender': all_ref_gend,'candidate_gender':all_cand_gend,\n",
    "            'labels': all_labels.cpu().numpy()}\n",
    "\n",
    "\n",
    "all_df = pd.DataFrame(all_df)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('inputs/bfw_senet50_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
