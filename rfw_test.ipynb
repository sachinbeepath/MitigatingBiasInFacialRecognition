{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring RFW data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import models,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import collections\n",
    "from  PIL import Image\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2_0003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2_0001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2_0002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.026tq86_0001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>m.027nbyf_0002.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304</th>\n",
       "      <td>m.027nbyf_0001.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>m.027nbyf_0005.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0005</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>m.098d5s_0002.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>m.098d5s_0001.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID Ethnicity\n",
       "0       m.0c7mh2_0003.jpg      0   m.0c7mh2   0003   African\n",
       "1       m.0c7mh2_0001.jpg      0   m.0c7mh2   0001   African\n",
       "2       m.0c7mh2_0002.jpg      0   m.0c7mh2   0002   African\n",
       "3      m.026tq86_0003.jpg      1  m.026tq86   0003   African\n",
       "4      m.026tq86_0001.jpg      1  m.026tq86   0001   African\n",
       "...                   ...    ...        ...    ...       ...\n",
       "10303  m.027nbyf_0002.jpg   2982  m.027nbyf   0002    Indian\n",
       "10304  m.027nbyf_0001.jpg   2982  m.027nbyf   0001    Indian\n",
       "10305  m.027nbyf_0005.jpg   2982  m.027nbyf   0005    Indian\n",
       "10306   m.098d5s_0002.jpg   2983   m.098d5s   0002    Indian\n",
       "10307   m.098d5s_0001.jpg   2983   m.098d5s   0001    Indian\n",
       "\n",
       "[40607 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df to contain all identities, their image file names, their ethnicities\n",
    "path = \"data/RFW/images/test/txts/\"\n",
    "img_path = 'data/RFW/images/test/data/'\n",
    "\n",
    "# African images\n",
    "african_images = pd.read_csv(path + 'African/African_images.txt', sep=\"\\t\", header=None)\n",
    "african_images.columns = ['File', 'Label']\n",
    "african_images['identityID'] = african_images['File'].str[:-9]\n",
    "african_images['faceID'] = african_images['File'].str[-8:-4]\n",
    "african_images['Ethnicity'] = 'African'\n",
    "# Asian images\n",
    "asian_images = pd.read_csv(path + 'Asian/Asian_images.txt', sep=\"\\t\", header=None)\n",
    "asian_images.columns = ['File', 'Label']\n",
    "asian_images['identityID'] = asian_images['File'].str[:-9]\n",
    "asian_images['faceID'] = asian_images['File'].str[-8:-4]\n",
    "asian_images['Ethnicity'] = 'Asian'\n",
    "# Caucasian images\n",
    "caucasian_images = pd.read_csv(path + 'Caucasian/Caucasian_images.txt', sep=\"\\t\", header=None)\n",
    "caucasian_images.columns = ['File', 'Label']\n",
    "caucasian_images['identityID'] = caucasian_images['File'].str[:-9]\n",
    "caucasian_images['faceID'] = caucasian_images['File'].str[-8:-4]\n",
    "caucasian_images['Ethnicity'] = 'Caucasian'\n",
    "# Indian images\n",
    "indian_images = pd.read_csv(path + 'Indian/Indian_images.txt', sep=\"\\t\", header=None)\n",
    "indian_images.columns = ['File', 'Label']\n",
    "indian_images['identityID'] = indian_images['File'].str[:-9]\n",
    "indian_images['faceID'] = indian_images['File'].str[-8:-4]\n",
    "indian_images['Ethnicity'] = 'Indian'\n",
    "all_images = pd.concat([african_images,asian_images,caucasian_images,indian_images])\n",
    "all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2_0003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2_0001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2_0002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.026tq86_0001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>m.027nbyf_0002.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304</th>\n",
       "      <td>m.027nbyf_0001.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>m.027nbyf_0005.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0005</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>m.098d5s_0002.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>m.098d5s_0001.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40520 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID Ethnicity\n",
       "0       m.0c7mh2_0003.jpg      0   m.0c7mh2   0003   African\n",
       "1       m.0c7mh2_0001.jpg      0   m.0c7mh2   0001   African\n",
       "2       m.0c7mh2_0002.jpg      0   m.0c7mh2   0002   African\n",
       "3      m.026tq86_0003.jpg      1  m.026tq86   0003   African\n",
       "4      m.026tq86_0001.jpg      1  m.026tq86   0001   African\n",
       "...                   ...    ...        ...    ...       ...\n",
       "10303  m.027nbyf_0002.jpg   2982  m.027nbyf   0002    Indian\n",
       "10304  m.027nbyf_0001.jpg   2982  m.027nbyf   0001    Indian\n",
       "10305  m.027nbyf_0005.jpg   2982  m.027nbyf   0005    Indian\n",
       "10306   m.098d5s_0002.jpg   2983   m.098d5s   0002    Indian\n",
       "10307   m.098d5s_0001.jpg   2983   m.098d5s   0001    Indian\n",
       "\n",
       "[40520 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any duplicate identities\n",
    "v = all_images.reset_index().groupby('identityID').Ethnicity.nunique()\n",
    "dup = v[v>1].index.tolist()\n",
    "all_images = all_images[~all_images['identityID'].isin(dup)]\n",
    "all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m.0c7mh2_0001.jpg', 'm.026tq86_0001.jpg', 'm.02wz3nc_0001.jpg',\n",
       "       ..., 'm.02793d7_0001.jpg', 'm.027nbyf_0001.jpg',\n",
       "       'm.098d5s_0001.jpg'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first image from each identity and use it as reference\n",
    "identities = np.array(all_images.identityID.unique().tolist()).astype(object)\n",
    "file_end =  np.array('_0001.jpg'.split()*len(identities)).astype(object)\n",
    "first_images = identities + file_end\n",
    "first_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11403 29117\n"
     ]
    }
   ],
   "source": [
    "references = all_images[all_images['File'].isin(first_images)]\n",
    "candidates = all_images[~all_images['File'].isin(first_images)]\n",
    "print(len(references),len(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2_0003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2_0002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m.026tq86_0002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m.02wz3nc_0002.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10301</th>\n",
       "      <td>m.027nbyf_0004.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0004</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>m.027nbyf_0003.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0003</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>m.027nbyf_0002.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>m.027nbyf_0005.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0005</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>m.098d5s_0002.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29117 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID Ethnicity\n",
       "0       m.0c7mh2_0003.jpg      0   m.0c7mh2   0003   African\n",
       "2       m.0c7mh2_0002.jpg      0   m.0c7mh2   0002   African\n",
       "3      m.026tq86_0003.jpg      1  m.026tq86   0003   African\n",
       "5      m.026tq86_0002.jpg      1  m.026tq86   0002   African\n",
       "6      m.02wz3nc_0002.jpg      2  m.02wz3nc   0002   African\n",
       "...                   ...    ...        ...    ...       ...\n",
       "10301  m.027nbyf_0004.jpg   2982  m.027nbyf   0004    Indian\n",
       "10302  m.027nbyf_0003.jpg   2982  m.027nbyf   0003    Indian\n",
       "10303  m.027nbyf_0002.jpg   2982  m.027nbyf   0002    Indian\n",
       "10305  m.027nbyf_0005.jpg   2982  m.027nbyf   0005    Indian\n",
       "10306   m.098d5s_0002.jpg   2983   m.098d5s   0002    Indian\n",
       "\n",
       "[29117 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class for RFW\n",
    "class resnetRFW(data.Dataset):\n",
    "    \n",
    "    '''\n",
    "    This will be a class to load data from RFW for resnet50 model\n",
    "    '''\n",
    "     \n",
    "    mean_bgr = np.array([91.4953, 103.8827, 131.0912])  # from resnet50_ft.prototxt\n",
    "\n",
    "    def __init__(self,img_path,img_df):\n",
    "        \"\"\"\n",
    "        :param img_path: dataset directory\n",
    "        :param img_df: contains image file names and other information\n",
    "        \"\"\"\n",
    "        assert os.path.exists(img_path), \"root: {} not found.\".format(img_path)\n",
    "        self.img_path = img_path\n",
    "        self.img_df = img_df\n",
    "        self.img_info = []\n",
    "\n",
    "        for i, row in self.img_df.iterrows():\n",
    "            self.img_info.append({\n",
    "                'img_file': row.Ethnicity + '/' + row.identityID + '/' + row.File,\n",
    "                'identityID': row.identityID,\n",
    "                'Ethnicity': row.Ethnicity,\n",
    "                'faceID': row.faceID,\n",
    "            })\n",
    "            if i % 5000 == 0:\n",
    "                print(\"processing: {} images\".format(i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_info)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        info = self.img_info[index]\n",
    "        img_file = info['img_file']\n",
    "        img = Image.open(os.path.join(self.img_path, img_file))\n",
    "        img = transforms.Resize(256)(img)\n",
    "        img = transforms.CenterCrop(224)(img)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        assert len(img.shape) == 3  # assumes color images and no alpha channel\n",
    "\n",
    "        Ethnicity = info['Ethnicity']\n",
    "        identityID = info['identityID']\n",
    "        faceID = info['faceID']\n",
    "        return self.transform(img), identityID, Ethnicity, faceID\n",
    "  \n",
    "\n",
    "    def transform(self, img):\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float32)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose(2, 0, 1)  # C x H x W\n",
    "        img = torch.from_numpy(img).float()\n",
    "        return img\n",
    "\n",
    "    def untransform(self, img, lbl):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        img += self.mean_bgr\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        return img, lbl\n",
    "\n",
    "def load_resnet50(weights=\"weights/resnet50_scratch_weight.pkl\"):\n",
    "    # load resnet50 model and modify it to match the one from the github to load the weights from the pkl\n",
    "# resnet50 trained on VGGFace2\n",
    "    resnet50 = models.resnet50(pretrained=False)\n",
    "    resnet50.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
    "    resnet50.layer2[0].conv1 = nn.Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    resnet50.layer2[0].conv2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    resnet50.layer3[0].conv1 = nn.Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    resnet50.layer3[0].conv2 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    resnet50.layer4[0].conv1 = nn.Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    resnet50.layer4[0].conv2 = nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    resnet50.avgpool = nn.AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
    "    resnet50.fc = nn.Linear(in_features=2048,out_features=8631)\n",
    "    with open(\"weights/resnet50_scratch_weight.pkl\", 'rb') as f:\n",
    "        weights = pickle.load(f, encoding='latin1')\n",
    "    weights = dict(map(lambda x: (x[0], torch.from_numpy(x[1])), weights.items()))\n",
    "    weights = OrderedDict(weights)\n",
    "    resnet50.load_state_dict(weights)\n",
    "    resnet50 = torch.nn.Sequential(*(list(resnet50.children())[:-1]))\n",
    "    return resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 10000 images\n",
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 10000 images\n",
      "processing: 15000 images\n",
      "processing: 20000 images\n",
      "processing: 25000 images\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "# load reference images\n",
    "reference_dataset = resnetRFW(img_path,references.reset_index(drop=True))\n",
    "reference_loader = torch.utils.data.DataLoader(reference_dataset, batch_size=4, shuffle=False, **kwargs)\n",
    "# load candidate images\n",
    "candidate_dataset = resnetRFW(img_path,candidates.reset_index(drop=True))\n",
    "candidate_loader = torch.utils.data.DataLoader(candidate_dataset, batch_size=4, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and assign weights\n",
    "resnet50_ft = load_resnet50(weights=\"weights/resnet50_ft_weight.pkl\")\n",
    "resnet50_ft = resnet50_ft.to(device=device)\n",
    "\n",
    "resnet50_scratch = load_resnet50(weights=\"weights/resnet50_scratch_weight.pkl\")\n",
    "resnet50_scratch = resnet50_scratch.to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model,dataloader,file_prefix,device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    identities = []\n",
    "    ethnicities = []\n",
    "    faceIDs = []\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(dataloader),total=len(dataloader)):\n",
    "            imgs = imgs.to(device)\n",
    "            x = model(imgs)\n",
    "            out = x.view(x.size(0),-1)\n",
    "            outputs.append(out)\n",
    "            identities.append(np.array(identityID))\n",
    "            ethnicities.append(np.array(Ethnicity))\n",
    "            faceIDs.append(np.array(faceID))\n",
    "\n",
    "    outputs=torch.cat(outputs)\n",
    "    identities= np.concatenate(np.array(identities)).ravel()\n",
    "    ethnicities= np.concatenate(np.array(ethnicities)).ravel()\n",
    "    faceIDs= np.concatenate(np.array(faceIDs)).ravel()\n",
    "\n",
    "    torch.save(outputs, file_prefix + '_outputs.pt')\n",
    "    np.save(file_prefix + '_identities.npy', identities)\n",
    "    np.save(file_prefix + '_ethnicities.npy', ethnicities)\n",
    "    np.save(file_prefix + '_faceIDs.npy', faceIDs)\n",
    "    return outputs, identities, ethnicities, faceIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d45bc69e6b45f2876ab771a5bd91a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2851 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5694d475fd4e14882aa464478dc2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" with torch.no_grad():\\n    for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(candidate_loader),total=len(candidate_loader)):\\n        x = resnet50(imgs)\\n        out = x.view(x.size(0),-1)\\n        outputs.append(out)\\n        identities.append(np.array(identityID))\\n        ethnicities.append(np.array(Ethnicity))\\n        faceIDs.append(np.array(faceID))\\n\\noutputs=torch.cat(outputs)\\nidentities= np.array(identities)\\nethnicities= np.array(ethnicities)\\nfaceIDs= np.array(faceIDs)\\n\\ntorch.save(outputs, 'candidate_outputs.pt')\\nnp.save('candidate_identities.npy', identities)\\nnp.save('candidate_ethnicities.npy', ethnicities)\\nnp.save('candidate_faceIDs.npy', faceIDs) \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply ft model to references\n",
    "\n",
    "reference_outputs, reference_identities, reference_ethnicities, reference_faceIDs = apply_model(resnet50_scratch,reference_loader,'outputs/RFW/scratch/reference',device)\n",
    "\"\"\" outputs = []\n",
    "identities = []\n",
    "ethnicities = []\n",
    "faceIDs = []\n",
    "with torch.no_grad():\n",
    "    for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(reference_loader),total=len(reference_loader)):\n",
    "        x = resnet50(imgs)\n",
    "        out = x.view(x.size(0),-1)\n",
    "        outputs.append(out)\n",
    "        identities.append(np.array(identityID))\n",
    "        ethnicities.append(np.array(Ethnicity))\n",
    "        faceIDs.append(np.array(faceID))\n",
    "\n",
    "outputs=torch.cat(outputs)\n",
    "identities= np.array(identities)\n",
    "ethnicities= np.array(ethnicities)\n",
    "faceIDs= np.array(faceIDs)\n",
    "\n",
    "torch.save(outputs, 'reference_outputs.pt')\n",
    "np.save('reference_identities.npy', identities)\n",
    "np.save('reference_ethnicities.npy', ethnicities)\n",
    "np.save('reference_faceIDs.npy', faceIDs) \"\"\"\n",
    "\n",
    "# apply model to candidates\n",
    "\n",
    "candidate_outputs, candidate_identities, candidate_ethnicities, candidate_faceIDs = apply_model(resnet50_scratch,candidate_loader,'outputs/RFW/scratch/candidate',device)\n",
    "\"\"\" with torch.no_grad():\n",
    "    for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(candidate_loader),total=len(candidate_loader)):\n",
    "        x = resnet50(imgs)\n",
    "        out = x.view(x.size(0),-1)\n",
    "        outputs.append(out)\n",
    "        identities.append(np.array(identityID))\n",
    "        ethnicities.append(np.array(Ethnicity))\n",
    "        faceIDs.append(np.array(faceID))\n",
    "\n",
    "outputs=torch.cat(outputs)\n",
    "identities= np.array(identities)\n",
    "ethnicities= np.array(ethnicities)\n",
    "faceIDs= np.array(faceIDs)\n",
    "\n",
    "torch.save(outputs, 'candidate_outputs.pt')\n",
    "np.save('candidate_identities.npy', identities)\n",
    "np.save('candidate_ethnicities.npy', ethnicities)\n",
    "np.save('candidate_faceIDs.npy', faceIDs) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face verification (1:1)\n",
    "\n",
    "def face_verification(reference, candidate, metric, threshold=None):\n",
    "    ''' \n",
    "    this function performs face verification given a reference face and a candidate face\n",
    "    returns 0 if the faces do not match and 1 if they do\n",
    "    '''\n",
    "    if metric == 'correlation':\n",
    "        if threshold is None:\n",
    "            threshold = 0.8\n",
    "        cor = np.abs(corr2_coeff(reference,candidate))\n",
    "        return cor\n",
    "        \"\"\"if cor > threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\"\"\"\n",
    "        \n",
    "    elif metric == 'cosine':\n",
    "        if threshold is None:\n",
    "            threshold = 0.5\n",
    "        cos = distance.cosine(reference,candidate)\n",
    "        if cos <= threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return \"Please use one of 'correlation', or 'cosine' as an input for metric\"\n",
    "        \n",
    "def corr2_coeff(A, B):\n",
    "    # Rowwise mean of input arrays & subtract from input arrays themeselves\n",
    "    A_mA = A - A.mean(1)[:, None]\n",
    "    B_mB = B - B.mean(1)[:, None]\n",
    "\n",
    "    # Sum of squares across rows\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "\n",
    "    # Finally get corr coeff\n",
    "    return torch.matmul(A_mA, B_mB.T) / torch.sqrt(torch.matmul(ssA[:, None],ssB[None]))\n",
    "def cos_sim(a, b, eps=1e-8):\n",
    "    \"\"\"\n",
    "    added eps for numerical stability\n",
    "    \"\"\"\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = corr2_coeff(reference_outputs,candidate_outputs).cpu().detach().numpy()\n",
    "cos = cos_sim(reference_outputs,candidate_outputs).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95468e9d6fdb48bd803914dc1e5e9504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791ed5cc51794993a869d8713735db0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African</td>\n",
       "      <td>0.385718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.432726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.532053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian</td>\n",
       "      <td>0.532201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  accuracy\n",
       "0    African  0.385718\n",
       "1      Asian  0.432726\n",
       "2  Caucasian  0.532053\n",
       "3     Indian  0.532201"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Face Identification\n",
    "\n",
    "'''\n",
    "here i want to do face identification\n",
    "basically take the outputs from the candidates and check against all references\n",
    "take the reference image that has highest correlation/similarity\n",
    "if the identities match then correct otherwise wrong\n",
    "'''\n",
    "\n",
    "cor_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor.T),total=len(cor.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cor_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cor_identification = cor_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos.T),total=len(cos.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cos_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cos_identification = cos_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cos_identification.candidate_ethnicity.unique():\n",
    "    eth_cos = cos_identification.loc[cos_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cos.match)/len(eth_cos)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cos_id_acc = cos_id_acc.append(row,ignore_index=True)\n",
    "cos_id_acc\n",
    "\n",
    "cor_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cor_identification.candidate_ethnicity.unique():\n",
    "    eth_cor = cor_identification.loc[cor_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cor.match)/len(eth_cor)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cor_id_acc = cor_id_acc.append(row,ignore_index=True)\n",
    "cos_id_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0253f7e3ae794e078f474d2ef4eb92f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fe6e608f944dbf8340b8c336bbcf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414609afb85747ddae341a90175c7900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8080c45fb63043ceb8c5c2f336dd2108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ethnicity  accuracy\n",
      "0    African  0.385718\n",
      "1      Asian  0.432726\n",
      "2  Caucasian  0.532053\n",
      "3     Indian  0.532201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African</td>\n",
       "      <td>0.384636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.430639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.532191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian</td>\n",
       "      <td>0.528775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  accuracy\n",
       "0    African  0.384636\n",
       "1      Asian  0.430639\n",
       "2  Caucasian  0.532191\n",
       "3     Indian  0.528775"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply scratch model to references\n",
    "\n",
    "reference_outputs, reference_identities, reference_ethnicities, reference_faceIDs = apply_model(resnet50_scratch,reference_loader,'outputs/RFW/ft/reference',device)\n",
    "\n",
    "candidate_outputs, candidate_identities, candidate_ethnicities, candidate_faceIDs = apply_model(resnet50_scratch,candidate_loader,'outputs/RFW/ft/candidate',device)\n",
    "\n",
    "\n",
    "\n",
    "cor = corr2_coeff(reference_outputs,candidate_outputs).cpu().detach().numpy()\n",
    "cos = cos_sim(reference_outputs,candidate_outputs).cpu().detach().numpy()\n",
    "\n",
    "# Face Identification\n",
    "\n",
    "'''\n",
    "here i want to do face identification\n",
    "basically take the outputs from the candidates and check against all references\n",
    "take the reference image that has highest correlation/similarity\n",
    "if the identities match then correct otherwise wrong\n",
    "'''\n",
    "\n",
    "cor_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor.T),total=len(cor.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cor_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cor_identification = cor_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos.T),total=len(cos.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cos_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cos_identification = cos_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cos_identification.candidate_ethnicity.unique():\n",
    "    eth_cos = cos_identification.loc[cos_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cos.match)/len(eth_cos)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cos_id_acc = cos_id_acc.append(row,ignore_index=True)\n",
    "print(cos_id_acc)\n",
    "\n",
    "\n",
    "cor_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cor_identification.candidate_ethnicity.unique():\n",
    "    eth_cor = cor_identification.loc[cor_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cor.match)/len(eth_cor)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cor_id_acc = cor_id_acc.append(row,ignore_index=True)\n",
    "cor_id_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reference_outputs = torch.load(\"outputs/RFW/reference_outputs.pt\")\\nreference_identities = np.concatenate(np.load(\\'outputs/RFW/reference_identities.npy\\',allow_pickle=True)).ravel()\\nreference_ethnicities = np.concatenate(np.load(\\'outputs/RFW/reference_ethnicities.npy\\',allow_pickle=True)).ravel()\\nreference_faceIDs = np.concatenate(np.load(\\'outputs/RFW/reference_faceIDs.npy\\',allow_pickle=True)).ravel()\\nprint(reference_outputs.shape,reference_identities.shape,reference_ethnicities.shape,reference_faceIDs.shape)\\n\\ncandidate_outputs = torch.load(\"outputs/RFW/candidate_outputs.pt\")\\ncandidate_identities = np.concatenate(np.load(\\'outputs/RFW/candidate_identities.npy\\',allow_pickle=True)).ravel()\\ncandidate_ethnicities = np.concatenate(np.load(\\'outputs/RFW/candidate_ethnicities.npy\\',allow_pickle=True)).ravel()\\ncandidate_faceIDs = np.concatenate(np.load(\\'outputs/RFW/candidate_faceIDs.npy\\',allow_pickle=True)).ravel()\\nprint(candidate_outputs.shape,candidate_identities.shape,candidate_ethnicities.shape,candidate_faceIDs.shape)\\n\\ncandidate_identities'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for now since i didnt update the files i have to ravel here otherwise just load normally\n",
    "\n",
    "'''reference_outputs = torch.load(\"outputs/RFW/reference_outputs.pt\")\n",
    "reference_identities = np.concatenate(np.load('outputs/RFW/reference_identities.npy',allow_pickle=True)).ravel()\n",
    "reference_ethnicities = np.concatenate(np.load('outputs/RFW/reference_ethnicities.npy',allow_pickle=True)).ravel()\n",
    "reference_faceIDs = np.concatenate(np.load('outputs/RFW/reference_faceIDs.npy',allow_pickle=True)).ravel()\n",
    "print(reference_outputs.shape,reference_identities.shape,reference_ethnicities.shape,reference_faceIDs.shape)\n",
    "\n",
    "candidate_outputs = torch.load(\"outputs/RFW/candidate_outputs.pt\")\n",
    "candidate_identities = np.concatenate(np.load('outputs/RFW/candidate_identities.npy',allow_pickle=True)).ravel()\n",
    "candidate_ethnicities = np.concatenate(np.load('outputs/RFW/candidate_ethnicities.npy',allow_pickle=True)).ravel()\n",
    "candidate_faceIDs = np.concatenate(np.load('outputs/RFW/candidate_faceIDs.npy',allow_pickle=True)).ravel()\n",
    "print(candidate_outputs.shape,candidate_identities.shape,candidate_ethnicities.shape,candidate_faceIDs.shape)\n",
    "\n",
    "candidate_identities'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11403, 2048]) (11403,) (11403,) (11403,)\n",
      "torch.Size([29117, 2048]) (29117,) (29117,) (29117,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['m.0c7mh2', 'm.0c7mh2', 'm.026tq86', ..., 'm.027nbyf', 'm.027nbyf',\n",
       "       'm.098d5s'], dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_outputs = torch.load(\"outputs/RFW/ft/reference_outputs.pt\")\n",
    "reference_identities = np.load('outputs/RFW/ft/reference_identities.npy',allow_pickle=True)\n",
    "reference_ethnicities = np.load('outputs/RFW/ft/reference_ethnicities.npy',allow_pickle=True)\n",
    "reference_faceIDs = np.load('outputs/RFW/ft/reference_faceIDs.npy',allow_pickle=True)\n",
    "print(reference_outputs.shape,reference_identities.shape,reference_ethnicities.shape,reference_faceIDs.shape)\n",
    "\n",
    "candidate_outputs = torch.load(\"outputs/RFW/ft/candidate_outputs.pt\")\n",
    "candidate_identities = np.load('outputs/RFW/ft/candidate_identities.npy',allow_pickle=True)\n",
    "candidate_ethnicities = np.load('outputs/RFW/ft/candidate_ethnicities.npy',allow_pickle=True)\n",
    "candidate_faceIDs = np.load('outputs/RFW/ft/candidate_faceIDs.npy',allow_pickle=True)\n",
    "print(candidate_outputs.shape,candidate_identities.shape,candidate_ethnicities.shape,candidate_faceIDs.shape)\n",
    "\n",
    "candidate_identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.7\n",
    "verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity', 'cor_matches', 'cos_matches'])\n",
    "for i, (cor_row, cos_row) in tqdm_notebook(enumerate(zip(cor,cos)),total=len(cor)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  match_cor = candidate_identities[cor_row>thresh]\n",
    "  match_cos = candidate_identities[cos_row>thresh]  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'cor_matches': match_cor, \n",
    "           'cos_matches': match_cos}\n",
    "  verification = verification.append(row,ignore_index=True)\n",
    "\n",
    "verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e2e672a6ef4329b624a61faf0f4ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>matches</th>\n",
       "      <th>not_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>m.0974m7</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0974m7, m.0974m7]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>m.0k00nk</td>\n",
       "      <td>African</td>\n",
       "      <td>3</td>\n",
       "      <td>29114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0k00nk, m.0k00nk, m.0k00nk]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>m.01ky6fb</td>\n",
       "      <td>African</td>\n",
       "      <td>4</td>\n",
       "      <td>29113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.01ky6fb, m.01ky6fb, m.01ky6fb, m.01ky6fb]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>m.05zl3c</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.05zl3c, m.05zl3c]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>m.02z21c6</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.02z21c6, m.02z21c6]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11034</th>\n",
       "      <td>m.0h3ry9b</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0h3ry9b, m.0h3ry9b]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11037</th>\n",
       "      <td>m.0593ll</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0593ll, m.0593ll]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>m.04jb36f</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.04jb36f, m.04jb36f]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200</th>\n",
       "      <td>m.01yv6p</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.01yv6p, m.01yv6p]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11308</th>\n",
       "      <td>m.0744sc</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0744sc, m.0744sc]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity reference_ethnicity TP     TN FP FN  \\\n",
       "324             m.0974m7             African  2  29115  0  0   \n",
       "406             m.0k00nk             African  3  29114  0  0   \n",
       "441            m.01ky6fb             African  4  29113  0  0   \n",
       "542             m.05zl3c             African  2  29115  0  0   \n",
       "641            m.02z21c6             African  2  29115  0  0   \n",
       "...                  ...                 ... ..    ... .. ..   \n",
       "11034          m.0h3ry9b              Indian  2  29115  0  0   \n",
       "11037           m.0593ll              Indian  2  29115  0  0   \n",
       "11195          m.04jb36f              Indian  2  29115  0  0   \n",
       "11200           m.01yv6p              Indian  2  29115  0  0   \n",
       "11308           m.0744sc              Indian  2  29115  0  0   \n",
       "\n",
       "                                            matches  \\\n",
       "324                            [m.0974m7, m.0974m7]   \n",
       "406                  [m.0k00nk, m.0k00nk, m.0k00nk]   \n",
       "441    [m.01ky6fb, m.01ky6fb, m.01ky6fb, m.01ky6fb]   \n",
       "542                            [m.05zl3c, m.05zl3c]   \n",
       "641                          [m.02z21c6, m.02z21c6]   \n",
       "...                                             ...   \n",
       "11034                        [m.0h3ry9b, m.0h3ry9b]   \n",
       "11037                          [m.0593ll, m.0593ll]   \n",
       "11195                        [m.04jb36f, m.04jb36f]   \n",
       "11200                          [m.01yv6p, m.01yv6p]   \n",
       "11308                          [m.0744sc, m.0744sc]   \n",
       "\n",
       "                                             not_matches  \n",
       "324    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "406    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "441    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "542    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "641    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "...                                                  ...  \n",
       "11034  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11037  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11195  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11200  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11308  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "\n",
       "[280 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.65\n",
    "cos_verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity','TP','TN','FP','FN','matches','not_matches'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos),total=len(cos)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  matches = candidate_identities[cos_row>thresh]  \n",
    "  not_matches = candidate_identities[cos_row<=thresh]\n",
    "  TP = sum(matches == identity)\n",
    "  FP = sum(matches != identity)\n",
    "  TN = sum(not_matches != identity)\n",
    "  FN = sum(not_matches == identity)\n",
    "  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'TP': TP,\n",
    "           'TN': TN,\n",
    "           'FP': FP,\n",
    "           'FN': FN,\n",
    "           'matches': matches, \n",
    "           'not_matches': not_matches}\n",
    "  cos_verification = cos_verification.append(row,ignore_index=True)\n",
    "\n",
    "cos_verification[cos_verification.FN == 0][cos_verification.FP == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_identity     m.0c7mh2m.026tq86m.02wz3ncm.0c012t4m.0p8s_gxm....\n",
      "reference_ethnicity    AfricanAfricanAfricanAfricanAfricanAfricanAfri...\n",
      "TP                                                                  4729\n",
      "TN                                                              86693850\n",
      "FP                                                                125650\n",
      "FN                                                                  2665\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "African_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'African']\n",
    "print(African_cos.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.0281bfhm.0421bfhm.02r80dqm.06w18lbm.02tcmtm....\n",
       "reference_ethnicity    AsianAsianAsianAsianAsianAsianAsianAsianAsianA...\n",
       "TP                                                                  4613\n",
       "TN                                                              72371881\n",
       "FP                                                                 93145\n",
       "FN                                                                  2574\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Asian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Asian']\n",
    "Asian_cos.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.05zdk2m.04064_hm.06414fsm.0dtsglm.02ww2f6m.0...\n",
       "reference_ethnicity    IndianIndianIndianIndianIndianIndianIndianIndi...\n",
       "TP                                                                  4944\n",
       "TN                                                              86531725\n",
       "FP                                                                 54935\n",
       "FN                                                                  2354\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Indian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Indian']\n",
    "Indian_cos.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.0cqh0qm.02r6ydbm.0415yw4m.049pq8m.03cdg6lm.0...\n",
       "reference_ethnicity    CaucasianCaucasianCaucasianCaucasianCaucasianC...\n",
       "TP                                                                  3914\n",
       "TN                                                              86110744\n",
       "FP                                                                 10104\n",
       "FN                                                                  3324\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caucasian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Caucasian']\n",
    "Caucasian_cos.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c51c802723643728eca451ba24c5265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>matches</th>\n",
       "      <th>not_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>m.03dwmn</td>\n",
       "      <td>African</td>\n",
       "      <td>1</td>\n",
       "      <td>29116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.03dwmn]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>m.033mrs</td>\n",
       "      <td>African</td>\n",
       "      <td>3</td>\n",
       "      <td>29114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.033mrs, m.033mrs, m.033mrs]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>m.04_zbx</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.04_zbx, m.04_zbx]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>m.0g5576</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0g5576, m.0g5576]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>m.0ngtn1l</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0ngtn1l, m.0ngtn1l]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11341</th>\n",
       "      <td>m.026n0ps</td>\n",
       "      <td>Indian</td>\n",
       "      <td>1</td>\n",
       "      <td>29116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.026n0ps]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11353</th>\n",
       "      <td>m.0h19lp</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0h19lp, m.0h19lp]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11354</th>\n",
       "      <td>m.0cz9878</td>\n",
       "      <td>Indian</td>\n",
       "      <td>1</td>\n",
       "      <td>29116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0cz9878]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11374</th>\n",
       "      <td>m.03h654p</td>\n",
       "      <td>Indian</td>\n",
       "      <td>4</td>\n",
       "      <td>29113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.03h654p, m.03h654p, m.03h654p, m.03h654p]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>m.07pkcf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>3</td>\n",
       "      <td>29114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.07pkcf, m.07pkcf, m.07pkcf]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity reference_ethnicity TP     TN FP FN  \\\n",
       "38              m.03dwmn             African  1  29116  0  0   \n",
       "71              m.033mrs             African  3  29114  0  0   \n",
       "74              m.04_zbx             African  2  29115  0  0   \n",
       "76              m.0g5576             African  2  29115  0  0   \n",
       "112            m.0ngtn1l             African  2  29115  0  0   \n",
       "...                  ...                 ... ..    ... .. ..   \n",
       "11341          m.026n0ps              Indian  1  29116  0  0   \n",
       "11353           m.0h19lp              Indian  2  29115  0  0   \n",
       "11354          m.0cz9878              Indian  1  29116  0  0   \n",
       "11374          m.03h654p              Indian  4  29113  0  0   \n",
       "11379           m.07pkcf              Indian  3  29114  0  0   \n",
       "\n",
       "                                            matches  \\\n",
       "38                                       [m.03dwmn]   \n",
       "71                   [m.033mrs, m.033mrs, m.033mrs]   \n",
       "74                             [m.04_zbx, m.04_zbx]   \n",
       "76                             [m.0g5576, m.0g5576]   \n",
       "112                          [m.0ngtn1l, m.0ngtn1l]   \n",
       "...                                             ...   \n",
       "11341                                   [m.026n0ps]   \n",
       "11353                          [m.0h19lp, m.0h19lp]   \n",
       "11354                                   [m.0cz9878]   \n",
       "11374  [m.03h654p, m.03h654p, m.03h654p, m.03h654p]   \n",
       "11379                [m.07pkcf, m.07pkcf, m.07pkcf]   \n",
       "\n",
       "                                             not_matches  \n",
       "38     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "71     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "74     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "76     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "112    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "...                                                  ...  \n",
       "11341  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11353  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11354  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11374  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11379  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "\n",
       "[713 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.65\n",
    "cor_verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity','TP','TN','FP','FN','matches','not_matches'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor),total=len(cor)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  matches = candidate_identities[cor_row>thresh]  \n",
    "  not_matches = candidate_identities[cor_row<=thresh]\n",
    "  TP = sum(matches == identity)\n",
    "  FP = sum(matches != identity)\n",
    "  TN = sum(not_matches != identity)\n",
    "  FN = sum(not_matches == identity)\n",
    "  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'TP': TP,\n",
    "           'TN': TN,\n",
    "           'FP': FP,\n",
    "           'FN': FN,\n",
    "           'matches': matches, \n",
    "           'not_matches': not_matches}\n",
    "  cor_verification = cor_verification.append(row,ignore_index=True)\n",
    "\n",
    "cor_verification[cor_verification.FN == 0][cor_verification.FP == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.0c7mh2m.026tq86m.02wz3ncm.0c012t4m.0p8s_gxm....\n",
       "reference_ethnicity    AfricanAfricanAfricanAfricanAfricanAfricanAfri...\n",
       "TP                                                                  1417\n",
       "TN                                                              86818807\n",
       "FP                                                                   693\n",
       "FN                                                                  5977\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "African_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'African']\n",
    "African_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.0281bfhm.0421bfhm.02r80dqm.06w18lbm.02tcmtm....\n",
       "reference_ethnicity    AsianAsianAsianAsianAsianAsianAsianAsianAsianA...\n",
       "TP                                                                  1862\n",
       "TN                                                              72463469\n",
       "FP                                                                  1557\n",
       "FN                                                                  5325\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Asian_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'Asian']\n",
    "Asian_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.05zdk2m.04064_hm.06414fsm.0dtsglm.02ww2f6m.0...\n",
       "reference_ethnicity    IndianIndianIndianIndianIndianIndianIndianIndi...\n",
       "TP                                                                  1919\n",
       "TN                                                              86586321\n",
       "FP                                                                   339\n",
       "FN                                                                  5379\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Indian_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'Indian']\n",
    "Indian_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.0cqh0qm.02r6ydbm.0415yw4m.049pq8m.03cdg6lm.0...\n",
       "reference_ethnicity    CaucasianCaucasianCaucasianCaucasianCaucasianC...\n",
       "TP                                                                  1149\n",
       "TN                                                              86120810\n",
       "FP                                                                    38\n",
       "FN                                                                  6089\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Caucasian_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'Caucasian']\n",
    "Caucasian_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African</td>\n",
       "      <td>0.384636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.430639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.532191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian</td>\n",
       "      <td>0.528775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  accuracy\n",
       "0    African  0.384636\n",
       "1      Asian  0.430639\n",
       "2  Caucasian  0.532191\n",
       "3     Indian  0.528775"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cor_identification.candidate_ethnicity.unique():\n",
    "    eth_cor = cor_identification.loc[cor_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cor.match)/len(eth_cor)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cor_id_acc = cor_id_acc.append(row,ignore_index=True)\n",
    "cor_id_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.6960, 0.7148, 0.7524,  ..., 0.6452, 0.7605, 0.6787], device='mps:0'),\n",
       "indices=tensor([ 2859,     0,     1,  ...,  5589, 11401,  8554], device='mps:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(cos_sim(candidate_outputs,reference_outputs),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62578154, 0.35835844, 0.47202942, ..., 0.25972196, 0.2957378 ,\n",
       "       0.3611129 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(candidate_outputs,reference_outputs)[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc09605aa5fb4587a7d998b5255e86b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0n_gk9j</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>m.02qvybd</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0dm44t</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.0hrgxh3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29113</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29114</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.06zrlyg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29116</th>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.02679cm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29117 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      candidate_identity candidate_ethnicity reference_identity  match\n",
       "0               m.0c7mh2             African          m.0n_gk9j    0.0\n",
       "1               m.0c7mh2             African           m.0c7mh2    1.0\n",
       "2              m.026tq86             African          m.026tq86    1.0\n",
       "3              m.026tq86             African          m.02qvybd    0.0\n",
       "4              m.02wz3nc             African           m.0dm44t    0.0\n",
       "...                  ...                 ...                ...    ...\n",
       "29112          m.027nbyf              Indian          m.0hrgxh3    0.0\n",
       "29113          m.027nbyf              Indian          m.027nbyf    1.0\n",
       "29114          m.027nbyf              Indian          m.06zrlyg    0.0\n",
       "29115          m.027nbyf              Indian          m.027nbyf    1.0\n",
       "29116           m.098d5s              Indian          m.02679cm    0.0\n",
       "\n",
       "[29117 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor.T),total=len(cor.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cor_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cor_identification = cor_identification.append(row,ignore_index=True)\n",
    "cor_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b3b41b014c4883b9e365d37ade0465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb#ch0000031?line=6'>7</a>\u001b[0m     match \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m identity \u001b[39m==\u001b[39m reference_identity \u001b[39melse\u001b[39;00m  \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb#ch0000031?line=7'>8</a>\u001b[0m     row \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mcandidate_identity\u001b[39m\u001b[39m'\u001b[39m: identity,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb#ch0000031?line=8'>9</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mcandidate_ethnicity\u001b[39m\u001b[39m'\u001b[39m: ethnicity, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb#ch0000031?line=9'>10</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mreference_identity\u001b[39m\u001b[39m'\u001b[39m: reference_identity,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb#ch0000031?line=10'>11</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmatch\u001b[39m\u001b[39m'\u001b[39m: match}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb#ch0000031?line=12'>13</a>\u001b[0m     cos_identification \u001b[39m=\u001b[39m cos_identification\u001b[39m.\u001b[39;49mappend(row,ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/rfw_test.ipynb#ch0000031?line=13'>14</a>\u001b[0m cos_identification\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/pandas/core/frame.py:9036\u001b[0m, in \u001b[0;36mDataFrame.append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mappend\u001b[39m(\n\u001b[1;32m   8930\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   8931\u001b[0m     other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8934\u001b[0m     sort: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   8935\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   8936\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   8937\u001b[0m \u001b[39m    Append rows of `other` to the end of caller, returning a new object.\u001b[39;00m\n\u001b[1;32m   8938\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9029\u001b[0m \u001b[39m    4  4\u001b[39;00m\n\u001b[1;32m   9030\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   9031\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   9032\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe frame.append method is deprecated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   9033\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand will be removed from pandas in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   9034\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse pandas.concat instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   9035\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m-> 9036\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   9037\u001b[0m     )\n\u001b[1;32m   9039\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append(other, ignore_index, verify_integrity, sort)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/pandas/util/_exceptions.py:32\u001b[0m, in \u001b[0;36mfind_stack_level\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_stack_level\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m     28\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m    Find the first place in the stack that is not inside pandas\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    (tests notwithstanding).\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     stack \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mstack()\n\u001b[1;32m     34\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     pkg_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(pd\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/inspect.py:1554\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack\u001b[39m(context\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1553\u001b[0m     \u001b[39m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1554\u001b[0m     \u001b[39mreturn\u001b[39;00m getouterframes(sys\u001b[39m.\u001b[39;49m_getframe(\u001b[39m1\u001b[39;49m), context)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/inspect.py:1531\u001b[0m, in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1529\u001b[0m framelist \u001b[39m=\u001b[39m []\n\u001b[1;32m   1530\u001b[0m \u001b[39mwhile\u001b[39;00m frame:\n\u001b[0;32m-> 1531\u001b[0m     frameinfo \u001b[39m=\u001b[39m (frame,) \u001b[39m+\u001b[39m getframeinfo(frame, context)\n\u001b[1;32m   1532\u001b[0m     framelist\u001b[39m.\u001b[39mappend(FrameInfo(\u001b[39m*\u001b[39mframeinfo))\n\u001b[1;32m   1533\u001b[0m     frame \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mf_back\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/inspect.py:1505\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1503\u001b[0m start \u001b[39m=\u001b[39m lineno \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m context\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m   1504\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     lines, lnum \u001b[39m=\u001b[39m findsource(frame)\n\u001b[1;32m   1506\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1507\u001b[0m     lines \u001b[39m=\u001b[39m index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/inspect.py:829\u001b[0m, in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (file\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m    827\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39msource code not available\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 829\u001b[0m module \u001b[39m=\u001b[39m getmodule(\u001b[39mobject\u001b[39;49m, file)\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m module:\n\u001b[1;32m    831\u001b[0m     lines \u001b[39m=\u001b[39m linecache\u001b[39m.\u001b[39mgetlines(file, module\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/inspect.py:746\u001b[0m, in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39m# Update the filename to module name cache and check yet again\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39m# Copy sys.modules in order to cope with changes while iterating\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[39mfor\u001b[39;00m modname, module \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 746\u001b[0m     \u001b[39mif\u001b[39;00m ismodule(module) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(module, \u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    747\u001b[0m         f \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m\n\u001b[1;32m    748\u001b[0m         \u001b[39mif\u001b[39;00m f \u001b[39m==\u001b[39m _filesbymodname\u001b[39m.\u001b[39mget(modname, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    749\u001b[0m             \u001b[39m# Have already mapped this module, so skip it\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/inspect.py:71\u001b[0m, in \u001b[0;36mismodule\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mismodule\u001b[39m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m     65\u001b[0m     \u001b[39m\"\"\"Return true if the object is a module.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    Module objects provide these attributes:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m        __cached__      pathname to byte compiled file\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m        __doc__         documentation string\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m        __file__        filename (missing for built-in modules)\"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mobject\u001b[39m, types\u001b[39m.\u001b[39mModuleType)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cos_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos.T),total=len(cos.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cos_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cos_identification = cos_identification.append(row,ignore_index=True)\n",
    "cos_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7394\n",
      "7187\n",
      "7238\n",
      "7298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African</td>\n",
       "      <td>0.385718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.432865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.532053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian</td>\n",
       "      <td>0.532201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  accuracy\n",
       "0    African  0.385718\n",
       "1      Asian  0.432865\n",
       "2  Caucasian  0.532053\n",
       "3     Indian  0.532201"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cos_identification.candidate_ethnicity.unique():\n",
    "    eth_cos = cos_identification.loc[cos_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cos.match)/len(eth_cos)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cos_id_acc = cos_id_acc.append(row,ignore_index=True)\n",
    "cos_id_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7394"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
