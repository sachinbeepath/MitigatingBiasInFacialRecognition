{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring RFW data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import models,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import collections\n",
    "from  PIL import Image\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet50']\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=8631, include_top=True):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        if not self.include_top:\n",
    "            return x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "fname = 'weights/resnet50_ft_weight.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    weights = pickle.load(f, encoding='latin1')\n",
    "\n",
    "own_state = model.state_dict()\n",
    "for name, param in weights.items():\n",
    "    if name in own_state:\n",
    "        try:\n",
    "            own_state[name].copy_(torch.from_numpy(param))\n",
    "        except Exception:\n",
    "            raise RuntimeError('While copying the parameter named {}, whose dimensions in the model are {} and whose '\\\n",
    "                                'dimensions in the checkpoint are {}.'.format(name, own_state[name].size(), param.shape))\n",
    "    else:\n",
    "        raise KeyError('unexpected key \"{}\" in state_dict'.format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2_0003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2_0001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2_0002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.026tq86_0001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>m.027nbyf_0002.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304</th>\n",
       "      <td>m.027nbyf_0001.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>m.027nbyf_0005.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0005</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>m.098d5s_0002.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>m.098d5s_0001.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID Ethnicity\n",
       "0       m.0c7mh2_0003.jpg      0   m.0c7mh2   0003   African\n",
       "1       m.0c7mh2_0001.jpg      0   m.0c7mh2   0001   African\n",
       "2       m.0c7mh2_0002.jpg      0   m.0c7mh2   0002   African\n",
       "3      m.026tq86_0003.jpg      1  m.026tq86   0003   African\n",
       "4      m.026tq86_0001.jpg      1  m.026tq86   0001   African\n",
       "...                   ...    ...        ...    ...       ...\n",
       "10303  m.027nbyf_0002.jpg   2982  m.027nbyf   0002    Indian\n",
       "10304  m.027nbyf_0001.jpg   2982  m.027nbyf   0001    Indian\n",
       "10305  m.027nbyf_0005.jpg   2982  m.027nbyf   0005    Indian\n",
       "10306   m.098d5s_0002.jpg   2983   m.098d5s   0002    Indian\n",
       "10307   m.098d5s_0001.jpg   2983   m.098d5s   0001    Indian\n",
       "\n",
       "[40607 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df to contain all identities, their image file names, their ethnicities\n",
    "path = \"data/RFW/images/test/txts/\"\n",
    "img_path = 'data/RFW/images/test/data/'\n",
    "\n",
    "# African images\n",
    "african_images = pd.read_csv(path + 'African/African_images.txt', sep=\"\\t\", header=None)\n",
    "african_images.columns = ['File', 'Label']\n",
    "african_images['identityID'] = african_images['File'].str[:-9]\n",
    "african_images['faceID'] = african_images['File'].str[-8:-4]\n",
    "african_images['Ethnicity'] = 'African'\n",
    "# Asian images\n",
    "asian_images = pd.read_csv(path + 'Asian/Asian_images.txt', sep=\"\\t\", header=None)\n",
    "asian_images.columns = ['File', 'Label']\n",
    "asian_images['identityID'] = asian_images['File'].str[:-9]\n",
    "asian_images['faceID'] = asian_images['File'].str[-8:-4]\n",
    "asian_images['Ethnicity'] = 'Asian'\n",
    "# Caucasian images\n",
    "caucasian_images = pd.read_csv(path + 'Caucasian/Caucasian_images.txt', sep=\"\\t\", header=None)\n",
    "caucasian_images.columns = ['File', 'Label']\n",
    "caucasian_images['identityID'] = caucasian_images['File'].str[:-9]\n",
    "caucasian_images['faceID'] = caucasian_images['File'].str[-8:-4]\n",
    "caucasian_images['Ethnicity'] = 'Caucasian'\n",
    "# Indian images\n",
    "indian_images = pd.read_csv(path + 'Indian/Indian_images.txt', sep=\"\\t\", header=None)\n",
    "indian_images.columns = ['File', 'Label']\n",
    "indian_images['identityID'] = indian_images['File'].str[:-9]\n",
    "indian_images['faceID'] = indian_images['File'].str[-8:-4]\n",
    "indian_images['Ethnicity'] = 'Indian'\n",
    "all_images = pd.concat([african_images,asian_images,caucasian_images,indian_images])\n",
    "all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2_0003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2_0001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2_0002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.026tq86_0001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>m.027nbyf_0002.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304</th>\n",
       "      <td>m.027nbyf_0001.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>m.027nbyf_0005.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0005</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>m.098d5s_0002.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>m.098d5s_0001.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0001</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40520 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID Ethnicity\n",
       "0       m.0c7mh2_0003.jpg      0   m.0c7mh2   0003   African\n",
       "1       m.0c7mh2_0001.jpg      0   m.0c7mh2   0001   African\n",
       "2       m.0c7mh2_0002.jpg      0   m.0c7mh2   0002   African\n",
       "3      m.026tq86_0003.jpg      1  m.026tq86   0003   African\n",
       "4      m.026tq86_0001.jpg      1  m.026tq86   0001   African\n",
       "...                   ...    ...        ...    ...       ...\n",
       "10303  m.027nbyf_0002.jpg   2982  m.027nbyf   0002    Indian\n",
       "10304  m.027nbyf_0001.jpg   2982  m.027nbyf   0001    Indian\n",
       "10305  m.027nbyf_0005.jpg   2982  m.027nbyf   0005    Indian\n",
       "10306   m.098d5s_0002.jpg   2983   m.098d5s   0002    Indian\n",
       "10307   m.098d5s_0001.jpg   2983   m.098d5s   0001    Indian\n",
       "\n",
       "[40520 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any duplicate identities\n",
    "v = all_images.reset_index().groupby('identityID').Ethnicity.nunique()\n",
    "dup = v[v>1].index.tolist()\n",
    "all_images = all_images[~all_images['identityID'].isin(dup)]\n",
    "all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m.0c7mh2_0001.jpg', 'm.026tq86_0001.jpg', 'm.02wz3nc_0001.jpg',\n",
       "       ..., 'm.02793d7_0001.jpg', 'm.027nbyf_0001.jpg',\n",
       "       'm.098d5s_0001.jpg'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first image from each identity and use it as reference\n",
    "identities = np.array(all_images.identityID.unique().tolist()).astype(object)\n",
    "file_end =  np.array('_0001.jpg'.split()*len(identities)).astype(object)\n",
    "first_images = identities + file_end\n",
    "first_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11403 29117\n"
     ]
    }
   ],
   "source": [
    "references = all_images[all_images['File'].isin(first_images)]\n",
    "candidates = all_images[~all_images['File'].isin(first_images)]\n",
    "print(len(references),len(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2_0003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2_0002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m.026tq86_0002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m.02wz3nc_0002.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10301</th>\n",
       "      <td>m.027nbyf_0004.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0004</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>m.027nbyf_0003.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0003</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>m.027nbyf_0002.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>m.027nbyf_0005.jpg</td>\n",
       "      <td>2982</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>0005</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>m.098d5s_0002.jpg</td>\n",
       "      <td>2983</td>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>0002</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29117 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID Ethnicity\n",
       "0       m.0c7mh2_0003.jpg      0   m.0c7mh2   0003   African\n",
       "2       m.0c7mh2_0002.jpg      0   m.0c7mh2   0002   African\n",
       "3      m.026tq86_0003.jpg      1  m.026tq86   0003   African\n",
       "5      m.026tq86_0002.jpg      1  m.026tq86   0002   African\n",
       "6      m.02wz3nc_0002.jpg      2  m.02wz3nc   0002   African\n",
       "...                   ...    ...        ...    ...       ...\n",
       "10301  m.027nbyf_0004.jpg   2982  m.027nbyf   0004    Indian\n",
       "10302  m.027nbyf_0003.jpg   2982  m.027nbyf   0003    Indian\n",
       "10303  m.027nbyf_0002.jpg   2982  m.027nbyf   0002    Indian\n",
       "10305  m.027nbyf_0005.jpg   2982  m.027nbyf   0005    Indian\n",
       "10306   m.098d5s_0002.jpg   2983   m.098d5s   0002    Indian\n",
       "\n",
       "[29117 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class for RFW\n",
    "class resnetRFW(data.Dataset):\n",
    "    \n",
    "    '''\n",
    "    This will be a class to load data from RFW for resnet50 model\n",
    "    '''\n",
    "     \n",
    "    mean_bgr = np.array([91.4953, 103.8827, 131.0912])  # from resnet50_ft.prototxt\n",
    "\n",
    "    def __init__(self,img_path,img_df):\n",
    "        \"\"\"\n",
    "        :param img_path: dataset directory\n",
    "        :param img_df: contains image file names and other information\n",
    "        \"\"\"\n",
    "        assert os.path.exists(img_path), \"root: {} not found.\".format(img_path)\n",
    "        self.img_path = img_path\n",
    "        self.img_df = img_df\n",
    "        self.img_info = []\n",
    "\n",
    "        for i, row in self.img_df.iterrows():\n",
    "            self.img_info.append({\n",
    "                'img_file': row.Ethnicity + '/' + row.identityID + '/' + row.File,\n",
    "                'identityID': row.identityID,\n",
    "                'Ethnicity': row.Ethnicity,\n",
    "                'faceID': row.faceID,\n",
    "            })\n",
    "            if i % 5000 == 0:\n",
    "                print(\"processing: {} images\".format(i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_info)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        info = self.img_info[index]\n",
    "        img_file = info['img_file']\n",
    "        img = Image.open(os.path.join(self.img_path, img_file))\n",
    "        img = transforms.Resize(256)(img)\n",
    "        img = transforms.CenterCrop(224)(img)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        assert len(img.shape) == 3  # assumes color images and no alpha channel\n",
    "\n",
    "        Ethnicity = info['Ethnicity']\n",
    "        identityID = info['identityID']\n",
    "        faceID = info['faceID']\n",
    "        return self.transform(img), identityID, Ethnicity, faceID\n",
    "  \n",
    "\n",
    "    def transform(self, img):\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float32)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose(2, 0, 1)  # C x H x W\n",
    "        img = torch.from_numpy(img).float()\n",
    "        return img\n",
    "\n",
    "    def untransform(self, img, lbl):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        img += self.mean_bgr\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        return img, lbl\n",
    "\n",
    "def load_resnet50(weights=\"weights/resnet50_scratch_weight.pkl\"):\n",
    "    # load resnet50 model and modify it to match the one from the github to load the weights from the pkl\n",
    "# resnet50 trained on VGGFace2\n",
    "    resnet50 = models.resnet50(pretrained=False)\n",
    "    resnet50.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
    "    resnet50.layer2[0].conv1 = nn.Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    resnet50.layer2[0].conv2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    resnet50.layer3[0].conv1 = nn.Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    resnet50.layer3[0].conv2 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    resnet50.layer4[0].conv1 = nn.Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "    resnet50.layer4[0].conv2 = nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    resnet50.avgpool = nn.AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
    "    resnet50.fc = nn.Linear(in_features=2048,out_features=8631)\n",
    "    with open(\"weights/resnet50_scratch_weight.pkl\", 'rb') as f:\n",
    "        weights = pickle.load(f, encoding='latin1')\n",
    "    weights = dict(map(lambda x: (x[0], torch.from_numpy(x[1])), weights.items()))\n",
    "    weights = OrderedDict(weights)\n",
    "    resnet50.load_state_dict(weights)\n",
    "    resnet50 = torch.nn.Sequential(*(list(resnet50.children())[:-1]))\n",
    "    return resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 10000 images\n",
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 10000 images\n",
      "processing: 15000 images\n",
      "processing: 20000 images\n",
      "processing: 25000 images\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "# load reference images\n",
    "reference_dataset = resnetRFW(img_path,references.reset_index(drop=True))\n",
    "reference_loader = torch.utils.data.DataLoader(reference_dataset, batch_size=32, shuffle=False, **kwargs)\n",
    "# load candidate images\n",
    "candidate_dataset = resnetRFW(img_path,candidates.reset_index(drop=True))\n",
    "candidate_loader = torch.utils.data.DataLoader(candidate_dataset, batch_size=32, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# load model and assign weights\n",
    "\n",
    "# resnet50 = load_resnet50(weights=\"weights/resnet50_ft_weight.pkl\")\n",
    "print(device)\n",
    "resnet50 = model.to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model,dataloader,file_prefix,device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    identities = []\n",
    "    ethnicities = []\n",
    "    faceIDs = []\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(dataloader),total=len(dataloader)):\n",
    "            imgs = imgs.to(device)\n",
    "            x = model(imgs)\n",
    "            out = x.view(x.size(0),-1)\n",
    "            outputs.append(out)\n",
    "            identities.append(np.array(identityID))\n",
    "            ethnicities.append(np.array(Ethnicity))\n",
    "            faceIDs.append(np.array(faceID))\n",
    "\n",
    "    outputs=torch.cat(outputs)\n",
    "    identities= np.concatenate(np.array(identities)).ravel()\n",
    "    ethnicities= np.concatenate(np.array(ethnicities)).ravel()\n",
    "    faceIDs= np.concatenate(np.array(faceIDs)).ravel()\n",
    "\n",
    "    torch.save(outputs, file_prefix + '_outputs.pt')\n",
    "    np.save(file_prefix + '_identities.npy', identities)\n",
    "    np.save(file_prefix + '_ethnicities.npy', ethnicities)\n",
    "    np.save(file_prefix + '_faceIDs.npy', faceIDs)\n",
    "    return outputs, identities, ethnicities, faceIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056e396ae96c4136a7fa876bec457a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" outputs = []\\nidentities = []\\nethnicities = []\\nfaceIDs = []\\nwith torch.no_grad():\\n    for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(reference_loader),total=len(reference_loader)):\\n        x = resnet50(imgs)\\n        out = x.view(x.size(0),-1)\\n        outputs.append(out)\\n        identities.append(np.array(identityID))\\n        ethnicities.append(np.array(Ethnicity))\\n        faceIDs.append(np.array(faceID))\\n\\noutputs=torch.cat(outputs)\\nidentities= np.array(identities)\\nethnicities= np.array(ethnicities)\\nfaceIDs= np.array(faceIDs)\\n\\ntorch.save(outputs, 'reference_outputs.pt')\\nnp.save('reference_identities.npy', identities)\\nnp.save('reference_ethnicities.npy', ethnicities)\\nnp.save('reference_faceIDs.npy', faceIDs) \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply model to references\n",
    "\n",
    "reference_outputs, reference_identities, reference_ethnicities, reference_faceIDs = apply_model(resnet50,reference_loader,'outputs/RFW/ft/reference',device)\n",
    "\"\"\" outputs = []\n",
    "identities = []\n",
    "ethnicities = []\n",
    "faceIDs = []\n",
    "with torch.no_grad():\n",
    "    for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(reference_loader),total=len(reference_loader)):\n",
    "        x = resnet50(imgs)\n",
    "        out = x.view(x.size(0),-1)\n",
    "        outputs.append(out)\n",
    "        identities.append(np.array(identityID))\n",
    "        ethnicities.append(np.array(Ethnicity))\n",
    "        faceIDs.append(np.array(faceID))\n",
    "\n",
    "outputs=torch.cat(outputs)\n",
    "identities= np.array(identities)\n",
    "ethnicities= np.array(ethnicities)\n",
    "faceIDs= np.array(faceIDs)\n",
    "\n",
    "torch.save(outputs, 'reference_outputs.pt')\n",
    "np.save('reference_identities.npy', identities)\n",
    "np.save('reference_ethnicities.npy', ethnicities)\n",
    "np.save('reference_faceIDs.npy', faceIDs) \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c62703c3ab4d65811c47f4fea0d934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000017?line=0'>1</a>\u001b[0m \u001b[39m# apply model to candidates\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000017?line=2'>3</a>\u001b[0m candidate_outputs, candidate_identities, candidate_ethnicities, candidate_faceIDs \u001b[39m=\u001b[39m apply_model(resnet50,candidate_loader,\u001b[39m'\u001b[39;49m\u001b[39moutputs/RFW/ft/candidate\u001b[39;49m\u001b[39m'\u001b[39;49m,device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000017?line=3'>4</a>\u001b[0m \u001b[39m\"\"\" with torch.no_grad():\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000017?line=4'>5</a>\u001b[0m \u001b[39m    for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(candidate_loader),total=len(candidate_loader)):\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000017?line=5'>6</a>\u001b[0m \u001b[39m        x = resnet50(imgs)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000017?line=19'>20</a>\u001b[0m \u001b[39mnp.save('candidate_ethnicities.npy', ethnicities)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000017?line=20'>21</a>\u001b[0m \u001b[39mnp.save('candidate_faceIDs.npy', faceIDs) \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb Cell 13'\u001b[0m in \u001b[0;36mapply_model\u001b[0;34m(model, dataloader, file_prefix, device)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000015?line=5'>6</a>\u001b[0m faceIDs \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000015?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000015?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (imgs, identityID, Ethnicity, faceID) \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39menumerate\u001b[39m(dataloader),total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataloader)):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000015?line=8'>9</a>\u001b[0m         imgs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000015?line=9'>10</a>\u001b[0m         x \u001b[39m=\u001b[39m model(imgs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    259\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    261\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:663\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    664\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    666\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    667\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    700\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    703\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb Cell 10'\u001b[0m in \u001b[0;36mresnetRFW.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000012?line=35'>36</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_path, img_file))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000012?line=36'>37</a>\u001b[0m img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mResize(\u001b[39m256\u001b[39m)(img)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000012?line=37'>38</a>\u001b[0m img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39;49mCenterCrop(\u001b[39m224\u001b[39;49m)(img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000012?line=38'>39</a>\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000012?line=39'>40</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(img\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m  \u001b[39m# assumes color images and no alpha channel\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mpsEnv/lib/python3.9/site-packages/torch/nn/modules/module.py:1181\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1181\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1182\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m             \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# apply model to candidates\n",
    "\n",
    "candidate_outputs, candidate_identities, candidate_ethnicities, candidate_faceIDs = apply_model(resnet50,candidate_loader,'outputs/RFW/ft/candidate',device)\n",
    "\"\"\" with torch.no_grad():\n",
    "    for i, (imgs, identityID, Ethnicity, faceID) in tqdm_notebook(enumerate(candidate_loader),total=len(candidate_loader)):\n",
    "        x = resnet50(imgs)\n",
    "        out = x.view(x.size(0),-1)\n",
    "        outputs.append(out)\n",
    "        identities.append(np.array(identityID))\n",
    "        ethnicities.append(np.array(Ethnicity))\n",
    "        faceIDs.append(np.array(faceID))\n",
    "\n",
    "outputs=torch.cat(outputs)\n",
    "identities= np.array(identities)\n",
    "ethnicities= np.array(ethnicities)\n",
    "faceIDs= np.array(faceIDs)\n",
    "\n",
    "torch.save(outputs, 'candidate_outputs.pt')\n",
    "np.save('candidate_identities.npy', identities)\n",
    "np.save('candidate_ethnicities.npy', ethnicities)\n",
    "np.save('candidate_faceIDs.npy', faceIDs) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face verification (1:1)\n",
    "\n",
    "def face_verification(reference, candidate, metric, threshold=None):\n",
    "    ''' \n",
    "    this function performs face verification given a reference face and a candidate face\n",
    "    returns 0 if the faces do not match and 1 if they do\n",
    "    '''\n",
    "    if metric == 'correlation':\n",
    "        if threshold is None:\n",
    "            threshold = 0.8\n",
    "        cor = np.abs(corr2_coeff(reference,candidate))\n",
    "        return cor\n",
    "        \"\"\"if cor > threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\"\"\"\n",
    "        \n",
    "    elif metric == 'cosine':\n",
    "        if threshold is None:\n",
    "            threshold = 0.5\n",
    "        cos = distance.cosine(reference,candidate)\n",
    "        if cos <= threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return \"Please use one of 'correlation', or 'cosine' as an input for metric\"\n",
    "        \n",
    "def corr2_coeff(A, B):\n",
    "    # Rowwise mean of input arrays & subtract from input arrays themeselves\n",
    "    A_mA = A - A.mean(1)[:, None]\n",
    "    B_mB = B - B.mean(1)[:, None]\n",
    "\n",
    "    # Sum of squares across rows\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "\n",
    "    # Finally get corr coeff\n",
    "    return torch.matmul(A_mA, B_mB.T) / torch.sqrt(torch.matmul(ssA[:, None],ssB[None]))\n",
    "def cos_sim(a, b, eps=1e-8):\n",
    "    \"\"\"\n",
    "    added eps for numerical stability\n",
    "    \"\"\"\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11403, 2048]) (11403,) (11403,) (11403,)\n",
      "torch.Size([29117, 2048]) (29117,) (29117,) (29117,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['m.0c7mh2', 'm.0c7mh2', 'm.026tq86', ..., 'm.027nbyf', 'm.027nbyf',\n",
       "       'm.098d5s'], dtype='<U10')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for now since i didnt update the files i have to ravel here otherwise just load normally\n",
    "\n",
    "'''reference_outputs = torch.load(\"outputs/RFW/reference_outputs.pt\")\n",
    "reference_identities = np.concatenate(np.load('outputs/RFW/reference_identities.npy',allow_pickle=True)).ravel()\n",
    "reference_ethnicities = np.concatenate(np.load('outputs/RFW/reference_ethnicities.npy',allow_pickle=True)).ravel()\n",
    "reference_faceIDs = np.concatenate(np.load('outputs/RFW/reference_faceIDs.npy',allow_pickle=True)).ravel()\n",
    "print(reference_outputs.shape,reference_identities.shape,reference_ethnicities.shape,reference_faceIDs.shape)\n",
    "\n",
    "candidate_outputs = torch.load(\"outputs/RFW/candidate_outputs.pt\")\n",
    "candidate_identities = np.concatenate(np.load('outputs/RFW/candidate_identities.npy',allow_pickle=True)).ravel()\n",
    "candidate_ethnicities = np.concatenate(np.load('outputs/RFW/candidate_ethnicities.npy',allow_pickle=True)).ravel()\n",
    "candidate_faceIDs = np.concatenate(np.load('outputs/RFW/candidate_faceIDs.npy',allow_pickle=True)).ravel()\n",
    "print(candidate_outputs.shape,candidate_identities.shape,candidate_ethnicities.shape,candidate_faceIDs.shape)\n",
    "\n",
    "candidate_identities'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11403, 2048]) (11403,) (11403,) (11403,)\n",
      "torch.Size([29117, 2048]) (29117,) (29117,) (29117,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['m.0c7mh2', 'm.0c7mh2', 'm.026tq86', ..., 'm.027nbyf', 'm.027nbyf',\n",
       "       'm.098d5s'], dtype='<U10')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reference_outputs = torch.load(\"outputs/RFW/ft/reference_outputs.pt\")\n",
    "reference_identities = np.load('outputs/RFW/ft/reference_identities.npy',allow_pickle=True)\n",
    "reference_ethnicities = np.load('outputs/RFW/ft/reference_ethnicities.npy',allow_pickle=True)\n",
    "reference_faceIDs = np.load('outputs/RFW/ft/reference_faceIDs.npy',allow_pickle=True)\n",
    "print(reference_outputs.shape,reference_identities.shape,reference_ethnicities.shape,reference_faceIDs.shape)\n",
    "\n",
    "candidate_outputs = torch.load(\"outputs/RFW/ft/candidate_outputs.pt\")\n",
    "candidate_identities = np.load('outputs/RFW/ft/candidate_identities.npy',allow_pickle=True)\n",
    "candidate_ethnicities = np.load('outputs/RFW/ft/candidate_ethnicities.npy',allow_pickle=True)\n",
    "candidate_faceIDs = np.load('outputs/RFW/ft/candidate_faceIDs.npy',allow_pickle=True)\n",
    "print(candidate_outputs.shape,candidate_identities.shape,candidate_ethnicities.shape,candidate_faceIDs.shape)\n",
    "\n",
    "candidate_identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = corr2_coeff(reference_outputs,candidate_outputs).cpu().detach().numpy()\n",
    "cos = cos_sim(reference_outputs,candidate_outputs).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.7\n",
    "verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity', 'cor_matches', 'cos_matches'])\n",
    "for i, (cor_row, cos_row) in tqdm_notebook(enumerate(zip(cor,cos)),total=len(cor)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  match_cor = candidate_identities[cor_row>thresh]\n",
    "  match_cos = candidate_identities[cos_row>thresh]  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'cor_matches': match_cor, \n",
    "           'cos_matches': match_cos}\n",
    "  verification = verification.append(row,ignore_index=True)\n",
    "\n",
    "verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52cfe300c6c499b9faba771a662010b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>matches</th>\n",
       "      <th>not_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>m.0974m7</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0974m7, m.0974m7]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>m.0k00nk</td>\n",
       "      <td>African</td>\n",
       "      <td>3</td>\n",
       "      <td>29114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0k00nk, m.0k00nk, m.0k00nk]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>m.01ky6fb</td>\n",
       "      <td>African</td>\n",
       "      <td>4</td>\n",
       "      <td>29113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.01ky6fb, m.01ky6fb, m.01ky6fb, m.01ky6fb]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>m.05zl3c</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.05zl3c, m.05zl3c]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>m.02z21c6</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.02z21c6, m.02z21c6]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11034</th>\n",
       "      <td>m.0h3ry9b</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0h3ry9b, m.0h3ry9b]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11037</th>\n",
       "      <td>m.0593ll</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0593ll, m.0593ll]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>m.04jb36f</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.04jb36f, m.04jb36f]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200</th>\n",
       "      <td>m.01yv6p</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.01yv6p, m.01yv6p]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11308</th>\n",
       "      <td>m.0744sc</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0744sc, m.0744sc]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity reference_ethnicity TP     TN FP FN  \\\n",
       "324             m.0974m7             African  2  29115  0  0   \n",
       "406             m.0k00nk             African  3  29114  0  0   \n",
       "441            m.01ky6fb             African  4  29113  0  0   \n",
       "542             m.05zl3c             African  2  29115  0  0   \n",
       "641            m.02z21c6             African  2  29115  0  0   \n",
       "...                  ...                 ... ..    ... .. ..   \n",
       "11034          m.0h3ry9b              Indian  2  29115  0  0   \n",
       "11037           m.0593ll              Indian  2  29115  0  0   \n",
       "11195          m.04jb36f              Indian  2  29115  0  0   \n",
       "11200           m.01yv6p              Indian  2  29115  0  0   \n",
       "11308           m.0744sc              Indian  2  29115  0  0   \n",
       "\n",
       "                                            matches  \\\n",
       "324                            [m.0974m7, m.0974m7]   \n",
       "406                  [m.0k00nk, m.0k00nk, m.0k00nk]   \n",
       "441    [m.01ky6fb, m.01ky6fb, m.01ky6fb, m.01ky6fb]   \n",
       "542                            [m.05zl3c, m.05zl3c]   \n",
       "641                          [m.02z21c6, m.02z21c6]   \n",
       "...                                             ...   \n",
       "11034                        [m.0h3ry9b, m.0h3ry9b]   \n",
       "11037                          [m.0593ll, m.0593ll]   \n",
       "11195                        [m.04jb36f, m.04jb36f]   \n",
       "11200                          [m.01yv6p, m.01yv6p]   \n",
       "11308                          [m.0744sc, m.0744sc]   \n",
       "\n",
       "                                             not_matches  \n",
       "324    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "406    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "441    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "542    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "641    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "...                                                  ...  \n",
       "11034  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11037  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11195  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11200  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11308  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "\n",
       "[280 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresh = 0.65\n",
    "cos_verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity','TP','TN','FP','FN','matches','not_matches'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos),total=len(cos)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  matches = candidate_identities[cos_row>thresh]  \n",
    "  not_matches = candidate_identities[cos_row<=thresh]\n",
    "  TP = sum(matches == identity)\n",
    "  FP = sum(matches != identity)\n",
    "  TN = sum(not_matches != identity)\n",
    "  FN = sum(not_matches == identity)\n",
    "  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'TP': TP,\n",
    "           'TN': TN,\n",
    "           'FP': FP,\n",
    "           'FN': FN,\n",
    "           'matches': matches, \n",
    "           'not_matches': not_matches}\n",
    "  cos_verification = cos_verification.append(row,ignore_index=True)\n",
    "\n",
    "cos_verification[cos_verification.FN == 0][cos_verification.FP == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_identity     m.0c7mh2m.026tq86m.02wz3ncm.0c012t4m.0p8s_gxm....\n",
      "reference_ethnicity    AfricanAfricanAfricanAfricanAfricanAfricanAfri...\n",
      "TP                                                                  4728\n",
      "TN                                                              86693849\n",
      "FP                                                                125651\n",
      "FN                                                                  2666\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "African_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'African']\n",
    "print(African_cos.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.0281bfhm.0421bfhm.02r80dqm.06w18lbm.02tcmtm....\n",
       "reference_ethnicity    AsianAsianAsianAsianAsianAsianAsianAsianAsianA...\n",
       "TP                                                                  4613\n",
       "TN                                                              72371880\n",
       "FP                                                                 93146\n",
       "FN                                                                  2574\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Asian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Asian']\n",
    "Asian_cos.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.05zdk2m.04064_hm.06414fsm.0dtsglm.02ww2f6m.0...\n",
       "reference_ethnicity    IndianIndianIndianIndianIndianIndianIndianIndi...\n",
       "TP                                                                  4944\n",
       "TN                                                              86531724\n",
       "FP                                                                 54936\n",
       "FN                                                                  2354\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Indian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Indian']\n",
    "Indian_cos.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference_identity     m.0cqh0qm.02r6ydbm.0415yw4m.049pq8m.03cdg6lm.0...\n",
       "reference_ethnicity    CaucasianCaucasianCaucasianCaucasianCaucasianC...\n",
       "TP                                                                  3914\n",
       "TN                                                              86110744\n",
       "FP                                                                 10104\n",
       "FN                                                                  3324\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Caucasian_cos = cos_verification.loc[cos_verification.reference_ethnicity == 'Caucasian']\n",
    "Caucasian_cos.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cd3732b6f74f3488e2640c759595c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>matches</th>\n",
       "      <th>not_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>m.03dwmn</td>\n",
       "      <td>African</td>\n",
       "      <td>1</td>\n",
       "      <td>29116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.03dwmn]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>m.033mrs</td>\n",
       "      <td>African</td>\n",
       "      <td>3</td>\n",
       "      <td>29114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.033mrs, m.033mrs, m.033mrs]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>m.04_zbx</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.04_zbx, m.04_zbx]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>m.0g5576</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0g5576, m.0g5576]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>m.0ngtn1l</td>\n",
       "      <td>African</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0ngtn1l, m.0ngtn1l]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11341</th>\n",
       "      <td>m.026n0ps</td>\n",
       "      <td>Indian</td>\n",
       "      <td>1</td>\n",
       "      <td>29116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.026n0ps]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11353</th>\n",
       "      <td>m.0h19lp</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>29115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0h19lp, m.0h19lp]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11354</th>\n",
       "      <td>m.0cz9878</td>\n",
       "      <td>Indian</td>\n",
       "      <td>1</td>\n",
       "      <td>29116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.0cz9878]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11374</th>\n",
       "      <td>m.03h654p</td>\n",
       "      <td>Indian</td>\n",
       "      <td>4</td>\n",
       "      <td>29113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.03h654p, m.03h654p, m.03h654p, m.03h654p]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>m.07pkcf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>3</td>\n",
       "      <td>29114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[m.07pkcf, m.07pkcf, m.07pkcf]</td>\n",
       "      <td>[m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity reference_ethnicity TP     TN FP FN  \\\n",
       "38              m.03dwmn             African  1  29116  0  0   \n",
       "71              m.033mrs             African  3  29114  0  0   \n",
       "74              m.04_zbx             African  2  29115  0  0   \n",
       "76              m.0g5576             African  2  29115  0  0   \n",
       "112            m.0ngtn1l             African  2  29115  0  0   \n",
       "...                  ...                 ... ..    ... .. ..   \n",
       "11341          m.026n0ps              Indian  1  29116  0  0   \n",
       "11353           m.0h19lp              Indian  2  29115  0  0   \n",
       "11354          m.0cz9878              Indian  1  29116  0  0   \n",
       "11374          m.03h654p              Indian  4  29113  0  0   \n",
       "11379           m.07pkcf              Indian  3  29114  0  0   \n",
       "\n",
       "                                            matches  \\\n",
       "38                                       [m.03dwmn]   \n",
       "71                   [m.033mrs, m.033mrs, m.033mrs]   \n",
       "74                             [m.04_zbx, m.04_zbx]   \n",
       "76                             [m.0g5576, m.0g5576]   \n",
       "112                          [m.0ngtn1l, m.0ngtn1l]   \n",
       "...                                             ...   \n",
       "11341                                   [m.026n0ps]   \n",
       "11353                          [m.0h19lp, m.0h19lp]   \n",
       "11354                                   [m.0cz9878]   \n",
       "11374  [m.03h654p, m.03h654p, m.03h654p, m.03h654p]   \n",
       "11379                [m.07pkcf, m.07pkcf, m.07pkcf]   \n",
       "\n",
       "                                             not_matches  \n",
       "38     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "71     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "74     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "76     [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "112    [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "...                                                  ...  \n",
       "11341  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11353  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11354  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11374  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "11379  [m.0c7mh2, m.0c7mh2, m.026tq86, m.026tq86, m.0...  \n",
       "\n",
       "[713 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresh = 0.65\n",
    "cor_verification = pd.DataFrame(columns=['reference_identity','reference_ethnicity','TP','TN','FP','FN','matches','not_matches'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor),total=len(cor)):\n",
    "  identity = reference_identities[i]\n",
    "  ethnicity = reference_ethnicities[i]\n",
    "  matches = candidate_identities[cor_row>thresh]  \n",
    "  not_matches = candidate_identities[cor_row<=thresh]\n",
    "  TP = sum(matches == identity)\n",
    "  FP = sum(matches != identity)\n",
    "  TN = sum(not_matches != identity)\n",
    "  FN = sum(not_matches == identity)\n",
    "  \n",
    "\n",
    "  row = {'reference_identity': identity,\n",
    "           'reference_ethnicity': ethnicity, \n",
    "           'TP': TP,\n",
    "           'TN': TN,\n",
    "           'FP': FP,\n",
    "           'FN': FN,\n",
    "           'matches': matches, \n",
    "           'not_matches': not_matches}\n",
    "  cor_verification = cor_verification.append(row,ignore_index=True)\n",
    "\n",
    "cor_verification[cor_verification.FN == 0][cor_verification.FP == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "African_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'African']\n",
    "African_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Asian_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'Asian']\n",
    "Asian_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indian_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'Indian']\n",
    "Indian_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Caucasian_cor = cor_verification.loc[cor_verification.reference_ethnicity == 'Caucasian']\n",
    "Caucasian_cor.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1446446c7d34c059505bc8743d48907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9aa740beb744e38271466d128aa406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African</td>\n",
       "      <td>0.385718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.432865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.532053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian</td>\n",
       "      <td>0.532201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  accuracy\n",
       "0    African  0.385718\n",
       "1      Asian  0.432865\n",
       "2  Caucasian  0.532053\n",
       "3     Indian  0.532201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Face Identification\n",
    "\n",
    "'''\n",
    "here i want to do face identification\n",
    "basically take the outputs from the candidates and check against all references\n",
    "take the reference image that has highest correlation/similarity\n",
    "if the identities match then correct otherwise wrong\n",
    "'''\n",
    "\n",
    "cor_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor.T),total=len(cor.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cor_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cor_identification = cor_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos.T),total=len(cos.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cos_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cos_identification = cos_identification.append(row,ignore_index=True)\n",
    "\n",
    "cos_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cos_identification.candidate_ethnicity.unique():\n",
    "    eth_cos = cos_identification.loc[cos_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cos.match)/len(eth_cos)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cos_id_acc = cos_id_acc.append(row,ignore_index=True)\n",
    "cos_id_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African</td>\n",
       "      <td>0.384636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.430639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.532191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian</td>\n",
       "      <td>0.528775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  accuracy\n",
       "0    African  0.384636\n",
       "1      Asian  0.430639\n",
       "2  Caucasian  0.532191\n",
       "3     Indian  0.528775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cor_identification.candidate_ethnicity.unique():\n",
    "    eth_cor = cor_identification.loc[cor_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cor.match)/len(eth_cor)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cor_id_acc = cor_id_acc.append(row,ignore_index=True)\n",
    "cor_id_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6257814 , 0.35835811, 0.47202954, ..., 0.2597217 , 0.2957376 ,\n",
       "       0.3611128 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.max(cos_sim(candidate_outputs,reference_outputs),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6257814 , 0.35835811, 0.47202954, ..., 0.2597218 , 0.2957372 ,\n",
       "       0.361113  ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos_sim(candidate_outputs,reference_outputs)[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2228ae1ac774b9390c06e9281934dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0n_gk9j</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>m.02qvybd</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0dm44t</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.0hrgxh3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29113</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29114</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.06zrlyg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29116</th>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.02679cm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29117 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      candidate_identity candidate_ethnicity reference_identity  match\n",
       "0               m.0c7mh2             African          m.0n_gk9j    0.0\n",
       "1               m.0c7mh2             African           m.0c7mh2    1.0\n",
       "2              m.026tq86             African          m.026tq86    1.0\n",
       "3              m.026tq86             African          m.02qvybd    0.0\n",
       "4              m.02wz3nc             African           m.0dm44t    0.0\n",
       "...                  ...                 ...                ...    ...\n",
       "29112          m.027nbyf              Indian          m.0hrgxh3    0.0\n",
       "29113          m.027nbyf              Indian          m.027nbyf    1.0\n",
       "29114          m.027nbyf              Indian          m.06zrlyg    0.0\n",
       "29115          m.027nbyf              Indian          m.027nbyf    1.0\n",
       "29116           m.098d5s              Indian          m.02679cm    0.0\n",
       "\n",
       "[29117 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cor_row in tqdm_notebook(enumerate(cor.T),total=len(cor.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cor_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cor_identification = cor_identification.append(row,ignore_index=True)\n",
    "cor_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011d0f39d18e446d9f78ec2d377823df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0n_gk9j</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>m.02qvybd</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>African</td>\n",
       "      <td>m.0dm44t</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.0hrgxh3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29113</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29114</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.06zrlyg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115</th>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.027nbyf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29116</th>\n",
       "      <td>m.098d5s</td>\n",
       "      <td>Indian</td>\n",
       "      <td>m.02679cm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29117 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      candidate_identity candidate_ethnicity reference_identity  match\n",
       "0               m.0c7mh2             African          m.0n_gk9j    0.0\n",
       "1               m.0c7mh2             African           m.0c7mh2    1.0\n",
       "2              m.026tq86             African          m.026tq86    1.0\n",
       "3              m.026tq86             African          m.02qvybd    0.0\n",
       "4              m.02wz3nc             African           m.0dm44t    0.0\n",
       "...                  ...                 ...                ...    ...\n",
       "29112          m.027nbyf              Indian          m.0hrgxh3    0.0\n",
       "29113          m.027nbyf              Indian          m.027nbyf    1.0\n",
       "29114          m.027nbyf              Indian          m.06zrlyg    0.0\n",
       "29115          m.027nbyf              Indian          m.027nbyf    1.0\n",
       "29116           m.098d5s              Indian          m.02679cm    0.0\n",
       "\n",
       "[29117 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos_identification = pd.DataFrame(columns=['candidate_identity','candidate_ethnicity','reference_identity'])\n",
    "for i, cos_row in tqdm_notebook(enumerate(cos.T),total=len(cos.T)):\n",
    "    identity = candidate_identities[i]\n",
    "    ethnicity = candidate_ethnicities[i]\n",
    "    max_ref = np.argmax(cos_row)\n",
    "    reference_identity = reference_identities[max_ref]\n",
    "    match = 1 if identity == reference_identity else  0\n",
    "    row = {'candidate_identity': identity,\n",
    "            'candidate_ethnicity': ethnicity, \n",
    "            'reference_identity': reference_identity,\n",
    "            'match': match}\n",
    "\n",
    "    cos_identification = cos_identification.append(row,ignore_index=True)\n",
    "cos_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7394\n",
      "7187\n",
      "7238\n",
      "7298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African</td>\n",
       "      <td>0.385718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.432865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.532053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian</td>\n",
       "      <td>0.532201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity  accuracy\n",
       "0    African  0.385718\n",
       "1      Asian  0.432865\n",
       "2  Caucasian  0.532053\n",
       "3     Indian  0.532201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos_id_acc = pd.DataFrame(columns=['ethnicity','accuracy'])\n",
    "for ethnicity in cos_identification.candidate_ethnicity.unique():\n",
    "    eth_cos = cos_identification.loc[cos_identification.candidate_ethnicity == ethnicity]\n",
    "    accuracy = sum(eth_cos.match)/len(eth_cos)\n",
    "    #print(len(eth_cos))\n",
    "    row = {'ethnicity': ethnicity,\n",
    "            'accuracy': accuracy}\n",
    "\n",
    "    cos_id_acc = cos_id_acc.append(row,ignore_index=True)\n",
    "cos_id_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macOS-12.4-arm64-arm-64bit'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'has_mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb Cell 39'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/fix_resnet.ipynb#ch0000041?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mhas_mps\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'has_mps'"
     ]
    }
   ],
   "source": [
    "torch.has_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
