{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import models,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import collections\n",
    "from  PIL import Image\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "from itertools import product\n",
    "import senet50\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = senet50.make_model()\n",
    "fname = 'weights/senet50_ft_weight.pkl'\n",
    "with open(fname, 'rb') as f:\n",
    "    weights = pickle.load(f, encoding='latin1')\n",
    "\n",
    "own_state = model_scratch.state_dict()\n",
    "for name, param in weights.items():\n",
    "    if name in own_state:\n",
    "        try:\n",
    "            own_state[name].copy_(torch.from_numpy(param))\n",
    "        except Exception:\n",
    "            raise RuntimeError('While copying the parameter named {}, whose dimensions in the model are {} and whose '\\\n",
    "                                'dimensions in the checkpoint are {}.'.format(name, own_state[name].size(), param.shape))\n",
    "    else:\n",
    "        raise KeyError('unexpected key \"{}\" in state_dict'.format(name))\n",
    "model_scratch = model_scratch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2_0001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.026tq86_0001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>m.02wz3nc_0001.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m.0c012t4_0001.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>m.0c012t4</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>m.0p8s_gx_0001.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>m.0p8s_gx</td>\n",
       "      <td>0001</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10179</th>\n",
       "      <td>m.0gchs9h_0001.jpg</td>\n",
       "      <td>2954</td>\n",
       "      <td>m.0gchs9h</td>\n",
       "      <td>0001</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10182</th>\n",
       "      <td>m.0bf61__0001.jpg</td>\n",
       "      <td>2955</td>\n",
       "      <td>m.0bf61_</td>\n",
       "      <td>0001</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10187</th>\n",
       "      <td>m.08pys0_0001.jpg</td>\n",
       "      <td>2956</td>\n",
       "      <td>m.08pys0</td>\n",
       "      <td>0001</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10191</th>\n",
       "      <td>m.0d3dsv_0001.jpg</td>\n",
       "      <td>2957</td>\n",
       "      <td>m.0d3dsv</td>\n",
       "      <td>0001</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>m.01g00c_0001.jpg</td>\n",
       "      <td>2958</td>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>0001</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5953 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID  Ethnicity\n",
       "1       m.0c7mh2_0001.jpg      0   m.0c7mh2   0001    African\n",
       "4      m.026tq86_0001.jpg      1  m.026tq86   0001    African\n",
       "8      m.02wz3nc_0001.jpg      2  m.02wz3nc   0001    African\n",
       "9      m.0c012t4_0001.jpg      3  m.0c012t4   0001    African\n",
       "13     m.0p8s_gx_0001.jpg      4  m.0p8s_gx   0001    African\n",
       "...                   ...    ...        ...    ...        ...\n",
       "10179  m.0gchs9h_0001.jpg   2954  m.0gchs9h   0001  Caucasian\n",
       "10182   m.0bf61__0001.jpg   2955   m.0bf61_   0001  Caucasian\n",
       "10187   m.08pys0_0001.jpg   2956   m.08pys0   0001  Caucasian\n",
       "10191   m.0d3dsv_0001.jpg   2957   m.0d3dsv   0001  Caucasian\n",
       "10195   m.01g00c_0001.jpg   2958   m.01g00c   0001  Caucasian\n",
       "\n",
       "[5953 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load data \n",
    "# create df to contain all identities, their image file names, their ethnicities\n",
    "path = \"data/RFW/images/test/txts/\"\n",
    "img_path = 'data/RFW/images/test/data/'\n",
    "\n",
    "# African images\n",
    "african_images = pd.read_csv(path + 'African/African_images.txt', sep=\"\\t\", header=None)\n",
    "african_images.columns = ['File', 'Label']\n",
    "african_images['identityID'] = african_images['File'].str[:-9]\n",
    "african_images['faceID'] = african_images['File'].str[-8:-4]\n",
    "african_images['Ethnicity'] = 'African'\n",
    "\n",
    "# Caucasian images\n",
    "caucasian_images = pd.read_csv(path + 'Caucasian/Caucasian_images.txt', sep=\"\\t\", header=None)\n",
    "caucasian_images.columns = ['File', 'Label']\n",
    "caucasian_images['identityID'] = caucasian_images['File'].str[:-9]\n",
    "caucasian_images['faceID'] = caucasian_images['File'].str[-8:-4]\n",
    "caucasian_images['Ethnicity'] = 'Caucasian'\n",
    "\n",
    "all_images = pd.concat([african_images,caucasian_images])\n",
    "\n",
    "# remove any duplicate identities\n",
    "v = all_images.reset_index().groupby('identityID').Ethnicity.nunique()\n",
    "dup = v[v>1].index.tolist()\n",
    "all_images = all_images[~all_images['identityID'].isin(dup)]\n",
    "\n",
    "# get first image from each identity and use it as reference\n",
    "identities = np.array(all_images.identityID.unique().tolist()).astype(object)\n",
    "file_end =  np.array('_0001.jpg'.split()*len(identities)).astype(object)\n",
    "first_images = identities + file_end\n",
    "\n",
    "references = all_images[all_images['File'].isin(first_images)]\n",
    "candidates = all_images[~all_images['File'].isin(first_images)]\n",
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>identityID</th>\n",
       "      <th>faceID</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2_0003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2_0002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0003</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m.026tq86_0002.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m.02wz3nc_0002.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>0002</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10189</th>\n",
       "      <td>m.08pys0_0005.jpg</td>\n",
       "      <td>2956</td>\n",
       "      <td>m.08pys0</td>\n",
       "      <td>0005</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10190</th>\n",
       "      <td>m.08pys0_0003.jpg</td>\n",
       "      <td>2956</td>\n",
       "      <td>m.08pys0</td>\n",
       "      <td>0003</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10192</th>\n",
       "      <td>m.0d3dsv_0002.jpg</td>\n",
       "      <td>2957</td>\n",
       "      <td>m.0d3dsv</td>\n",
       "      <td>0002</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10193</th>\n",
       "      <td>m.0d3dsv_0003.jpg</td>\n",
       "      <td>2957</td>\n",
       "      <td>m.0d3dsv</td>\n",
       "      <td>0003</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10194</th>\n",
       "      <td>m.01g00c_0002.jpg</td>\n",
       "      <td>2958</td>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>0002</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14658 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File  Label identityID faceID  Ethnicity\n",
       "0       m.0c7mh2_0003.jpg      0   m.0c7mh2   0003    African\n",
       "2       m.0c7mh2_0002.jpg      0   m.0c7mh2   0002    African\n",
       "3      m.026tq86_0003.jpg      1  m.026tq86   0003    African\n",
       "5      m.026tq86_0002.jpg      1  m.026tq86   0002    African\n",
       "6      m.02wz3nc_0002.jpg      2  m.02wz3nc   0002    African\n",
       "...                   ...    ...        ...    ...        ...\n",
       "10189   m.08pys0_0005.jpg   2956   m.08pys0   0005  Caucasian\n",
       "10190   m.08pys0_0003.jpg   2956   m.08pys0   0003  Caucasian\n",
       "10192   m.0d3dsv_0002.jpg   2957   m.0d3dsv   0002  Caucasian\n",
       "10193   m.0d3dsv_0003.jpg   2957   m.0d3dsv   0003  Caucasian\n",
       "10194   m.01g00c_0002.jpg   2958   m.01g00c   0002  Caucasian\n",
       "\n",
       "[14658 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class for RFW\n",
    "class senetRFW(data.Dataset):\n",
    "    \n",
    "    '''\n",
    "    This will be a class to load data from RFW for senet50 model\n",
    "    '''\n",
    "     \n",
    "    mean_bgr = np.array([91.4953, 103.8827, 131.0912])  # from senet50_ft.prototxt\n",
    "\n",
    "    def __init__(self,img_path,img_df):\n",
    "        \"\"\"\n",
    "        :param img_path: dataset directory\n",
    "        :param img_df: contains image file names and other information\n",
    "        \"\"\"\n",
    "        assert os.path.exists(img_path), \"root: {} not found.\".format(img_path)\n",
    "        self.img_path = img_path\n",
    "        self.img_df = img_df\n",
    "        self.img_info = []\n",
    "\n",
    "        for i, row in self.img_df.iterrows():\n",
    "            self.img_info.append({\n",
    "                'img_file': row.Ethnicity + '/' + row.identityID + '/' + row.File,\n",
    "                'identityID': row.identityID,\n",
    "                'Ethnicity': row.Ethnicity,\n",
    "                'faceID': row.faceID,\n",
    "            })\n",
    "            if i % 5000 == 0:\n",
    "                print(\"processing: {} images\".format(i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_info)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        info = self.img_info[index]\n",
    "        img_file = info['img_file']\n",
    "        img = Image.open(os.path.join(self.img_path, img_file))\n",
    "        img = transforms.Resize(256)(img)\n",
    "        img = transforms.CenterCrop(224)(img)\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        assert len(img.shape) == 3  # assumes color images and no alpha channel\n",
    "\n",
    "        Ethnicity = info['Ethnicity']\n",
    "        identityID = info['identityID']\n",
    "        faceID = info['faceID']\n",
    "        return self.transform(img), identityID, Ethnicity\n",
    "  \n",
    "\n",
    "    def transform(self, img):\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float32)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose(2, 0, 1)  # C x H x W\n",
    "        img = torch.from_numpy(img).float()\n",
    "        return img\n",
    "\n",
    "    def untransform(self, img, lbl):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        #img += self.mean_bgr\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        return img, lbl\n",
    "\n",
    "def apply_model(model,dataloader,device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    identities = []\n",
    "    ethnicities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (imgs, identityID, ethnicity) in tqdm_notebook(enumerate(dataloader),total=len(dataloader)):\n",
    "            imgs = imgs.to(device)\n",
    "            x = model(imgs)\n",
    "            out = x.view(x.size(0),-1)\n",
    "            outputs.append(out)\n",
    "            identities.append(np.array(identityID))\n",
    "            ethnicities.append(np.array(ethnicity))\n",
    "\n",
    "    outputs=torch.cat(outputs)\n",
    "    identities= np.concatenate(np.array(identities)).ravel()\n",
    "    ethnicities= np.concatenate(np.array(ethnicities)).ravel()\n",
    "\n",
    "    # torch.save(outputs, file_prefix + '_outputs.pt')\n",
    "    # np.save(file_prefix + '_identities.npy', identities)\n",
    "    # np.save(file_prefix + '_ethnicities.npy', ethnicities)\n",
    "    # np.save(file_prefix + '_faceIDs.npy', genders)\n",
    "    return outputs, identities, ethnicities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 0 images\n",
      "processing: 5000 images\n",
      "processing: 10000 images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11540d6ef2d742f5880cdf47e02c48bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c6020afc364b4f8a5de925437bd927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3665 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "# load reference images\n",
    "reference_dataset = senetRFW(img_path,references.reset_index(drop=True))\n",
    "reference_loader = torch.utils.data.DataLoader(reference_dataset, batch_size=4, shuffle=False, **kwargs)\n",
    "# load candidate images\n",
    "candidate_dataset = senetRFW(img_path,candidates.reset_index(drop=True))\n",
    "candidate_loader = torch.utils.data.DataLoader(candidate_dataset, batch_size=4, shuffle=False, **kwargs)\n",
    "\n",
    "reference_outputs, reference_identities, reference_ethnicities = apply_model(model_scratch,reference_loader,device)\n",
    "candidate_outputs, candidate_identities, candidate_ethnicities = apply_model(model_scratch,candidate_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_outputs_list = []\n",
    "for output in reference_outputs.cpu().numpy():\n",
    "    reference_outputs_list.append(output)\n",
    "candidate_outputs_list = []\n",
    "for output in candidate_outputs.cpu().numpy():\n",
    "    candidate_outputs_list.append(output)\n",
    "output_references = {'outputs': reference_outputs_list, 'identity': reference_identities,'ethnicity': reference_ethnicities}\n",
    "output_references = pd.DataFrame(output_references)\n",
    "\n",
    "output_candidates = {'outputs': candidate_outputs_list, 'identity': candidate_identities,'ethnicity': candidate_ethnicities}\n",
    "output_candidates = pd.DataFrame(output_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259069</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.08pys0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259070</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.08pys0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259071</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.0d3dsv</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259072</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.0d3dsv</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259073</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87259074 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reference_identity candidate_identity reference_ethnicity  \\\n",
       "0                  m.0c7mh2           m.0c7mh2             African   \n",
       "1                  m.0c7mh2           m.0c7mh2             African   \n",
       "2                  m.0c7mh2          m.026tq86             African   \n",
       "3                  m.0c7mh2          m.026tq86             African   \n",
       "4                  m.0c7mh2          m.02wz3nc             African   \n",
       "...                     ...                ...                 ...   \n",
       "87259069           m.01g00c           m.08pys0           Caucasian   \n",
       "87259070           m.01g00c           m.08pys0           Caucasian   \n",
       "87259071           m.01g00c           m.0d3dsv           Caucasian   \n",
       "87259072           m.01g00c           m.0d3dsv           Caucasian   \n",
       "87259073           m.01g00c           m.01g00c           Caucasian   \n",
       "\n",
       "         candidate_ethnicity  \n",
       "0                    African  \n",
       "1                    African  \n",
       "2                    African  \n",
       "3                    African  \n",
       "4                    African  \n",
       "...                      ...  \n",
       "87259069           Caucasian  \n",
       "87259070           Caucasian  \n",
       "87259071           Caucasian  \n",
       "87259072           Caucasian  \n",
       "87259073           Caucasian  \n",
       "\n",
       "[87259074 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.array(list(product(output_references['identity'], output_candidates['identity'])))\n",
    "ethnicities = np.array(list(product(output_references['ethnicity'], output_candidates['ethnicity'])))\n",
    "logistic_df = { \n",
    "                'reference_identity': ids[:,0],'candidate_identity': ids[:,1],\n",
    "                'reference_ethnicity': ethnicities[:,0],'candidate_ethnicity': ethnicities[:,1]}\n",
    "logistic_df = pd.DataFrame(logistic_df)\n",
    "logistic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259069</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.08pys0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259070</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.08pys0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259071</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.0d3dsv</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259072</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.0d3dsv</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87259073</th>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>m.01g00c</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43632904 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reference_identity candidate_identity reference_ethnicity  \\\n",
       "0                  m.0c7mh2           m.0c7mh2             African   \n",
       "1                  m.0c7mh2           m.0c7mh2             African   \n",
       "2                  m.0c7mh2          m.026tq86             African   \n",
       "3                  m.0c7mh2          m.026tq86             African   \n",
       "4                  m.0c7mh2          m.02wz3nc             African   \n",
       "...                     ...                ...                 ...   \n",
       "87259069           m.01g00c           m.08pys0           Caucasian   \n",
       "87259070           m.01g00c           m.08pys0           Caucasian   \n",
       "87259071           m.01g00c           m.0d3dsv           Caucasian   \n",
       "87259072           m.01g00c           m.0d3dsv           Caucasian   \n",
       "87259073           m.01g00c           m.01g00c           Caucasian   \n",
       "\n",
       "         candidate_ethnicity  labels  \n",
       "0                    African       1  \n",
       "1                    African       1  \n",
       "2                    African       0  \n",
       "3                    African       0  \n",
       "4                    African       0  \n",
       "...                      ...     ...  \n",
       "87259069           Caucasian       0  \n",
       "87259070           Caucasian       0  \n",
       "87259071           Caucasian       0  \n",
       "87259072           Caucasian       0  \n",
       "87259073           Caucasian       1  \n",
       "\n",
       "[43632904 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_df['labels']=(logistic_df.reference_identity == logistic_df.candidate_identity )*1\n",
    "logistic_df2 = logistic_df[(logistic_df['reference_ethnicity']==logistic_df['candidate_ethnicity'] )]\n",
    "logistic_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    43618246\n",
       "1       14658\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels= logistic_df2.labels\n",
    "logistic_df2.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16854868 26642054 17706011 ... 16602078 20463754  6485722]\n"
     ]
    }
   ],
   "source": [
    "match_idx = np.where(labels==1)[0]\n",
    "not_match_idx = np.where(labels==0)[0]\n",
    "np.random.seed(random_state)\n",
    "not_match_idx_sub  = not_match_idx[np.random.choice(len(not_match_idx), size=len(match_idx), replace=False)]\n",
    "print((not_match_idx_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43632904, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_1 = np.arange(reference_outputs.shape[0])\n",
    "array_2 = np.arange(candidate_outputs.shape[0])\n",
    "mesh = np.array(np.meshgrid(array_1, array_2))\n",
    "combinations = mesh.T.reshape(-1, 2)\n",
    "combinations = combinations[logistic_df2.index.values]\n",
    "combinations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35150300cec645c8accd4a80dfe1f109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/senet_rfw_load_logistic_data.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/senet_rfw_load_logistic_data.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m match_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/senet_rfw_load_logistic_data.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m _,pairs \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39menumerate\u001b[39m(match_pairs),total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(match_pairs)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/senet_rfw_load_logistic_data.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     match_list\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mconcat((reference_outputs[pairs[\u001b[39m0\u001b[39;49m]],candidate_outputs[pairs[\u001b[39m1\u001b[39m]])))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/senet_rfw_load_logistic_data.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m not_match_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sachinbeepath/HolisticAI/DISS_CODE/MSc_Dissertation/senet_rfw_load_logistic_data.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m _,pairs \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39menumerate\u001b[39m(not_match_pairs),total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(not_match_pairs)):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "match_pairs = combinations[match_idx]\n",
    "not_match_pairs = combinations[not_match_idx_sub]\n",
    "\n",
    "match_list = []\n",
    "for _,pairs in tqdm_notebook(enumerate(match_pairs),total=len(match_pairs)):\n",
    "    match_list.append(torch.concat((reference_outputs[pairs[0]],candidate_outputs[pairs[1]])))\n",
    "\n",
    "not_match_list = []\n",
    "for _,pairs in tqdm_notebook(enumerate(not_match_pairs),total=len(not_match_pairs)):\n",
    "    not_match_list.append(torch.concat((reference_outputs[pairs[0]],candidate_outputs[pairs[1]])))\n",
    "\n",
    "match_tensor=torch.stack(match_list)\n",
    "not_match_tensor=torch.stack(not_match_list)\n",
    "\n",
    "match_ref_ids =[]\n",
    "match_ref_eth =[]\n",
    "\n",
    "for _,pairs in tqdm_notebook(enumerate(match_pairs),total=len(match_pairs)):\n",
    "    match_ref_ids.append(reference_identities[pairs[0]])\n",
    "    match_ref_eth.append(reference_ethnicities[pairs[0]])\n",
    "not_match_ref_ids =[]\n",
    "not_match_ref_eth =[]\n",
    "not_match_cand_ids =[]\n",
    "not_match_cand_eth =[]\n",
    "\n",
    "for _,pairs in tqdm_notebook(enumerate(not_match_pairs),total=len(not_match_pairs)):\n",
    "    not_match_ref_ids.append(reference_identities[pairs[0]])\n",
    "    not_match_ref_eth.append(reference_ethnicities[pairs[0]])\n",
    "    not_match_cand_ids.append(candidate_identities[pairs[1]])\n",
    "    not_match_cand_eth.append(candidate_ethnicities[pairs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = torch.cat([match_tensor,not_match_tensor])\n",
    "torch.save(all_inputs,'inputs/rfw_senet50_face_embeddings.pt')\n",
    "match_labels = torch.ones(len(match_pairs))\n",
    "not_match_labels = torch.zeros(len(match_pairs))\n",
    "all_labels = torch.cat([match_labels,not_match_labels])\n",
    "torch.save(all_labels,'inputs/rfw_senet50_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29311</th>\n",
       "      <td>m.0402tg</td>\n",
       "      <td>m.01npnk3</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29312</th>\n",
       "      <td>m.05pbbnj</td>\n",
       "      <td>m.02rrb2n</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>m.09j6df</td>\n",
       "      <td>m.07kcsqd</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29314</th>\n",
       "      <td>m.0fhrbz</td>\n",
       "      <td>m.025zgjt</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29315</th>\n",
       "      <td>m.02q15tj</td>\n",
       "      <td>m.01w6m_0</td>\n",
       "      <td>African</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29316 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity candidate_identity reference_ethnicity  \\\n",
       "0               m.0c7mh2           m.0c7mh2             African   \n",
       "1               m.0c7mh2           m.0c7mh2             African   \n",
       "2              m.026tq86          m.026tq86             African   \n",
       "3              m.026tq86          m.026tq86             African   \n",
       "4              m.02wz3nc          m.02wz3nc             African   \n",
       "...                  ...                ...                 ...   \n",
       "29311           m.0402tg          m.01npnk3           Caucasian   \n",
       "29312          m.05pbbnj          m.02rrb2n           Caucasian   \n",
       "29313           m.09j6df          m.07kcsqd             African   \n",
       "29314           m.0fhrbz          m.025zgjt             African   \n",
       "29315          m.02q15tj          m.01w6m_0             African   \n",
       "\n",
       "      candidate_ethnicity  labels  \n",
       "0                 African     1.0  \n",
       "1                 African     1.0  \n",
       "2                 African     1.0  \n",
       "3                 African     1.0  \n",
       "4                 African     1.0  \n",
       "...                   ...     ...  \n",
       "29311           Caucasian     0.0  \n",
       "29312           Caucasian     0.0  \n",
       "29313             African     0.0  \n",
       "29314             African     0.0  \n",
       "29315             African     0.0  \n",
       "\n",
       "[29316 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ref_ids = match_ref_ids + not_match_ref_ids\n",
    "all_ref_eth = match_ref_eth + not_match_ref_eth\n",
    "all_cand_ids = match_ref_ids + not_match_cand_ids\n",
    "all_cand_eth = match_ref_eth + not_match_cand_eth\n",
    "\n",
    "all_df = { 'reference_identity': all_ref_ids,'candidate_identity': all_cand_ids,\n",
    "            'reference_ethnicity': all_ref_eth,'candidate_ethnicity': all_cand_eth,\n",
    "            'labels': all_labels.cpu().numpy()}\n",
    "\n",
    "\n",
    "all_df = pd.DataFrame(all_df)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('inputs/rfw_senet50_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
