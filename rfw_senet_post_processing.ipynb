{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "print(device)\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from aif360.algorithms.postprocessing import (CalibratedEqOddsPostprocessing,\n",
    "                                              EqOddsPostprocessing,\n",
    "                                              RejectOptionClassification)\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "random_state = 1\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>m.0c7mh2</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>m.026tq86</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>m.02wz3nc</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29311</th>\n",
       "      <td>m.0402tg</td>\n",
       "      <td>m.01npnk3</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29312</th>\n",
       "      <td>m.05pbbnj</td>\n",
       "      <td>m.02rrb2n</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>m.09j6df</td>\n",
       "      <td>m.07kcsqd</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29314</th>\n",
       "      <td>m.0fhrbz</td>\n",
       "      <td>m.025zgjt</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29315</th>\n",
       "      <td>m.02q15tj</td>\n",
       "      <td>m.01w6m_0</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29316 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity candidate_identity reference_ethnicity  \\\n",
       "0               m.0c7mh2           m.0c7mh2             african   \n",
       "1               m.0c7mh2           m.0c7mh2             african   \n",
       "2              m.026tq86          m.026tq86             african   \n",
       "3              m.026tq86          m.026tq86             african   \n",
       "4              m.02wz3nc          m.02wz3nc             african   \n",
       "...                  ...                ...                 ...   \n",
       "29311           m.0402tg          m.01npnk3           caucasian   \n",
       "29312          m.05pbbnj          m.02rrb2n           caucasian   \n",
       "29313           m.09j6df          m.07kcsqd             african   \n",
       "29314           m.0fhrbz          m.025zgjt             african   \n",
       "29315          m.02q15tj          m.01w6m_0             african   \n",
       "\n",
       "      candidate_ethnicity  labels  \n",
       "0                 African     1.0  \n",
       "1                 African     1.0  \n",
       "2                 African     1.0  \n",
       "3                 African     1.0  \n",
       "4                 African     1.0  \n",
       "...                   ...     ...  \n",
       "29311           Caucasian     0.0  \n",
       "29312           Caucasian     0.0  \n",
       "29313             African     0.0  \n",
       "29314             African     0.0  \n",
       "29315             African     0.0  \n",
       "\n",
       "[29316 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data and split\n",
    "X = torch.load('inputs/rfw_senet50_face_embeddings.pt').cpu()\n",
    "y = torch.load('inputs/rfw_senet50_labels.pt').cpu()\n",
    "df = pd.read_csv('inputs/rfw_senet50_df.csv')\n",
    "df['reference_ethnicity'] = df['reference_ethnicity'].str.lower()\n",
    "ethnicity = df['reference_ethnicity']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split data into 3 sets\n",
    "train_split, test_split = train_test_split(np.arange(len(X)),test_size=0.2, random_state=random_state)\n",
    "train_split, val_split = train_test_split(train_split,test_size=0.25, random_state=random_state)\n",
    "\n",
    "train_X = X[train_split]\n",
    "X_val = X[val_split]\n",
    "test_X = X[test_split]\n",
    "\n",
    "train_y = y[train_split]\n",
    "y_val = y[val_split]\n",
    "test_y = y[test_split]\n",
    "\n",
    "train_df = df.iloc[train_split]\n",
    "val_df = df.iloc[val_split]\n",
    "test_df = df.iloc[test_split]\n",
    "\n",
    "ethnicity = df['reference_ethnicity'].values\n",
    "ethnicity[ethnicity=='caucasian'] = 0\n",
    "ethnicity[ethnicity=='african'] = 1\n",
    "ethnicity = ethnicity.astype(int)\n",
    "\n",
    "train_ethnicity = ethnicity[train_split]\n",
    "\n",
    "\n",
    "ethnicity_val = ethnicity[val_split]\n",
    "\n",
    "test_ethnicity = ethnicity[test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non matches\n",
      "african      4492\n",
      "caucasian    4376\n",
      "Name: reference_ethnicity, dtype: int64\n",
      "matches\n",
      "african      4396\n",
      "caucasian    4325\n",
      "Name: reference_ethnicity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### get breakdown of training set\n",
    "\n",
    "train_matches = train_df[train_df.labels==1]\n",
    "train_non_matches = train_df[train_df.labels==0]\n",
    "print('non matches')\n",
    "print(train_non_matches['reference_ethnicity'].value_counts())\n",
    "print('matches')\n",
    "print(train_matches['reference_ethnicity'].value_counts())\n",
    "\n",
    "african_non_matches = train_non_matches[train_non_matches['reference_ethnicity']=='african']\n",
    "caucasian_non_matches = train_non_matches[train_non_matches['reference_ethnicity']=='caucasian']\n",
    "\n",
    "african_matches = train_matches[train_matches['reference_ethnicity']=='african']\n",
    "caucasian_matches = train_matches[train_matches['reference_ethnicity']=='caucasian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>m.03j6s0</td>\n",
       "      <td>m.03j6s0</td>\n",
       "      <td>1</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>m.01qd5bm</td>\n",
       "      <td>m.01qd5bm</td>\n",
       "      <td>1</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5881</th>\n",
       "      <td>m.02qdp4v</td>\n",
       "      <td>m.02qdp4v</td>\n",
       "      <td>1</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>m.0272001</td>\n",
       "      <td>m.0272001</td>\n",
       "      <td>1</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>m.05f962</td>\n",
       "      <td>m.05f962</td>\n",
       "      <td>1</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18810</th>\n",
       "      <td>m.0g3f1p</td>\n",
       "      <td>m.01kxfvq</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20550</th>\n",
       "      <td>m.07gb0p</td>\n",
       "      <td>m.0bgwxt</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24018</th>\n",
       "      <td>m.07pyvy</td>\n",
       "      <td>m.01y7m1</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20879</th>\n",
       "      <td>m.02qg85</td>\n",
       "      <td>m.070p26</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27148</th>\n",
       "      <td>m.05ppy0</td>\n",
       "      <td>m.0g9zt_w</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity candidate_identity reference_ethnicity  \\\n",
       "6419            m.03j6s0           m.03j6s0                   1   \n",
       "5541           m.01qd5bm          m.01qd5bm                   1   \n",
       "5881           m.02qdp4v          m.02qdp4v                   1   \n",
       "229            m.0272001          m.0272001                   1   \n",
       "5264            m.05f962           m.05f962                   1   \n",
       "...                  ...                ...                 ...   \n",
       "18810           m.0g3f1p          m.01kxfvq                   0   \n",
       "20550           m.07gb0p           m.0bgwxt                   0   \n",
       "24018           m.07pyvy           m.01y7m1                   0   \n",
       "20879           m.02qg85           m.070p26                   0   \n",
       "27148           m.05ppy0          m.0g9zt_w                   0   \n",
       "\n",
       "      candidate_ethnicity  labels  \n",
       "6419              African     1.0  \n",
       "5541              African     1.0  \n",
       "5881              African     1.0  \n",
       "229               African     1.0  \n",
       "5264              African     1.0  \n",
       "...                   ...     ...  \n",
       "18810           Caucasian     0.0  \n",
       "20550           Caucasian     0.0  \n",
       "24018           Caucasian     0.0  \n",
       "20879           Caucasian     0.0  \n",
       "27148           Caucasian     0.0  \n",
       "\n",
       "[17300 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "african_matches_sub_idx = african_matches.index[np.random.choice(len(african_matches.index), size=4325, replace=False)]\n",
    "caucasian_non_matches_sub_idx = caucasian_non_matches.index[np.random.choice(len(caucasian_non_matches.index), size=4325, replace=False)]\n",
    "african_non_matches_sub_idx = african_non_matches.index[np.random.choice(len(african_non_matches.index), size=4325, replace=False)]\n",
    "caucasian_matches_sub_idx = caucasian_matches.index\n",
    "\n",
    "X_train = torch.cat([X[african_matches_sub_idx],X[caucasian_matches_sub_idx],X[african_non_matches_sub_idx],X[caucasian_non_matches_sub_idx]])\n",
    "y_train = torch.cat([y[african_matches_sub_idx],y[caucasian_matches_sub_idx],y[african_non_matches_sub_idx],y[caucasian_non_matches_sub_idx]])\n",
    "ethnicity_train = np.concatenate([ethnicity[african_matches_sub_idx],ethnicity[caucasian_matches_sub_idx],ethnicity[african_non_matches_sub_idx],ethnicity[caucasian_non_matches_sub_idx]])\n",
    "df_train = pd.concat([df.iloc[african_matches_sub_idx],df.iloc[caucasian_matches_sub_idx],df.iloc[african_non_matches_sub_idx],df.iloc[caucasian_non_matches_sub_idx]])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_identity</th>\n",
       "      <th>candidate_identity</th>\n",
       "      <th>reference_ethnicity</th>\n",
       "      <th>candidate_ethnicity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26599</th>\n",
       "      <td>m.08dyjb</td>\n",
       "      <td>m.01dysq</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13208</th>\n",
       "      <td>m.05nqz8</td>\n",
       "      <td>m.05nqz8</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7459</th>\n",
       "      <td>m.0chlpf</td>\n",
       "      <td>m.0chlpf</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>m.0gzkxh</td>\n",
       "      <td>m.0gzkxh</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22098</th>\n",
       "      <td>m.01tl0vh</td>\n",
       "      <td>m.027g5hs</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27224</th>\n",
       "      <td>m.0glqs_8</td>\n",
       "      <td>m.05972y</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>m.06w9s22</td>\n",
       "      <td>m.06w9s22</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>m.04zvsy6</td>\n",
       "      <td>m.06tvw7</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25909</th>\n",
       "      <td>m.0h_dpyh</td>\n",
       "      <td>m.04d_dnm</td>\n",
       "      <td>african</td>\n",
       "      <td>African</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16263</th>\n",
       "      <td>m.05zp39m</td>\n",
       "      <td>m.01nwty</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reference_identity candidate_identity reference_ethnicity  \\\n",
       "26599           m.08dyjb           m.01dysq             african   \n",
       "13208           m.05nqz8           m.05nqz8           caucasian   \n",
       "7459            m.0chlpf           m.0chlpf           caucasian   \n",
       "4747            m.0gzkxh           m.0gzkxh             african   \n",
       "22098          m.01tl0vh          m.027g5hs             african   \n",
       "...                  ...                ...                 ...   \n",
       "27224          m.0glqs_8           m.05972y             african   \n",
       "5728           m.06w9s22          m.06w9s22             african   \n",
       "18206          m.04zvsy6           m.06tvw7           caucasian   \n",
       "25909          m.0h_dpyh          m.04d_dnm             african   \n",
       "16263          m.05zp39m           m.01nwty           caucasian   \n",
       "\n",
       "      candidate_ethnicity  labels  \n",
       "26599             African     0.0  \n",
       "13208           Caucasian     1.0  \n",
       "7459            Caucasian     1.0  \n",
       "4747              African     1.0  \n",
       "22098             African     0.0  \n",
       "...                   ...     ...  \n",
       "27224             African     0.0  \n",
       "5728              African     1.0  \n",
       "18206           Caucasian     0.0  \n",
       "25909             African     0.0  \n",
       "16263           Caucasian     0.0  \n",
       "\n",
       "[587 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split, holdout_split = train_test_split(np.arange(5864),test_size=0.1, random_state=random_state)\n",
    "X_test = test_X[test_split]\n",
    "X_holdout = test_X[holdout_split]\n",
    "y_test = test_y[test_split]\n",
    "y_holdout = test_y[holdout_split]\n",
    "ethnicity_test = test_ethnicity[test_split]\n",
    "ethnicity_holdout = test_ethnicity[holdout_split]\n",
    "df_test = test_df.iloc[test_split]\n",
    "df_holdout = test_df.iloc[holdout_split]\n",
    "df_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(data.Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data,ethnicity):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.ethnicity = ethnicity    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index], self.ethnicity[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train),\n",
    "                       ethnicity_train)\n",
    "test_data = TrainData(torch.FloatTensor(X_test),torch.FloatTensor(y_test),ethnicity_test)\n",
    "holdout_data = TrainData(torch.FloatTensor(X_holdout),torch.FloatTensor(y_holdout),ethnicity_holdout)\n",
    "val_data = TrainData(torch.FloatTensor(X_val), \n",
    "                       torch.FloatTensor(y_val),\n",
    "                       ethnicity_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a bunch of stuff\n",
    "\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 4096\n",
    "        self.layer_1 = nn.Linear(4096, 1024) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(1024)\n",
    "        self.layer_2 = nn.Linear(1024, 512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.layer_out = nn.Linear(512, 1) \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def confusion_mat(y_pred, y_test):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    acc = (tn + tp)/(tn+tp+fn+fp)\n",
    "    return tn, fp, fn, tp, acc\n",
    "def val_model(model, loader, criterion):\n",
    "    \"\"\"Validate model on loader with criterion function\"\"\"\n",
    "    y_true, y_pred, y_prot = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels,protected in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            y_true.append(labels)\n",
    "            y_prot.append(protected)\n",
    "            y_pred.append(torch.sigmoid(model(inputs)).cpu())\n",
    "    y_true, y_pred, y_prot = torch.cat(y_true), torch.cat(y_pred), torch.cat(y_prot)\n",
    "    return criterion(y_true, y_pred, y_prot)\n",
    "def compute_bias(y_pred, y_true, prot, metric):\n",
    "    \"\"\"Compute bias on the dataset\"\"\"\n",
    "    def zero_if_nan(data):\n",
    "        \"\"\"Zero if there is a nan\"\"\"\n",
    "        return 0. if torch.isnan(data) else data\n",
    "\n",
    "    gtpr_prot = zero_if_nan(y_pred[prot * y_true == 1].mean())\n",
    "    gfpr_prot = zero_if_nan(y_pred[prot * (1-y_true) == 1].mean())\n",
    "    mean_prot = zero_if_nan(y_pred[prot == 1].mean())\n",
    "\n",
    "    gtpr_unprot = zero_if_nan(y_pred[(1-prot) * y_true == 1].mean())\n",
    "    gfpr_unprot = zero_if_nan(y_pred[(1-prot) * (1-y_true) == 1].mean())\n",
    "    mean_unprot = zero_if_nan(y_pred[(1-prot) == 1].mean())\n",
    "\n",
    "    if metric == \"spd\":\n",
    "        return mean_prot - mean_unprot\n",
    "    elif metric == \"aod\":\n",
    "        return 0.5 * ((gfpr_prot - gfpr_unprot) + (gtpr_prot - gtpr_unprot))\n",
    "    elif metric == \"eod\":\n",
    "        return gtpr_prot - gtpr_unprot\n",
    "    elif metric=='false_diff':\n",
    "        return (np.abs(gfpr_prot - gfpr_unprot) + np.abs(gtpr_unprot - gtpr_prot))\n",
    "\n",
    "def compute_objective(performance, bias, epsilon=0.001, margin=0.0005):\n",
    "    if abs(bias) <= (epsilon-margin):\n",
    "        return performance\n",
    "    else:\n",
    "        return 0.0\n",
    "def get_best_objective(y_true, y_pred, y_prot):\n",
    "    \"\"\"Find the threshold for the best objective\"\"\"\n",
    "    num_samples = 5\n",
    "    threshs = torch.linspace(0, 1, 501)\n",
    "    best_obj, best_thresh = -math.inf, 0.\n",
    "    for thresh in threshs:\n",
    "        indices = np.random.choice(np.arange(y_pred.size()[0]), num_samples*y_pred.size()[0], replace=True).reshape(num_samples, y_pred.size()[0])\n",
    "        objs = []\n",
    "        for index in indices:\n",
    "            y_pred_tmp = y_pred[index]\n",
    "            y_true_tmp = y_true[index]\n",
    "            y_prot_tmp = y_prot[index]\n",
    "            perf = (torch.mean((y_pred_tmp > thresh)[y_true_tmp.type(torch.bool)].type(torch.float32)) + torch.mean((y_pred_tmp <= thresh)[~y_true_tmp.type(torch.bool)].type(torch.float32))) / 2\n",
    "            bias = compute_bias((y_pred_tmp > thresh).float().cpu(), y_true_tmp.float().cpu(), y_prot_tmp.float().cpu(), 'false_diff')\n",
    "            objs.append(compute_objective(perf, bias))\n",
    "        obj = float(torch.tensor(objs).mean())\n",
    "        if obj > best_obj:\n",
    "            best_obj, best_thresh = obj, thresh\n",
    "\n",
    "    return best_obj, best_thresh\n",
    "def AOE(tn_1,fp_1,fn_1,tp_1,tn_0,fp_0,fn_0,tp_0):\n",
    "    tpr_1 = tp_1/(tp_1+fn_1)\n",
    "    tpr_0 = tp_0/(tp_0+fn_0)\n",
    "\n",
    "    fpr_1 = fp_1/(fp_1+tn_1)\n",
    "    fpr_0 = fp_0/(fp_0+tn_0)\n",
    "\n",
    "    return (np.abs(fpr_1-fpr_0) + np.abs(tpr_1 - tpr_0))/2\n",
    "def to_dataframe(y_true, y_pred, y_prot):\n",
    "        y_true, y_pred, y_prot = y_true.float().cpu().numpy(), y_pred.float().cpu().numpy(), y_prot.float().cpu().numpy()\n",
    "        df = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'y_prot': y_prot})\n",
    "        dataset = StandardDataset(df, 'y_true', [1.], ['y_prot'], [[1.]])\n",
    "        dataset.scores = y_pred.reshape(-1, 1)\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load pre trained model\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "eps = 1e-5\n",
    "model = torch.load('weights/rfw_senet50_logistic_regression_face_matching_0.0_betaTEST.pt')\n",
    "# model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE)\n",
    "val_loader = data.DataLoader(dataset=val_data, batch_size=BATCH_SIZE)\n",
    "holdout_loader = data.DataLoader(dataset=holdout_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0189)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bias on val set\n",
    "y_true, y_pred, y_prot = [], [], []\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels,protected in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        y_true.append(labels)\n",
    "        y_prot.append(protected)\n",
    "        y_pred.append(torch.sigmoid(model(inputs)[:, 0]).cpu())\n",
    "y_true, y_pred, y_prot = torch.cat(y_true), torch.cat(y_pred), torch.cat(y_prot)\n",
    "\n",
    "compute_bias((y_pred>0.5).float().cpu(), y_true, y_prot, 'false_diff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0340)\n",
      "tensor(-0.0170)\n"
     ]
    }
   ],
   "source": [
    "# apply model to test set and get bias before mitigating\n",
    "test_true, test_pred, test_prot = [], [], []\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels,protected in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        test_true.append(labels)\n",
    "        test_prot.append(protected)\n",
    "        test_pred.append(torch.sigmoid(model(inputs)[:, 0]).cpu())\n",
    "test_true, test_pred, test_prot = torch.cat(test_true), torch.cat(test_pred), torch.cat(test_prot)\n",
    "\n",
    "print(compute_bias((test_pred>0.5).float().cpu(), test_true, test_prot, 'false_diff'))\n",
    "print(compute_bias((test_pred>0.5).float().cpu(), test_true, test_prot, 'aod'))\n",
    "aif_data = to_dataframe(test_true, test_pred, test_prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.938\n",
      "Missclassificaition Rate Ratio: 1.156\n",
      "FNR Ratio: 2.346 FPR Ratio: 0.909\n",
      "AOE: 0.017\n"
     ]
    }
   ],
   "source": [
    "# same thing as before pretty much\n",
    "test_bias_df = pd.DataFrame(columns=['label','prediction','rounded','protected'])\n",
    "test_bias_df['label']=test_true.cpu().numpy()\n",
    "test_bias_df['prediction']=test_pred.cpu().numpy()\n",
    "test_bias_df['rounded']=(test_pred>0.5).float().cpu()\n",
    "test_bias_df['protected']=test_prot\n",
    "unpriveleged_df = test_bias_df[test_bias_df['protected']==1]\n",
    "priveleged_df = test_bias_df[test_bias_df['protected']==0]\n",
    "\n",
    "unpriveleged_tn, unpriveleged_fp, unpriveleged_fn, unpriveleged_tp, unpriveleged_acc = confusion_mat(unpriveleged_df['rounded'], unpriveleged_df['label'])\n",
    "priveleged_tn, priveleged_fp, priveleged_fn, priveleged_tp, priveleged_acc = confusion_mat(priveleged_df['rounded'], priveleged_df['label'])\n",
    "unpriveleged_fnr = unpriveleged_fn/(unpriveleged_fn+unpriveleged_tp)\n",
    "unpriveleged_fpr = unpriveleged_fp/(unpriveleged_fp+unpriveleged_tn)\n",
    "priveleged_fnr = priveleged_fn/(priveleged_fn+priveleged_tp)\n",
    "priveleged_fpr = priveleged_fp/(priveleged_fp+priveleged_tn)\n",
    "\n",
    "print('Overall Accuracy:',round(torch.sum((test_pred>0.5).float().cpu() == test_true).item()/test_true.size()[0],3))\n",
    "print('Missclassificaition Rate Ratio:',round((1-unpriveleged_acc)/(1- priveleged_acc),3))\n",
    "print('FNR Ratio:',round(unpriveleged_fnr/priveleged_fnr,3),'FPR Ratio:',round(unpriveleged_fpr/priveleged_fpr,3))\n",
    "print('AOE:',round(AOE(unpriveleged_tn,unpriveleged_fp,unpriveleged_fn,unpriveleged_tp,priveleged_tn,priveleged_fp,priveleged_fn,priveleged_tp),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassificaition Rate Ratio: nan\n",
      "FPR Ratio: nan\n",
      "FNR Ratio: nan\n",
      "Overall Accuracy: 1.0\n",
      "AOD: tensor(0., dtype=torch.float64)\n",
      "False Diff: tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### apply eo post\n",
    "eo = EqOddsPostprocessing(privileged_groups=[{'y_prot': 0.}],\n",
    "                                  unprivileged_groups=[{'y_prot': 1.}],seed=random_state)\n",
    "\n",
    "eo=eo.fit(aif_data,aif_data)\n",
    "\n",
    "eo_pred = eo.predict(aif_data).labels.reshape(-1)\n",
    "eo_label = aif_data.labels.reshape(-1)\n",
    "eo_prot = aif_data.protected_attributes.reshape(-1)\n",
    "\n",
    "eo_unpriv_ids = (eo_prot==1)\n",
    "eo_unpriv_pred = eo_pred[eo_unpriv_ids]\n",
    "eo_unpriv_label = eo_label[eo_unpriv_ids]\n",
    "\n",
    "eo_priv_ids = (eo_prot==0)\n",
    "eo_priv_pred = eo_pred[eo_priv_ids]\n",
    "eo_priv_label = eo_label[eo_priv_ids]\n",
    "\n",
    "eo_unpriv_tn, eo_unpriv_fp, eo_unpriv_fn, eo_unpriv_tp, eo_unpriv_acc = confusion_mat(eo_unpriv_pred, eo_unpriv_label)\n",
    "eo_unpriv_fpr = eo_unpriv_fp/(eo_unpriv_fp+eo_unpriv_tn)\n",
    "eo_unpriv_fnr = eo_unpriv_fn/(eo_unpriv_fn+eo_unpriv_tp)\n",
    "\n",
    "eo_priv_tn, eo_priv_fp, eo_priv_fn, eo_priv_tp, eo_priv_acc = confusion_mat(eo_priv_pred, eo_priv_label)\n",
    "eo_priv_fpr = eo_priv_fp/(eo_priv_fp+eo_priv_tn)\n",
    "eo_priv_fnr = eo_priv_fn/(eo_priv_fn+eo_priv_tp)\n",
    "\n",
    "print('Missclassificaition Rate Ratio:',round((1-eo_unpriv_acc)/(1- eo_priv_acc),3))\n",
    "print('FPR Ratio:',eo_unpriv_fpr/eo_priv_fpr)\n",
    "print('FNR Ratio:',eo_unpriv_fnr/eo_priv_fnr)\n",
    "print('Overall Accuracy:', np.sum(eo_pred == eo_label)/len(eo_pred))\n",
    "print('AOD:',compute_bias(torch.tensor(eo_pred), torch.tensor(eo_label), torch.tensor(eo_prot), 'aod'))\n",
    "print('False Diff:',compute_bias(torch.tensor(eo_pred), torch.tensor(eo_label), torch.tensor(eo_prot), 'false_diff'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1172)\n",
      "tensor(-0.0586)\n"
     ]
    }
   ],
   "source": [
    "# apply model to holdout set and get bias before mitigating\n",
    "holdout_true, holdout_pred, holdout_prot = [], [], []\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels,protected in holdout_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        holdout_true.append(labels)\n",
    "        holdout_prot.append(protected)\n",
    "        holdout_pred.append(torch.sigmoid(model(inputs)[:, 0]).cpu())\n",
    "holdout_true, holdout_pred, holdout_prot = torch.cat(holdout_true), torch.cat(holdout_pred), torch.cat(holdout_prot)\n",
    "print(compute_bias((holdout_pred>0.5).float().cpu(), holdout_true, holdout_prot, 'false_diff'))\n",
    "print(compute_bias((holdout_pred>0.5).float().cpu(), holdout_true, holdout_prot, 'aod'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassificaition Rate Ratio: nan\n",
      "FPR Ratio: nan\n",
      "FNR Ratio: nan\n",
      "Overall Accuracy: 1.0\n",
      "AOD: tensor(0., dtype=torch.float64)\n",
      "False Diff: tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### apply eo prediction to hold out\n",
    "holdout_aif_data = to_dataframe(holdout_true, holdout_pred, holdout_prot)\n",
    "\n",
    "holdout_eo_pred = eo.predict(holdout_aif_data).labels.reshape(-1)\n",
    "holdout_eo_label = holdout_aif_data.labels.reshape(-1)\n",
    "holdout_eo_prot = holdout_aif_data.protected_attributes.reshape(-1)\n",
    "\n",
    "holdout_eo_unpriv_ids = (holdout_eo_prot==1)\n",
    "holdout_eo_unpriv_pred = holdout_eo_pred[holdout_eo_unpriv_ids]\n",
    "holdout_eo_unpriv_label = holdout_eo_label[holdout_eo_unpriv_ids]\n",
    "\n",
    "holdout_eo_priv_ids = (holdout_eo_prot==0)\n",
    "holdout_eo_priv_pred = holdout_eo_pred[holdout_eo_priv_ids]\n",
    "holdout_eo_priv_label = holdout_eo_label[holdout_eo_priv_ids]\n",
    "\n",
    "holdout_eo_unpriv_tn, holdout_eo_unpriv_fp, holdout_eo_unpriv_fn, holdout_eo_unpriv_tp, holdout_eo_unpriv_acc = confusion_mat(holdout_eo_unpriv_pred, holdout_eo_unpriv_label)\n",
    "holdout_eo_unpriv_fpr = holdout_eo_unpriv_fp/(holdout_eo_unpriv_fp+holdout_eo_unpriv_tn)\n",
    "holdout_eo_unpriv_fnr = holdout_eo_unpriv_fn/(holdout_eo_unpriv_fn+holdout_eo_unpriv_tp)\n",
    "\n",
    "holdout_eo_priv_tn, holdout_eo_priv_fp, holdout_eo_priv_fn, holdout_eo_priv_tp, holdout_eo_priv_acc = confusion_mat(holdout_eo_priv_pred, holdout_eo_priv_label)\n",
    "holdout_eo_priv_fpr = holdout_eo_priv_fp/(holdout_eo_priv_fp+holdout_eo_priv_tn)\n",
    "holdout_eo_priv_fnr = holdout_eo_priv_fn/(holdout_eo_priv_fn+holdout_eo_priv_tp)\n",
    "\n",
    "print('Missclassificaition Rate Ratio:',round((1-holdout_eo_unpriv_acc)/(1- holdout_eo_priv_acc),3))\n",
    "print('FPR Ratio:',holdout_eo_unpriv_fpr/holdout_eo_priv_fpr)\n",
    "print('FNR Ratio:',holdout_eo_unpriv_fnr/holdout_eo_priv_fnr)\n",
    "print('Overall Accuracy:', np.sum(holdout_eo_pred == holdout_eo_label)/len(holdout_eo_pred))\n",
    "print('AOD:',compute_bias(torch.tensor(holdout_eo_pred), torch.tensor(holdout_eo_label), torch.tensor(holdout_eo_prot), 'aod'))\n",
    "print('False Diff:',compute_bias(torch.tensor(holdout_eo_pred), torch.tensor(holdout_eo_label), torch.tensor(holdout_eo_prot), 'false_diff'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassificaition Rate Ratio: 1.002\n",
      "FPR Ratio: 0.7671016823354775\n",
      "FNR Ratio: 2.3458723302135827\n",
      "Overall Accuracy: 0.934242941064999\n",
      "AOD: tensor(-0.0259, dtype=torch.float64)\n",
      "False Diff: tensor(0.0519, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### apply cpp post\n",
    "cost_constraint = 'weighted'\n",
    "cpp = CalibratedEqOddsPostprocessing(privileged_groups=[{'y_prot': 0.}],\n",
    "                                             unprivileged_groups=[{'y_prot': 1.}],\n",
    "                                             cost_constraint=cost_constraint,seed=random_state)\n",
    "cpp=cpp.fit(aif_data,aif_data)\n",
    "cpp_pred = cpp.predict(aif_data).labels.reshape(-1)\n",
    "cpp_label = aif_data.labels.reshape(-1)\n",
    "cpp_prot = aif_data.protected_attributes.reshape(-1)\n",
    "\n",
    "cpp_unpriv_ids = (cpp_prot==1)\n",
    "cpp_unpriv_pred = cpp_pred[cpp_unpriv_ids]\n",
    "cpp_unpriv_label = cpp_label[cpp_unpriv_ids]\n",
    "\n",
    "cpp_priv_ids = (cpp_prot==0)\n",
    "cpp_priv_pred = cpp_pred[cpp_priv_ids]\n",
    "cpp_priv_label = cpp_label[cpp_priv_ids]\n",
    "\n",
    "cpp_unpriv_tn, cpp_unpriv_fp, cpp_unpriv_fn, cpp_unpriv_tp, cpp_unpriv_acc = confusion_mat(cpp_unpriv_pred, cpp_unpriv_label)\n",
    "cpp_unpriv_fpr = cpp_unpriv_fp/(cpp_unpriv_fp+cpp_unpriv_tn)\n",
    "cpp_unpriv_fnr = cpp_unpriv_fn/(cpp_unpriv_fn+cpp_unpriv_tp)\n",
    "\n",
    "cpp_priv_tn, cpp_priv_fp, cpp_priv_fn, cpp_priv_tp, cpp_priv_acc = confusion_mat(cpp_priv_pred, cpp_priv_label)\n",
    "cpp_priv_fpr = cpp_priv_fp/(cpp_priv_fp+cpp_priv_tn)\n",
    "cpp_priv_fnr = cpp_priv_fn/(cpp_priv_fn+cpp_priv_tp)\n",
    "\n",
    "\n",
    "print('Missclassificaition Rate Ratio:',round((1-cpp_unpriv_acc)/(1- cpp_priv_acc),3))\n",
    "print('FPR Ratio:',cpp_unpriv_fpr/cpp_priv_fpr)\n",
    "print('FNR Ratio:',cpp_unpriv_fnr/cpp_priv_fnr)\n",
    "print('Overall Accuracy:', np.sum(cpp_pred == cpp_label)/len(eo_pred))\n",
    "print('AOD:',compute_bias(torch.tensor(cpp_pred), torch.tensor(cpp_label), torch.tensor(cpp_prot), 'aod'))\n",
    "print('False Diff:',compute_bias(torch.tensor(cpp_pred), torch.tensor(cpp_label), torch.tensor(cpp_prot), 'false_diff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassificaition Rate Ratio: 0.823\n",
      "FPR Ratio: 0.4507042253521127\n",
      "FNR Ratio: 4.548192771084337\n",
      "Overall Accuracy: 0.9284497444633731\n",
      "AOD: tensor(-0.0664, dtype=torch.float64)\n",
      "False Diff: tensor(0.1328, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### cpp holdout predict\n",
    "holdout_cpp_pred = cpp.predict(holdout_aif_data).labels.reshape(-1)\n",
    "holdout_cpp_label = holdout_aif_data.labels.reshape(-1)\n",
    "holdout_cpp_prot = holdout_aif_data.protected_attributes.reshape(-1)\n",
    "\n",
    "holdout_cpp_unpriv_ids = (holdout_cpp_prot==1)\n",
    "holdout_cpp_unpriv_pred = holdout_cpp_pred[holdout_cpp_unpriv_ids]\n",
    "holdout_cpp_unpriv_label = holdout_cpp_label[holdout_cpp_unpriv_ids]\n",
    "\n",
    "holdout_cpp_priv_ids = (holdout_cpp_prot==0)\n",
    "holdout_cpp_priv_pred = holdout_cpp_pred[holdout_cpp_priv_ids]\n",
    "holdout_cpp_priv_label = holdout_cpp_label[holdout_cpp_priv_ids]\n",
    "\n",
    "holdout_cpp_unpriv_tn, holdout_cpp_unpriv_fp, holdout_cpp_unpriv_fn, holdout_cpp_unpriv_tp, holdout_cpp_unpriv_acc = confusion_mat(holdout_cpp_unpriv_pred, holdout_cpp_unpriv_label)\n",
    "holdout_cpp_unpriv_fpr = holdout_cpp_unpriv_fp/(holdout_cpp_unpriv_fp+holdout_cpp_unpriv_tn)\n",
    "holdout_cpp_unpriv_fnr = holdout_cpp_unpriv_fn/(holdout_cpp_unpriv_fn+holdout_cpp_unpriv_tp)\n",
    "\n",
    "holdout_cpp_priv_tn, holdout_cpp_priv_fp, holdout_cpp_priv_fn, holdout_cpp_priv_tp, holdout_cpp_priv_acc = confusion_mat(holdout_cpp_priv_pred, holdout_cpp_priv_label)\n",
    "holdout_cpp_priv_fpr = holdout_cpp_priv_fp/(holdout_cpp_priv_fp+holdout_cpp_priv_tn)\n",
    "holdout_cpp_priv_fnr = holdout_cpp_priv_fn/(holdout_cpp_priv_fn+holdout_cpp_priv_tp)\n",
    "\n",
    "print('Missclassificaition Rate Ratio:',round((1-holdout_cpp_unpriv_acc)/(1- holdout_cpp_priv_acc),3))\n",
    "print('FPR Ratio:',holdout_cpp_unpriv_fpr/holdout_cpp_priv_fpr)\n",
    "print('FNR Ratio:',holdout_cpp_unpriv_fnr/holdout_cpp_priv_fnr)\n",
    "print('Overall Accuracy:', np.sum(holdout_cpp_pred == holdout_cpp_label)/len(holdout_cpp_pred))\n",
    "print('AOD:',compute_bias(torch.tensor(holdout_cpp_pred), torch.tensor(holdout_cpp_label), torch.tensor(holdout_cpp_prot), 'aod'))\n",
    "print('False Diff:',compute_bias(torch.tensor(holdout_cpp_pred), torch.tensor(holdout_cpp_label), torch.tensor(holdout_cpp_prot), 'false_diff'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassificaition Rate Ratio: 1.253\n",
      "FPR Ratio: 2.203555976203353\n",
      "FNR Ratio: 0.7406518589623942\n",
      "Overall Accuracy: 0.944097024824711\n",
      "AOD: tensor(0.0292, dtype=torch.float64)\n",
      "False Diff: tensor(0.0585, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### apply roc post\n",
    "roc = RejectOptionClassification(unprivileged_groups=[{'y_prot': 1.}],\n",
    "                                         privileged_groups=[{'y_prot': 0.}],\n",
    "                                         low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                         num_class_thresh=100, num_ROC_margin=50,\n",
    "                                         metric_name=\"Average odds difference\",\n",
    "                                         metric_ub=0.05, metric_lb=-0.05)\n",
    "\n",
    "roc = roc.fit(aif_data, aif_data)\n",
    "\n",
    "roc_pred = roc.predict(aif_data).labels.reshape(-1)\n",
    "roc_label = aif_data.labels.reshape(-1)\n",
    "roc_prot = aif_data.protected_attributes.reshape(-1)\n",
    "\n",
    "roc_unpriv_ids = (roc_prot==1)\n",
    "roc_unpriv_pred = roc_pred[roc_unpriv_ids]\n",
    "roc_unpriv_label = roc_label[roc_unpriv_ids]\n",
    "\n",
    "roc_priv_ids = (roc_prot==0)\n",
    "roc_priv_pred = roc_pred[roc_priv_ids]\n",
    "roc_priv_label = roc_label[roc_priv_ids]\n",
    "\n",
    "roc_unpriv_tn, roc_unpriv_fp, roc_unpriv_fn, roc_unpriv_tp, roc_unpriv_acc = confusion_mat(roc_unpriv_pred, roc_unpriv_label)\n",
    "roc_unpriv_fpr = roc_unpriv_fp/(roc_unpriv_fp+roc_unpriv_tn)\n",
    "roc_unpriv_fnr = roc_unpriv_fn/(roc_unpriv_fn+roc_unpriv_tp)\n",
    "\n",
    "roc_priv_tn, roc_priv_fp, roc_priv_fn, roc_priv_tp, roc_priv_acc = confusion_mat(roc_priv_pred, roc_priv_label)\n",
    "roc_priv_fpr = roc_priv_fp/(roc_priv_fp+roc_priv_tn)\n",
    "roc_priv_fnr = roc_priv_fn/(roc_priv_fn+roc_priv_tp)\n",
    "\n",
    "print('Missclassificaition Rate Ratio:',round((1-roc_unpriv_acc)/(1- roc_priv_acc),3))\n",
    "print('FPR Ratio:',roc_unpriv_fpr/roc_priv_fpr)\n",
    "print('FNR Ratio:',roc_unpriv_fnr/roc_priv_fnr)\n",
    "print('Overall Accuracy:', np.sum(roc_pred == roc_label)/len(eo_pred))\n",
    "print('AOD:',compute_bias(torch.tensor(roc_pred), torch.tensor(roc_label), torch.tensor(roc_prot), 'aod'))\n",
    "print('False Diff:',compute_bias(torch.tensor(roc_pred), torch.tensor(roc_label), torch.tensor(roc_prot), 'false_diff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassificaition Rate Ratio: 0.996\n",
      "FPR Ratio: 1.1267605633802817\n",
      "FNR Ratio: 0.9096385542168673\n",
      "Overall Accuracy: 0.9284497444633731\n",
      "AOD: tensor(0.0076, dtype=torch.float64)\n",
      "False Diff: tensor(0.0151, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### roc predict on holdout\n",
    "holdout_roc_pred = roc.predict(holdout_aif_data).labels.reshape(-1)\n",
    "holdout_roc_label = holdout_aif_data.labels.reshape(-1)\n",
    "holdout_roc_prot = holdout_aif_data.protected_attributes.reshape(-1)\n",
    "\n",
    "holdout_roc_unpriv_ids = (holdout_roc_prot==1)\n",
    "holdout_roc_unpriv_pred = holdout_roc_pred[holdout_roc_unpriv_ids]\n",
    "holdout_roc_unpriv_label = holdout_roc_label[holdout_roc_unpriv_ids]\n",
    "\n",
    "holdout_roc_priv_ids = (holdout_roc_prot==0)\n",
    "holdout_roc_priv_pred = holdout_roc_pred[holdout_roc_priv_ids]\n",
    "holdout_roc_priv_label = holdout_roc_label[holdout_roc_priv_ids]\n",
    "\n",
    "holdout_roc_unpriv_tn, holdout_roc_unpriv_fp, holdout_roc_unpriv_fn, holdout_roc_unpriv_tp, holdout_roc_unpriv_acc = confusion_mat(holdout_roc_unpriv_pred, holdout_roc_unpriv_label)\n",
    "holdout_roc_unpriv_fpr = holdout_roc_unpriv_fp/(holdout_roc_unpriv_fp+holdout_roc_unpriv_tn)\n",
    "holdout_roc_unpriv_fnr = holdout_roc_unpriv_fn/(holdout_roc_unpriv_fn+holdout_roc_unpriv_tp)\n",
    "\n",
    "holdout_roc_priv_tn, holdout_roc_priv_fp, holdout_roc_priv_fn, holdout_roc_priv_tp, holdout_roc_priv_acc = confusion_mat(holdout_roc_priv_pred, holdout_roc_priv_label)\n",
    "holdout_roc_priv_fpr = holdout_roc_priv_fp/(holdout_roc_priv_fp+holdout_roc_priv_tn)\n",
    "holdout_roc_priv_fnr = holdout_roc_priv_fn/(holdout_roc_priv_fn+holdout_roc_priv_tp)\n",
    "\n",
    "print('Missclassificaition Rate Ratio:',round((1-holdout_roc_unpriv_acc)/(1- holdout_roc_priv_acc),3))\n",
    "print('FPR Ratio:',holdout_roc_unpriv_fpr/holdout_roc_priv_fpr)\n",
    "print('FNR Ratio:',holdout_roc_unpriv_fnr/holdout_roc_priv_fnr)\n",
    "print('Overall Accuracy:', np.sum(holdout_roc_pred == holdout_roc_label)/len(holdout_roc_pred))\n",
    "print('AOD:',compute_bias(torch.tensor(holdout_roc_pred), torch.tensor(holdout_roc_label), torch.tensor(holdout_roc_prot), 'aod'))\n",
    "print('False Diff:',compute_bias(torch.tensor(holdout_roc_pred), torch.tensor(holdout_roc_label), torch.tensor(holdout_roc_prot), 'false_diff'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
